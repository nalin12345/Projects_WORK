{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397a1d37-f057-4067-b5a7-9ada522c6fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title event_type  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "#read data into papers\n",
    "papers = pd.read_csv(r'C:\\Users\\Nalin\\Desktop\\papers.csv')\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eff7e5d-a6aa-40d7-897b-f170d3887817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>Brain Inspired Reinforcement Learning\\nFran?oi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5621</th>\n",
       "      <td>Dimension-Free Iteration Complexity of Finite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>Efficient Spike-Coding with Multiplicative\\nAd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>An MDP-Based Approach to Online\\nMechanism Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>Finding the M Most Probable\\nConfigurations Us...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             paper_text\n",
       "1925  Brain Inspired Reinforcement Learning\\nFran?oi...\n",
       "5621  Dimension-Free Iteration Complexity of Finite ...\n",
       "4085  Efficient Spike-Coding with Multiplicative\\nAd...\n",
       "1576  An MDP-Based Approach to Online\\nMechanism Des...\n",
       "1483  Finding the M Most Probable\\nConfigurations Us..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove the columns\n",
    "papers = papers.drop(columns=['id','title','abstract','event_type','pdf_name','year'],axis=1)\n",
    "\n",
    "#sample only 100 papers\n",
    "papers = papers.sample(100)\n",
    "\n",
    "#print out the first rows of papers\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8614b615-c668-4f63-ba0e-c0c7cc5bf321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1925    brain inspired reinforcement learning\\nfranois...\n",
       "5621    dimension-free iteration complexity of finite ...\n",
       "4085    efficient spike-coding with multiplicative\\nad...\n",
       "1576    an mdp-based approach to online\\nmechanism des...\n",
       "1483    finding the m most probable\\nconfigurations us...\n",
       "Name: paper_text_processed, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the regular expression library\n",
    "import re\n",
    "\n",
    "#remove punctuation\n",
    "papers['paper_text_processed'] = papers['paper_text'].map(lambda x: re.sub('[,\\.!?]','',x))\n",
    "\n",
    "#convert the titles to lowercase\n",
    "papers['paper_text_processed'] = papers['paper_text_processed'].map(lambda x: x.lower())\n",
    "\n",
    "#print out the first rows of papers\n",
    "papers['paper_text_processed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b32f9d-a666-4b44-9881-fe0a6c0eb33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain', 'inspired', 'reinforcement', 'learning', 'franois', 'rivest', 'yoshua', 'bengio', 'dpartement', 'dinformatique', 'et', 'de', 'recherche', 'oprationnelle', 'universit', 'de', 'montral', 'cp', 'succ', 'centre', 'ville', 'montral', 'qc', 'canada', 'francoisrivest', 'mailmcgillca', 'bengioy', 'iroumontrealca', 'john', 'kalaska']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True)) #deacc=True removes punctuations\n",
    "        \n",
    "data = papers.paper_text_processed.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e31fe5e0-bad5-4527-8230-f344add2157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words,min_count=5,threshold=100) #higher threshold fewer phrases\n",
    "trigram = gensim.models.Phrases(bigram[data_words],threshold=100)\n",
    "\n",
    "#faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe857f45-b8d1-4f5d-b3ff-a0ce7e982d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk stowords\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from','subject','re','edu','use'])\n",
    "\n",
    "#define functions for stopwords, bigrams, trigrsms and lemmatization\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts,allowed_postags=['NOUN','ADJ','VERB','ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ab08946-6e54-49d9-98a1-5dd77d15c612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['brain', 'inspire', 'reinforcement', 'learning', 'franois', 'rivest', 'yoshua_bengio', 'dpartement', 'dinformatique', 'recherche', 'oprationnelle', 'universit', 'montral', 'succ', 'centre', 'ville', 'montral', 'qc', 'canada', 'francoisriv', 'mailmcgillca', 'bengioy', 'john', 'kalaska', 'dpartement', 'physiologie', 'universit', 'montral', 'kalaskaj', 'abstract', 'successful', 'application', 'reinforcement', 'learning', 'algorithm', 'often', 'involve', 'considerable', 'hand', 'craft', 'necessary', 'non', 'linear', 'feature', 'reduce', 'complexity', 'value', 'function', 'hence', 'promote', 'convergence', 'algorithm', 'contrast', 'human', 'brain', 'readily', 'autonomously', 'find', 'complex', 'feature', 'provide', 'sufficient', 'training', 'recent', 'work', 'machine', 'learning', 'neurophysiology', 'demonstrate', 'role', 'basal_ganglia', 'frontal_cortex', 'mammalian', 'reinforcement', 'learning', 'paper', 'develop', 'explore', 'new', 'reinforcement', 'learning', 'algorithm', 'inspire', 'neurological', 'evidence', 'provide', 'potential', 'new', 'approach', 'feature', 'construction', 'problem', 'algorithm', 'compare', 'evaluated', 'acrobot', 'task', 'introduction', 'reinforcement', 'learning', 'algorithm', 'often', 'face', 'problem', 'find', 'useful', 'complex', 'non', 'linear', 'feature', 'reinforcement', 'learn', 'non', 'linear', 'function', 'approximator', 'backpropagation', 'network', 'attempt', 'address', 'problem', 'many', 'case', 'demonstrate', 'non', 'convergent', 'major', 'challenge', 'face', 'algorithm', 'learn', 'value', 'function', 'instead', 'learn', 'policy', 'motivating', 'interest', 'algorithm', 'directly', 'modify', 'policy', 'parallel', 'recent', 'work', 'neurophysiology', 'show', 'basal_ganglia', 'model', 'actor_critic', 'version', 'temporal_difference', 'learn', 'well', 'known', 'reinforcement', 'learning', 'algorithm', 'however', 'basal_ganglia', 'solve', 'problem', 'find', 'complex', 'feature', 'know', 'play', 'important', 'role', 'plan', 'decision_making', 'tightly', 'link', 'basal_ganglia', 'nature', 'interaction', 'still', 'poorly', 'understand', 'generate', 'grow', 'interest', 'neurophysiology', 'url_http', 'rivestfr', 'paper', 'present', 'new', 'algorithm', 'base', 'current', 'evidence', 'brain', 'functional', 'organization', 'try', 'devise', 'biologically_plausible', 'algorithm', 'help', 'overcome', 'exist', 'difficulty', 'machine', 'reinforcement', 'learning', 'algorithm', 'test', 'compare', 'acrobot', 'task', 'also', 'compare', 'use', 'standard', 'backpropagation', 'function', 'approximator', 'biological', 'background', 'mammalian', 'brain', 'multiple', 'learning', 'subsystem', 'major', 'learn', 'component', 'include', 'neocortex', 'hippocampal', 'formation', 'explicit', 'memory', 'storage', 'system', 'cerebellum', 'adaptive', 'control', 'system', 'basal_ganglia', 'reinforcement', 'learning', 'also', 'know', 'instrumental', 'conditioning', 'cortex', 'argue', 'equipotent', 'meaning', 'give', 'input', 'region', 'learn', 'perform', 'computation', 'nevertheless', 'frontal', 'lobe', 'differ', 'receive', 'particularly', 'prominent', 'innervation', 'specific', 'type', 'namely', 'dopamine', 'large', 'frontal', 'lobe', 'primate', 'especially', 'human', 'distinguish', 'low', 'mammal', 'region', 'cortex', 'model', 'use', 'unsupervised', 'learn', 'method', 'ica', 'model', 'learn', 'frontal_cortex', 'begin', 'emerge', 'frontal', 'dopaminergic', 'input', 'arise', 'part', 'basal_ganglia', 'call', 'ventral', 'tegmental', 'area', 'vta', 'substantia', 'nigra', 'sn', 'signal', 'generate', 'dopaminergic', 'neuron', 'resemble', 'effective', 'reinforcement', 'signal', 'temporal_difference', 'learn', 'algorithm', 'important', 'part', 'basal_ganglia', 'striatum', 'structure', 'make', 'part', 'matriosome', 'striosome', 'receive', 'input', 'cortex', 'mostly', 'frontal', 'neuron', 'striosome', 'project', 'principally', 'neuron', 'vta', 'sn', 'striosome', 'hypothesized', 'act', 'reward', 'predictor', 'allow', 'signal', 'compute', 'difference', 'expect', 'receive', 'reward', 'matriosome', 'project', 'back', 'frontal', 'lobe', 'example', 'motor', 'cortex', 'hypothesize', 'role', 'therefore', 'action', 'selection', 'several', 'attempt', 'model', 'interaction', 'frontal_cortex', 'basal_ganglia', 'little', 'work', 'do', 'learn', 'frontal_cortex', 'adaptive', 'learning', 'system', 'base', 'cerebellum', 'basal_ganglia', 'propose', 'reinforcement', 'learning', 'model', 'hippocampus', 'present', 'paper', 'attempt', 'model', 'datum', 'rather', 'develop', 'current', 'knowledge', 'new', 'efficient', 'reinforcement', 'learning', 'algorithm', 'model', 'model', 'develop', 'follow', 'architecture', 'depict', 'figure', 'first', 'layer', 'input', 'layer', 'activation', 'represent', 'current', 'state', 'second', 'layer', 'hidden_layer', 'responsible', 'find', 'non', 'linear', 'feature', 'necessary', 'solve', 'task', 'learn', 'layer', 'vary', 'model', 'model', 'input', 'hidden_layer', 'feed', 'parallel', 'actor_critic', 'layer', 'computational', 'analog', 'striatal', 'matriosome', 'striosome', 'respectively', 'represent', 'linear', 'actor_critic', 'implementation', 'neurological', 'literature', 'report', 'uplink', 'reward', 'da', 'neuron', 'send', 'effective', 'reinforcement', 'signal', 'dashed_line', 'action', 'unit', 'usually', 'feed', 'motor', 'cortex', 'control', 'muscle', 'activation', 'consider', 'represent', 'possible', 'action', 'basal_ganglia', 'receive', 'input', 'mainly', 'frontal_cortex', 'dopaminergic', 'signal', 'also', 'receive', 'input', 'parietal', 'cortex', 'oppose', 'frontal_cortex', 'receive', 'da', 'input', 'hence', 'unsupervised', 'represent', 'frontal_cortex', 'give', 'non', 'frontal_cortex', 'weight', 'correspond', 'weight', 'layer', 'respectively', 'weight', 'reward', 'striatum', 'frontal_cortex', 'sensory', 'input', 'figure', 'architecture', 'model', 'let', 'xt', 'vector', 'input', 'layer', 'activation', 'base', 'state', 'environment', 'time', 'let', 'sigmoidal', 'activation', 'function', 'hidden_unit', 'yt', 'unxt', 'vector', 'activation', 'hidden_layer', 'time', 'ui', 'row', 'weight', 'matrix', 'let', 'xtt', 'ytt', 'state', 'description', 'form', 'layer', 'time', 'actor_critic', 'model', 'basal_ganglia', 'develop', 'derive', 'similar', 'basal_ganglia', 'model', 'use', 'simulate', 'datum', 'record', 'monkey', 'learn', 'task', 'unit', 'linear', 'weight', 'sum', 'activity', 'previous', 'layer', 'actor', 'unit', 'behave', 'winner', 'take', 'rule', 'winner', 'activity', 'settle', 'other', 'initial', 'weight', 'equal', 'non_negative', 'order', 'obtain', 'initial', 'optimist', 'policy', 'beginning', 'overestimate', 'expect', 'reward', 'lead', 'action', 'negatively', 'correct', 'good', 'remain', 'usually', 'favor', 'exploration', 'vtzt', 'let', 'bt', 'wzt', 'vector', 'activation', 'actor', 'layer', 'winner', 'take', 'processing', 'let', 'argmax', 'bti', 'win', 'action', 'index', 'time', 'let', 'vector', 'ct', 'activation', 'layer', 'winner', 'take', 'processing', 'cta', 'otherwise', 'formal', 'description', 'learn', 'function', 'state', 'converge', 'expect', 'total', 'discounted_reward', 'order', 'update', 'reward', 'time', 'discount_factor', 'simple', 'way', 'achieve', 'transform', 'problem', 'optimization', 'problem', 'goal', 'minimize', 'also', 'useful', 'point', 'introduce', 'td', 'effective', 'reinforcement', 'signal', 'equivalent', 'dopaminergic', 'signal', 'thus', 'et', 'learning', 'rule', 'weight', 'devise', 'find', 'gradient', 'respect', 'weight', 'weight', 'sum', 'activity', 'thus', 'gradient', 'give', 'add', 'learn', 'rate', 'negating', 'gradient', 'minimization', 'give', 'update', 'develop', 'learning', 'rule', 'actor', 'unit', 'weight', 'use', 'cost', 'function', 'bit', 'complex', 'approach', 'tri', 'hebbian', 'rule', 'remark', 'row', 'vector', 'weight', 'win', 'action', 'modify', 'rule', 'first', 'introduce', 'simulate', 'associate', 'error', 'last', 'select', 'action', 'reward', 'high', 'expect', 'action', 'unit', 'activate', 'previous', 'state', 'reinforce', 'conversely', 'less', 'expect', 'win', 'actor', 'unit', 'activity', 'reduce', 'state', 'exactly', 'tri', 'hebbian', 'rule', 'biological', 'justification', 'present', 'first', 'description', 'actor_critic', 'architecture', 'base', 'datum', 'basal_ganglia', 'resemble', 'major', 'difference', 'complete', 'gradient', 'information', 'similar', 'version', 'also', 'develop', 'little', 'mathematical', 'justification', 'model', 'present', 'simple', 'critic', 'basically', 'justify', 'neurologically', 'model', 'also', 'realistic', 'actor', 'consistent', 'neurological', 'knowledge', 'plasticity', 'corticostriatal', 'synapse', 'weight', 'main', 'purpose', 'model', 'present', 'simulate', 'dopaminergic', 'activity', 'important', 'factor', 'respect', 'successful', 'hidden_layer', 'reinforcement', 'learn', 'layer', 'linear', 'hidden_layer', 'learn', 'necessary', 'non_linearity', 'solve', 'task', 'rule', 'attempt', 'neurologically', 'plausible', 'learning', 'rule', 'cortex', 'assume', 'clear', 'supervision', 'signal', 'signal', 'frontal_cortex', 'hidden_unit', 'weight', 'vector', 'initialize', 'randomly', 'scale', 'norm', 'update', 'fix', 'random', 'baseline', 'model', 'algorithm', 'compare', 'hidden_layer', 'compose', 'randomly', 'generate', 'hidden_unit', 'train', 'ica', 'visual', 'cortex', 'model', 'ica', 'learning', 'rule', 'non', 'frontal_cortex', 'equipotent', 'region', 'cortex', 'successfully', 'model', 'use', 'generic', 'rule', 'idea', 'combine', 'unsupervised', 'learn', 'reinforcement', 'learning', 'already', 'prove', 'useful', 'unsupervised', 'feature', 'train', 'prior', 'reinforcement', 'training', 'hand', 'show', 'different', 'system', 'sort', 'learn', 'concurrently', 'ica', 'rule', 'use', 'hidden_layer', 'mean', 'hidden_unit', 'learn', 'reproduce', 'independent', 'source', 'signal', 'origin', 'observe', 'mixed', 'signal', 'adaptive', 'ica', 'ica', 'represent', 'frontal_cortex', 'interesting', 'variation', 'ica', 'update', 'term', 'signal', 'size', 'act', 'adaptive', 'learning', 'rate', 'source', 'reinforcement', 'learning', 'system', 'critic', 'also', 'reward', 'less', 'expect', 'feature', 'learn', 'ica', 'unit', 'helpful', 'push', 'learn', 'away', 'feature', 'gradient', 'method', 'possible', 'approach', 'base', 'derivative', 'objective', 'function', 'apply', 'hidden_layer', 'weight', 'constrain', 'update_rule', 'information', 'available', 'locally', 'let', 'derivative', 'gradient', 'respect', 'approximate', 'vi', 'ui', 'negating', 'gradient', 'minimization', 'add', 'learn', 'rate', 'remove', 'non', 'local', 'weight', 'information', 'give', 'weight', 'et', 'xt', 'use', 'value', 'weight', 'lead', 'rule', 'non', 'local', 'information', 'cortex', 'unlikely', 'consider', 'weight', 'equal', 'constant', 'avoid', 'neuron', 'move', 'direction', 'uniformly', 'encourage', 'unit', 'hidden_layer', 'minimize', 'covariance', 'achieve', 'add', 'inhibitory', 'neuron', 'let', 'qt', 'average', 'activity', 'time', 'ie', 'inhibitory', 'neuron', 'activity', 'let', 'qt', 'move', 'exponential', 'average', 'qt', 'var', 'qt', 'cov', 'timeaverage', 'qt', 'ignore', 'non_linearity', 'gradient', 'var', 'qt', 'respect', 'weight', 'approximate', 'var', 'combine', 'previous', 'equation', 'result', 'new', 'et', 'xt', 'qt', 'allow', 'different', 'hidden_layer', 'find', 'give', 'much', 'well', 'result', 'gradient', 'ons', 'model', 'section', 'run', 'acrobot', 'task', 'task', 'consist', 'link', 'pendulum', 'torque', 'middle', 'joint', 'goal', 'bring', 'tip', 'second', 'pole', 'totally', 'upright', 'position', 'task', 'acrobot', 'input', 'code', 'use', 'equidistant', 'radial_basis', 'function', 'angle', 'equidistant', 'radial_basis', 'function', 'angular', 'velocity', 'total', 'nonnegative', 'input', 'somewhat', 'simulate', 'input', 'joint', 'angle', 'receptor', 'reward', 'give', 'final', 'state', 'reach', 'case', 'reward', 'action', 'action', 'available', 'actor', 'unit', 'unit', 'torque', 'detail', 'find', 'network', 'different', 'random', 'initialization', 'run', 'model', 'episode', 'episode', 'sequence', 'step', 'network', 'perform', 'achieve', 'goal', 'start', 'position', 'episode', 'limited', 'step', 'number', 'learn', 'rate', 'value', 'try', 'model', 'actor_critic', 'layer', 'learning', 'rate', 'hidden_layer', 'learning', 'rate', 'select', 'parameter', 'one', 'average', 'number', 'step', 'standard_deviation', 'low', 'hidden_layer', 'model', 'get', 'learn', 'rate', 'result', 'figure', 'display', 'learn', 'curve', 'model', 'evaluate', 'variable', 'compare', 'overall', 'learn', 'performance', 'number', 'step', 'success', 'per_episode', 'final', 'performance', 'number', 'step', 'last', 'episode', 'early', 'learn', 'performance', 'number', 'step', 'first', 'episode', 'average', 'learn', 'curve', 'average', 'number', 'step', 'per_episode', 'baseline', 'ica', 'ica', 'step', 'per_episode', 'gradient', 'step', 'baseline', 'gradient', 'ica', 'ica', 'gradient', 'hidden_layer', 'episode', 'figure', 'average', 'number', 'step', 'figure', 'learn', 'curve', 'model', 'episode', 'confidence', 'interval', 'space', 'learning', 'curve', 'figure', 'show', 'average', 'step', 'per_episode', 'model', 'decrease', 'order', 'model', 'need', 'few', 'step', 'average', 'baseline', 'training', 'hidden_layer', 'order', 'assess', 'performance', 'model', 'analysis', 'average', 'number', 'step', 'per_episode', 'episode', 'perform', 'scheff', 'analysis', 'reveal', 'performance', 'model', 'significantly', 'different', 'gradient', 'ica', 'significantly', 'different', 'final', 'performance', 'analysis', 'also', 'use', 'determine', 'final', 'performance', 'model', 'compare', 'number', 'step', 'last', 'episode', 'scheff', 'test', 'result', 'show', 'ica', 'significantly', 'well', 'baseline', 'figure', 'show', 'result', 'last', 'episode', 'increase', 'order', 'curve', 'line', 'top', 'show', 'homogeneous', 'subset', 'number', 'step', 'last', 'episode', 'number', 'step', 'first', 'episode', 'step', 'step', 'per_episode', 'gradient', 'ica', 'gradient', 'ica', 'hidden_layer', 'baseline', 'gradient', 'ica', 'gradient', 'baseline', 'ica', 'hidden_layer', 'figure', 'number', 'step', 'last', 'figure', 'number', 'step', 'first', 'episode', 'confidence', 'interval', 'episode', 'confidence', 'interval', 'early', 'learn', 'figure', 'show', 'model', 'also', 'differ', 'initial', 'learning', 'assess', 'different', 'curve', 'run', 'number', 'step', 'first', 'episode', 'measure', 'gradient', 'ica', 'significantly', 'fast', 'baseline', 'ica', 'significantly', 'slow', 'figure', 'make', 'sense', 'ica', 'slow', 'beginning', 'first', 'stabilize', 'system', 'able', 'learn', 'input', 'ica', 'stabilize', 'system', 'move', 'input', 'hence', 'learn', 'effectively', 'interestingly', 'ica', 'protect', 'effect', 'start', 'significantly', 'fast', 'baseline', 'implie', 'signal', 'control', 'ica', 'learning', 'move', 'synergistically', 'reinforcement', 'learning', 'system', 'external', 'comparison', 'acrobot', 'also', 'run', 'use', 'standard', 'backpropagation', 'greedy', 'policy', 'setup', 'neural', 'network', 'input', 'hidden', 'sigmoidal', 'unit', 'linear', 'output', 'use', 'function', 'approximator', 'network', 'cross', 'connection', 'weight', 'initialize', 'section', 'architecture', 'closely', 'match', 'term', 'power', 'method', 'rh', 'equation', 'use', 'constant', 'target', 'value', 'lhs', 'single', 'gradient', 'apply', 'minimize', 'square', 'error', 'result', 'action', 'different', 'baseline', 'first', 'episode', 'significantly', 'bad', 'overall', 'final', 'performance', 'unable', 'constantly', 'improve', 'common', 'problem', 'use', 'backprop', 'network', 'handcraft', 'necessary', 'complex', 'feature', 'also', 'try', 'sarsa', 'use', 'network', 'action', 'result', 'worst', 'td', 'good', 'result', 'find', 'literature', 'exact', 'task', 'use', 'sarsa', 'linear', 'combination', 'tile', 'tile', 'code', 'discretized', 'input', 'space', 'small', 'hyper', 'cube', 'overlap', 'tiling', 'use', 'available', 'report', 'first', 'trial', 'slow', 'gradient', 'reach', 'well', 'final', 'performance', 'episode', 'final', 'average', 'step', 'episode', 'hand', 'function', 'weight', 'model', 'use', 'weight', 'paper', 'explore', 'new', 'family', 'biologically_plausible', 'reinforcement', 'learning', 'algorithm', 'inspire', 'model', 'basal_ganglia', 'cortex', 'linear', 'actor_critic', 'model', 'basal_ganglia', 'extend', 'variety', 'unsupervised', 'partially', 'supervised', 'learn', 'algorithm', 'inspire', 'brain', 'structure', 'result', 'show', 'pure', 'unsupervised', 'learning', 'slow', 'learn', 'simple', 'quasi', 'local', 'rule', 'hidden_layer', 'greatly', 'improve', 'performance', 'result', 'also', 'demonstrate', 'advantage', 'simple', 'system', 'function', 'approximator', 'backpropagation', 'empirical', 'result', 'indicate', 'strong', 'potential', 'combination', 'present', 'remain', 'test', 'task', 'compare', 'reinforcement', 'learning', 'algorithm', 'possible', 'loop', 'actor', 'unit', 'hidden_layer', 'also', 'consider', 'acknowledgment', 'research', 'support', 'new', 'emerge', 'team', 'grant', 'kalaska', 'yoshua_bengio', 'cihr', 'thank', 'doina', 'precup', 'reference', 'foster', 'dayan', 'structure', 'space', 'value', 'function', 'machine', 'learning', 'tsitsikli', 'feature', 'base', 'method', 'large', 'scale', 'dynamic_programming', 'machine', 'learning', 'sutton', 'rs', 'mcallester', 'singh', 'mansour', 'policy', 'gradient', 'method', 'reinforcement', 'learning', 'function', 'approximation', 'advance', 'neural', 'information_processe', 'system', 'mit_press', 'barto', 'adaptive', 'critic', 'basal_ganglia', 'model', 'information_processe', 'basal_ganglia', 'pp', 'cambridge', 'mit_press', 'suri', 'schultz', 'neural', 'network', 'model', 'dopamine', 'reinforcement', 'signal', 'learn', 'spatial', 'delay', 'response', 'task', 'neuroscience', 'suri', 'schultz', 'temporal_difference', 'model', 'reproduce', 'anticipatory', 'neural', 'activity', 'neural_computation', 'doi', 'inui', 'lee', 'wachtler', 'sejnowski', 'spatiochromatic', 'receptive', 'field', 'property', 'derive', 'information', 'theoritic', 'analysis', 'cone', 'mosaic', 'response', 'natural', 'scene', 'neural_computation', 'sutton', 'rs', 'barto', 'reinforcement', 'learning', 'introduction', 'cambridge', 'mit_press', 'doya', 'computation', 'cerebellum', 'basal_ganglia', 'cerebral', 'cortex', 'neural_network', 'foster', 'morris', 'rgm', 'dayan', 'model', 'hippocampally', 'dependent', 'navigation', 'use', 'temporal_difference', 'learning', 'rule', 'hippocampus', 'wicken', 'ktter', 'cellular', 'model', 'reinforcement', 'model', 'information_processe', 'basal_ganglia', 'pp', 'cambridge', 'mit_press', 'whiteson', 'stone', 'concurrent', 'layer', 'learning', 'proceeding', 'internaltional', 'joint', 'conference', 'autonomous', 'agent', 'multi', 'agent', 'system', 'amari', 'natural', 'gradient', 'learn', 'complete', 'basis', 'ica', 'neural', 'computatio']]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "#remove stop words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "#from bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "#initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser','ner'])\n",
    "\n",
    "#do lemmtization keeping only noun ,adj ,vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN','ADJ','VERB','ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a8eab5f-6b53-4722-895a-8552ec9fc562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 3), (3, 1), (4, 5), (5, 2), (6, 12), (7, 1), (8, 7), (9, 8), (10, 7), (11, 7), (12, 5), (13, 3), (14, 1), (15, 1), (16, 1), (17, 2), (18, 17), (19, 2), (20, 1), (21, 13), (22, 1), (23, 1), (24, 4), (25, 2), (26, 1), (27, 1), (28, 1), (29, 2), (30, 3), (31, 2), (32, 1), (33, 4), (34, 4), (35, 1), (36, 1), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 4), (43, 1), (44, 1), (45, 3), (46, 10), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 4), (53, 1), (54, 2), (55, 19), (56, 6), (57, 10), (58, 1), (59, 1), (60, 1), (61, 2), (62, 1), (63, 1), (64, 2), (65, 2), (66, 1), (67, 5), (68, 1), (69, 1), (70, 1), (71, 1), (72, 3), (73, 1), (74, 2), (75, 1), (76, 1), (77, 3), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 2), (84, 2), (85, 2), (86, 1), (87, 7), (88, 1), (89, 2), (90, 5), (91, 1), (92, 1), (93, 1), (94, 1), (95, 2), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 3), (104, 1), (105, 3), (106, 1), (107, 1), (108, 1), (109, 2), (110, 1), (111, 1), (112, 1), (113, 1), (114, 3), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 12), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 3), (128, 1), (129, 1), (130, 1), (131, 1), (132, 3), (133, 6), (134, 2), (135, 1), (136, 3), (137, 2), (138, 1), (139, 1), (140, 1), (141, 3), (142, 1), (143, 1), (144, 2), (145, 2), (146, 3), (147, 1), (148, 1), (149, 6), (150, 2), (151, 2), (152, 2), (153, 7), (154, 1), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 2), (167, 5), (168, 1), (169, 2), (170, 1), (171, 2), (172, 1), (173, 3), (174, 1), (175, 1), (176, 2), (177, 1), (178, 1), (179, 1), (180, 18), (181, 2), (182, 2), (183, 2), (184, 2), (185, 1), (186, 2), (187, 1), (188, 3), (189, 1), (190, 1), (191, 2), (192, 1), (193, 1), (194, 1), (195, 1), (196, 6), (197, 1), (198, 1), (199, 2), (200, 1), (201, 1), (202, 1), (203, 2), (204, 1), (205, 1), (206, 2), (207, 1), (208, 11), (209, 2), (210, 1), (211, 1), (212, 11), (213, 7), (214, 8), (215, 10), (216, 1), (217, 1), (218, 1), (219, 1), (220, 1), (221, 2), (222, 1), (223, 1), (224, 5), (225, 12), (226, 15), (227, 1), (228, 3), (229, 1), (230, 1), (231, 7), (232, 3), (233, 2), (234, 22), (235, 1), (236, 1), (237, 1), (238, 1), (239, 3), (240, 1), (241, 2), (242, 1), (243, 1), (244, 3), (245, 1), (246, 18), (247, 4), (248, 1), (249, 1), (250, 1), (251, 2), (252, 1), (253, 1), (254, 2), (255, 1), (256, 1), (257, 1), (258, 25), (259, 1), (260, 1), (261, 1), (262, 1), (263, 1), (264, 3), (265, 2), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 5), (272, 3), (273, 2), (274, 3), (275, 1), (276, 2), (277, 1), (278, 17), (279, 4), (280, 1), (281, 1), (282, 2), (283, 2), (284, 1), (285, 1), (286, 1), (287, 3), (288, 2), (289, 2), (290, 1), (291, 1), (292, 1), (293, 3), (294, 2), (295, 1), (296, 2), (297, 1), (298, 2), (299, 2), (300, 1), (301, 1), (302, 2), (303, 6), (304, 14), (305, 2), (306, 36), (307, 35), (308, 1), (309, 2), (310, 9), (311, 1), (312, 1), (313, 1), (314, 10), (315, 2), (316, 2), (317, 2), (318, 3), (319, 3), (320, 1), (321, 1), (322, 2), (323, 4), (324, 1), (325, 1), (326, 1), (327, 3), (328, 2), (329, 1), (330, 2), (331, 1), (332, 1), (333, 1), (334, 1), (335, 3), (336, 1), (337, 1), (338, 1), (339, 1), (340, 1), (341, 1), (342, 5), (343, 1), (344, 2), (345, 3), (346, 4), (347, 1), (348, 40), (349, 2), (350, 1), (351, 3), (352, 1), (353, 1), (354, 1), (355, 1), (356, 2), (357, 4), (358, 1), (359, 1), (360, 1), (361, 1), (362, 1), (363, 2), (364, 1), (365, 1), (366, 4), (367, 1), (368, 2), (369, 1), (370, 1), (371, 8), (372, 5), (373, 2), (374, 1), (375, 3), (376, 2), (377, 7), (378, 3), (379, 1), (380, 1), (381, 7), (382, 1), (383, 9), (384, 2), (385, 1), (386, 1), (387, 1), (388, 14), (389, 1), (390, 1), (391, 1), (392, 2), (393, 1), (394, 1), (395, 1), (396, 1), (397, 1), (398, 1), (399, 5), (400, 1), (401, 1), (402, 1), (403, 1), (404, 1), (405, 2), (406, 1), (407, 1), (408, 1), (409, 4), (410, 2), (411, 1), (412, 1), (413, 3), (414, 1), (415, 1), (416, 1), (417, 6), (418, 3), (419, 10), (420, 1), (421, 1), (422, 1), (423, 1), (424, 1), (425, 1), (426, 1), (427, 5), (428, 1), (429, 2), (430, 3), (431, 2), (432, 1), (433, 2), (434, 1), (435, 1), (436, 6), (437, 3), (438, 1), (439, 1), (440, 1), (441, 7), (442, 1), (443, 2), (444, 2), (445, 1), (446, 1), (447, 1), (448, 1), (449, 1), (450, 1), (451, 2), (452, 1), (453, 1), (454, 1), (455, 1), (456, 7), (457, 1), (458, 2), (459, 2), (460, 2), (461, 7), (462, 1), (463, 2), (464, 1), (465, 1), (466, 6), (467, 2), (468, 1), (469, 1), (470, 1), (471, 1), (472, 2), (473, 1), (474, 3), (475, 1), (476, 25), (477, 2), (478, 1), (479, 1), (480, 2), (481, 5), (482, 2), (483, 1), (484, 2), (485, 4), (486, 2), (487, 2), (488, 1), (489, 11), (490, 1), (491, 10), (492, 1), (493, 1), (494, 1), (495, 1), (496, 3), (497, 2), (498, 2), (499, 14), (500, 4), (501, 2), (502, 2), (503, 1), (504, 2), (505, 2), (506, 2), (507, 2), (508, 1), (509, 2), (510, 1), (511, 1), (512, 1), (513, 1), (514, 1), (515, 1), (516, 1), (517, 1), (518, 8), (519, 2), (520, 14), (521, 7), (522, 2), (523, 4), (524, 4), (525, 1), (526, 1), (527, 1), (528, 4), (529, 1), (530, 2), (531, 3), (532, 1), (533, 1), (534, 2), (535, 3), (536, 1), (537, 1), (538, 1), (539, 1), (540, 2), (541, 2), (542, 1), (543, 2), (544, 7), (545, 22), (546, 1), (547, 1), (548, 1), (549, 1), (550, 2), (551, 4), (552, 1), (553, 3), (554, 1), (555, 1), (556, 1), (557, 1), (558, 1), (559, 2), (560, 1), (561, 1), (562, 2), (563, 1), (564, 1), (565, 1), (566, 2), (567, 2), (568, 1), (569, 1), (570, 11), (571, 3), (572, 1), (573, 11), (574, 2), (575, 1), (576, 1), (577, 4), (578, 2), (579, 3), (580, 1), (581, 1), (582, 1), (583, 2), (584, 1), (585, 2), (586, 1), (587, 6), (588, 1), (589, 1), (590, 1), (591, 2), (592, 2), (593, 1), (594, 2), (595, 3), (596, 1), (597, 2), (598, 1), (599, 3), (600, 1), (601, 1), (602, 2), (603, 1), (604, 1), (605, 1), (606, 12), (607, 2), (608, 1), (609, 6), (610, 1), (611, 4), (612, 1), (613, 1), (614, 1), (615, 1), (616, 18), (617, 3), (618, 2), (619, 6), (620, 3), (621, 1), (622, 1), (623, 1), (624, 1), (625, 6), (626, 1), (627, 1), (628, 2), (629, 1), (630, 1), (631, 1), (632, 2), (633, 1), (634, 1), (635, 1), (636, 22), (637, 4), (638, 1), (639, 1), (640, 3), (641, 4), (642, 3), (643, 1), (644, 1), (645, 3), (646, 1), (647, 2), (648, 1), (649, 1)]]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "#create dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "#create corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "#term document frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "#view\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8068cae6-08ce-4621-9770-9d9ecc12d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build lda model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,id2word=id2word,num_topics=10,random_state=100,chunksize=100,passes=10,per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b634226c-0d8f-4b20-aad7-78c473343eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 3), (3, 1), (4, 5), (5, 2), (6, 12), (7, 1), (8, 7), (9, 8), (10, 7), (11, 7), (12, 5), (13, 3), (14, 1), (15, 1), (16, 1), (17, 2), (18, 17), (19, 2), (20, 1), (21, 13), (22, 1), (23, 1), (24, 4), (25, 2), (26, 1), (27, 1), (28, 1), (29, 2), (30, 3), (31, 2), (32, 1), (33, 4), (34, 4), (35, 1), (36, 1), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 4), (43, 1), (44, 1), (45, 3), (46, 10), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 4), (53, 1), (54, 2), (55, 19), (56, 6), (57, 10), (58, 1), (59, 1), (60, 1), (61, 2), (62, 1), (63, 1), (64, 2), (65, 2), (66, 1), (67, 5), (68, 1), (69, 1), (70, 1), (71, 1), (72, 3), (73, 1), (74, 2), (75, 1), (76, 1), (77, 3), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 2), (84, 2), (85, 2), (86, 1), (87, 7), (88, 1), (89, 2), (90, 5), (91, 1), (92, 1), (93, 1), (94, 1), (95, 2), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 3), (104, 1), (105, 3), (106, 1), (107, 1), (108, 1), (109, 2), (110, 1), (111, 1), (112, 1), (113, 1), (114, 3), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 12), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 3), (128, 1), (129, 1), (130, 1), (131, 1), (132, 3), (133, 6), (134, 2), (135, 1), (136, 3), (137, 2), (138, 1), (139, 1), (140, 1), (141, 3), (142, 1), (143, 1), (144, 2), (145, 2), (146, 3), (147, 1), (148, 1), (149, 6), (150, 2), (151, 2), (152, 2), (153, 7), (154, 1), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 2), (167, 5), (168, 1), (169, 2), (170, 1), (171, 2), (172, 1), (173, 3), (174, 1), (175, 1), (176, 2), (177, 1), (178, 1), (179, 1), (180, 18), (181, 2), (182, 2), (183, 2), (184, 2), (185, 1), (186, 2), (187, 1), (188, 3), (189, 1), (190, 1), (191, 2), (192, 1), (193, 1), (194, 1), (195, 1), (196, 6), (197, 1), (198, 1), (199, 2), (200, 1), (201, 1), (202, 1), (203, 2), (204, 1), (205, 1), (206, 2), (207, 1), (208, 11), (209, 2), (210, 1), (211, 1), (212, 11), (213, 7), (214, 8), (215, 10), (216, 1), (217, 1), (218, 1), (219, 1), (220, 1), (221, 2), (222, 1), (223, 1), (224, 5), (225, 12), (226, 15), (227, 1), (228, 3), (229, 1), (230, 1), (231, 7), (232, 3), (233, 2), (234, 22), (235, 1), (236, 1), (237, 1), (238, 1), (239, 3), (240, 1), (241, 2), (242, 1), (243, 1), (244, 3), (245, 1), (246, 18), (247, 4), (248, 1), (249, 1), (250, 1), (251, 2), (252, 1), (253, 1), (254, 2), (255, 1), (256, 1), (257, 1), (258, 25), (259, 1), (260, 1), (261, 1), (262, 1), (263, 1), (264, 3), (265, 2), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 5), (272, 3), (273, 2), (274, 3), (275, 1), (276, 2), (277, 1), (278, 17), (279, 4), (280, 1), (281, 1), (282, 2), (283, 2), (284, 1), (285, 1), (286, 1), (287, 3), (288, 2), (289, 2), (290, 1), (291, 1), (292, 1), (293, 3), (294, 2), (295, 1), (296, 2), (297, 1), (298, 2), (299, 2), (300, 1), (301, 1), (302, 2), (303, 6), (304, 14), (305, 2), (306, 36), (307, 35), (308, 1), (309, 2), (310, 9), (311, 1), (312, 1), (313, 1), (314, 10), (315, 2), (316, 2), (317, 2), (318, 3), (319, 3), (320, 1), (321, 1), (322, 2), (323, 4), (324, 1), (325, 1), (326, 1), (327, 3), (328, 2), (329, 1), (330, 2), (331, 1), (332, 1), (333, 1), (334, 1), (335, 3), (336, 1), (337, 1), (338, 1), (339, 1), (340, 1), (341, 1), (342, 5), (343, 1), (344, 2), (345, 3), (346, 4), (347, 1), (348, 40), (349, 2), (350, 1), (351, 3), (352, 1), (353, 1), (354, 1), (355, 1), (356, 2), (357, 4), (358, 1), (359, 1), (360, 1), (361, 1), (362, 1), (363, 2), (364, 1), (365, 1), (366, 4), (367, 1), (368, 2), (369, 1), (370, 1), (371, 8), (372, 5), (373, 2), (374, 1), (375, 3), (376, 2), (377, 7), (378, 3), (379, 1), (380, 1), (381, 7), (382, 1), (383, 9), (384, 2), (385, 1), (386, 1), (387, 1), (388, 14), (389, 1), (390, 1), (391, 1), (392, 2), (393, 1), (394, 1), (395, 1), (396, 1), (397, 1), (398, 1), (399, 5), (400, 1), (401, 1), (402, 1), (403, 1), (404, 1), (405, 2), (406, 1), (407, 1), (408, 1), (409, 4), (410, 2), (411, 1), (412, 1), (413, 3), (414, 1), (415, 1), (416, 1), (417, 6), (418, 3), (419, 10), (420, 1), (421, 1), (422, 1), (423, 1), (424, 1), (425, 1), (426, 1), (427, 5), (428, 1), (429, 2), (430, 3), (431, 2), (432, 1), (433, 2), (434, 1), (435, 1), (436, 6), (437, 3), (438, 1), (439, 1), (440, 1), (441, 7), (442, 1), (443, 2), (444, 2), (445, 1), (446, 1), (447, 1), (448, 1), (449, 1), (450, 1), (451, 2), (452, 1), (453, 1), (454, 1), (455, 1), (456, 7), (457, 1), (458, 2), (459, 2), (460, 2), (461, 7), (462, 1), (463, 2), (464, 1), (465, 1), (466, 6), (467, 2), (468, 1), (469, 1), (470, 1), (471, 1), (472, 2), (473, 1), (474, 3), (475, 1), (476, 25), (477, 2), (478, 1), (479, 1), (480, 2), (481, 5), (482, 2), (483, 1), (484, 2), (485, 4), (486, 2), (487, 2), (488, 1), (489, 11), (490, 1), (491, 10), (492, 1), (493, 1), (494, 1), (495, 1), (496, 3), (497, 2), (498, 2), (499, 14), (500, 4), (501, 2), (502, 2), (503, 1), (504, 2), (505, 2), (506, 2), (507, 2), (508, 1), (509, 2), (510, 1), (511, 1), (512, 1), (513, 1), (514, 1), (515, 1), (516, 1), (517, 1), (518, 8), (519, 2), (520, 14), (521, 7), (522, 2), (523, 4), (524, 4), (525, 1), (526, 1), (527, 1), (528, 4), (529, 1), (530, 2), (531, 3), (532, 1), (533, 1), (534, 2), (535, 3), (536, 1), (537, 1), (538, 1), (539, 1), (540, 2), (541, 2), (542, 1), (543, 2), (544, 7), (545, 22), (546, 1), (547, 1), (548, 1), (549, 1), (550, 2), (551, 4), (552, 1), (553, 3), (554, 1), (555, 1), (556, 1), (557, 1), (558, 1), (559, 2), (560, 1), (561, 1), (562, 2), (563, 1), (564, 1), (565, 1), (566, 2), (567, 2), (568, 1), (569, 1), (570, 11), (571, 3), (572, 1), (573, 11), (574, 2), (575, 1), (576, 1), (577, 4), (578, 2), (579, 3), (580, 1), (581, 1), (582, 1), (583, 2), (584, 1), (585, 2), (586, 1), (587, 6), (588, 1), (589, 1), (590, 1), (591, 2), (592, 2), (593, 1), (594, 2), (595, 3), (596, 1), (597, 2), (598, 1), (599, 3), (600, 1), (601, 1), (602, 2), (603, 1), (604, 1), (605, 1), (606, 12), (607, 2), (608, 1), (609, 6), (610, 1), (611, 4), (612, 1), (613, 1), (614, 1), (615, 1), (616, 18), (617, 3), (618, 2), (619, 6), (620, 3), (621, 1), (622, 1), (623, 1), (624, 1), (625, 6), (626, 1), (627, 1), (628, 2), (629, 1), (630, 1), (631, 1), (632, 2), (633, 1), (634, 1), (635, 1), (636, 22), (637, 4), (638, 1), (639, 1), (640, 3), (641, 4), (642, 3), (643, 1), (644, 1), (645, 3), (646, 1), (647, 2), (648, 1), (649, 1)]]\n"
     ]
    }
   ],
   "source": [
    "#create dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "#create corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "#term document frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "#view\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31306196-25cd-4d28-b793-60b4d0bf5550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'able'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3377c9da-20c3-45bc-a1ff-054fe90f4280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('able', 1),\n",
       "  ('abstract', 1),\n",
       "  ('achieve', 3),\n",
       "  ('acknowledgment', 1),\n",
       "  ('acrobot', 5),\n",
       "  ('act', 2),\n",
       "  ('action', 12),\n",
       "  ('activate', 1),\n",
       "  ('activation', 7),\n",
       "  ('activity', 8),\n",
       "  ('actor', 7),\n",
       "  ('actor_critic', 7),\n",
       "  ('adaptive', 5),\n",
       "  ('add', 3),\n",
       "  ('address', 1),\n",
       "  ('advance', 1),\n",
       "  ('advantage', 1),\n",
       "  ('agent', 2),\n",
       "  ('algorithm', 17),\n",
       "  ('allow', 2),\n",
       "  ('already', 1),\n",
       "  ('also', 13),\n",
       "  ('amari', 1),\n",
       "  ('analog', 1),\n",
       "  ('analysis', 4),\n",
       "  ('angle', 2),\n",
       "  ('angular', 1),\n",
       "  ('anticipatory', 1),\n",
       "  ('application', 1),\n",
       "  ('apply', 2),\n",
       "  ('approach', 3),\n",
       "  ('approximate', 2),\n",
       "  ('approximation', 1),\n",
       "  ('approximator', 4),\n",
       "  ('architecture', 4),\n",
       "  ('area', 1),\n",
       "  ('argmax', 1),\n",
       "  ('argue', 1),\n",
       "  ('arise', 1),\n",
       "  ('assess', 2),\n",
       "  ('associate', 1),\n",
       "  ('assume', 1),\n",
       "  ('attempt', 4),\n",
       "  ('autonomous', 1),\n",
       "  ('autonomously', 1),\n",
       "  ('available', 3),\n",
       "  ('average', 10),\n",
       "  ('avoid', 1),\n",
       "  ('away', 1),\n",
       "  ('back', 1),\n",
       "  ('background', 1),\n",
       "  ('backprop', 1),\n",
       "  ('backpropagation', 4),\n",
       "  ('bad', 1),\n",
       "  ('barto', 2),\n",
       "  ('basal_ganglia', 19),\n",
       "  ('base', 6),\n",
       "  ('baseline', 10),\n",
       "  ('basically', 1),\n",
       "  ('basis', 1),\n",
       "  ('begin', 1),\n",
       "  ('beginning', 2),\n",
       "  ('behave', 1),\n",
       "  ('bengioy', 1),\n",
       "  ('biological', 2),\n",
       "  ('biologically_plausible', 2),\n",
       "  ('bit', 1),\n",
       "  ('brain', 5),\n",
       "  ('bring', 1),\n",
       "  ('bt', 1),\n",
       "  ('bti', 1),\n",
       "  ('call', 1),\n",
       "  ('cambridge', 3),\n",
       "  ('canada', 1),\n",
       "  ('case', 2),\n",
       "  ('cellular', 1),\n",
       "  ('centre', 1),\n",
       "  ('cerebellum', 3),\n",
       "  ('cerebral', 1),\n",
       "  ('challenge', 1),\n",
       "  ('cihr', 1),\n",
       "  ('clear', 1),\n",
       "  ('closely', 1),\n",
       "  ('code', 2),\n",
       "  ('combination', 2),\n",
       "  ('combine', 2),\n",
       "  ('common', 1),\n",
       "  ('compare', 7),\n",
       "  ('comparison', 1),\n",
       "  ('complete', 2),\n",
       "  ('complex', 5),\n",
       "  ('complexity', 1),\n",
       "  ('component', 1),\n",
       "  ('compose', 1),\n",
       "  ('computatio', 1),\n",
       "  ('computation', 2),\n",
       "  ('computational', 1),\n",
       "  ('compute', 1),\n",
       "  ('concurrent', 1),\n",
       "  ('concurrently', 1),\n",
       "  ('conditioning', 1),\n",
       "  ('cone', 1),\n",
       "  ('conference', 1),\n",
       "  ('confidence', 3),\n",
       "  ('connection', 1),\n",
       "  ('consider', 3),\n",
       "  ('considerable', 1),\n",
       "  ('consist', 1),\n",
       "  ('consistent', 1),\n",
       "  ('constant', 2),\n",
       "  ('constantly', 1),\n",
       "  ('constrain', 1),\n",
       "  ('construction', 1),\n",
       "  ('contrast', 1),\n",
       "  ('control', 3),\n",
       "  ('converge', 1),\n",
       "  ('convergence', 1),\n",
       "  ('convergent', 1),\n",
       "  ('conversely', 1),\n",
       "  ('correct', 1),\n",
       "  ('correspond', 1),\n",
       "  ('cortex', 12),\n",
       "  ('corticostriatal', 1),\n",
       "  ('cost', 1),\n",
       "  ('cov', 1),\n",
       "  ('covariance', 1),\n",
       "  ('craft', 1),\n",
       "  ('critic', 3),\n",
       "  ('cross', 1),\n",
       "  ('ct', 1),\n",
       "  ('cta', 1),\n",
       "  ('cube', 1),\n",
       "  ('current', 3),\n",
       "  ('curve', 6),\n",
       "  ('da', 2),\n",
       "  ('dashed_line', 1),\n",
       "  ('datum', 3),\n",
       "  ('dayan', 2),\n",
       "  ('decision_making', 1),\n",
       "  ('decrease', 1),\n",
       "  ('delay', 1),\n",
       "  ('demonstrate', 3),\n",
       "  ('dependent', 1),\n",
       "  ('depict', 1),\n",
       "  ('derivative', 2),\n",
       "  ('derive', 2),\n",
       "  ('description', 3),\n",
       "  ('detail', 1),\n",
       "  ('determine', 1),\n",
       "  ('develop', 6),\n",
       "  ('devise', 2),\n",
       "  ('differ', 2),\n",
       "  ('difference', 2),\n",
       "  ('different', 7),\n",
       "  ('difficulty', 1),\n",
       "  ('dinformatique', 1),\n",
       "  ('direction', 1),\n",
       "  ('directly', 1),\n",
       "  ('discount_factor', 1),\n",
       "  ('discounted_reward', 1),\n",
       "  ('discretized', 1),\n",
       "  ('display', 1),\n",
       "  ('distinguish', 1),\n",
       "  ('do', 1),\n",
       "  ('doi', 1),\n",
       "  ('doina', 1),\n",
       "  ('dopamine', 2),\n",
       "  ('dopaminergic', 5),\n",
       "  ('doya', 1),\n",
       "  ('dpartement', 2),\n",
       "  ('dynamic_programming', 1),\n",
       "  ('early', 2),\n",
       "  ('effect', 1),\n",
       "  ('effective', 3),\n",
       "  ('effectively', 1),\n",
       "  ('efficient', 1),\n",
       "  ('emerge', 2),\n",
       "  ('empirical', 1),\n",
       "  ('encourage', 1),\n",
       "  ('environment', 1),\n",
       "  ('episode', 18),\n",
       "  ('equal', 2),\n",
       "  ('equation', 2),\n",
       "  ('equidistant', 2),\n",
       "  ('equipotent', 2),\n",
       "  ('equivalent', 1),\n",
       "  ('error', 2),\n",
       "  ('especially', 1),\n",
       "  ('et', 3),\n",
       "  ('evaluate', 1),\n",
       "  ('evaluated', 1),\n",
       "  ('evidence', 2),\n",
       "  ('exact', 1),\n",
       "  ('exactly', 1),\n",
       "  ('example', 1),\n",
       "  ('exist', 1),\n",
       "  ('expect', 6),\n",
       "  ('explicit', 1),\n",
       "  ('exploration', 1),\n",
       "  ('explore', 2),\n",
       "  ('exponential', 1),\n",
       "  ('extend', 1),\n",
       "  ('external', 1),\n",
       "  ('face', 2),\n",
       "  ('factor', 1),\n",
       "  ('family', 1),\n",
       "  ('fast', 2),\n",
       "  ('favor', 1),\n",
       "  ('feature', 11),\n",
       "  ('feed', 2),\n",
       "  ('few', 1),\n",
       "  ('field', 1),\n",
       "  ('figure', 11),\n",
       "  ('final', 7),\n",
       "  ('find', 8),\n",
       "  ('first', 10),\n",
       "  ('fix', 1),\n",
       "  ('follow', 1),\n",
       "  ('form', 1),\n",
       "  ('formal', 1),\n",
       "  ('formation', 1),\n",
       "  ('foster', 2),\n",
       "  ('francoisriv', 1),\n",
       "  ('franois', 1),\n",
       "  ('frontal', 5),\n",
       "  ('frontal_cortex', 12),\n",
       "  ('function', 15),\n",
       "  ('functional', 1),\n",
       "  ('generate', 3),\n",
       "  ('generic', 1),\n",
       "  ('get', 1),\n",
       "  ('give', 7),\n",
       "  ('goal', 3),\n",
       "  ('good', 2),\n",
       "  ('gradient', 22),\n",
       "  ('grant', 1),\n",
       "  ('greatly', 1),\n",
       "  ('greedy', 1),\n",
       "  ('grow', 1),\n",
       "  ('hand', 3),\n",
       "  ('handcraft', 1),\n",
       "  ('hebbian', 2),\n",
       "  ('help', 1),\n",
       "  ('helpful', 1),\n",
       "  ('hence', 3),\n",
       "  ('hidden', 1),\n",
       "  ('hidden_layer', 18),\n",
       "  ('hidden_unit', 4),\n",
       "  ('high', 1),\n",
       "  ('hippocampal', 1),\n",
       "  ('hippocampally', 1),\n",
       "  ('hippocampus', 2),\n",
       "  ('homogeneous', 1),\n",
       "  ('however', 1),\n",
       "  ('human', 2),\n",
       "  ('hyper', 1),\n",
       "  ('hypothesize', 1),\n",
       "  ('hypothesized', 1),\n",
       "  ('ica', 25),\n",
       "  ('idea', 1),\n",
       "  ('ie', 1),\n",
       "  ('ignore', 1),\n",
       "  ('implementation', 1),\n",
       "  ('implie', 1),\n",
       "  ('important', 3),\n",
       "  ('improve', 2),\n",
       "  ('include', 1),\n",
       "  ('increase', 1),\n",
       "  ('independent', 1),\n",
       "  ('index', 1),\n",
       "  ('indicate', 1),\n",
       "  ('information', 5),\n",
       "  ('information_processe', 3),\n",
       "  ('inhibitory', 2),\n",
       "  ('initial', 3),\n",
       "  ('initialization', 1),\n",
       "  ('initialize', 2),\n",
       "  ('innervation', 1),\n",
       "  ('input', 17),\n",
       "  ('inspire', 4),\n",
       "  ('instead', 1),\n",
       "  ('instrumental', 1),\n",
       "  ('interaction', 2),\n",
       "  ('interest', 2),\n",
       "  ('interesting', 1),\n",
       "  ('interestingly', 1),\n",
       "  ('internaltional', 1),\n",
       "  ('interval', 3),\n",
       "  ('introduce', 2),\n",
       "  ('introduction', 2),\n",
       "  ('inui', 1),\n",
       "  ('involve', 1),\n",
       "  ('john', 1),\n",
       "  ('joint', 3),\n",
       "  ('justification', 2),\n",
       "  ('justify', 1),\n",
       "  ('kalaska', 2),\n",
       "  ('kalaskaj', 1),\n",
       "  ('know', 2),\n",
       "  ('knowledge', 2),\n",
       "  ('known', 1),\n",
       "  ('ktter', 1),\n",
       "  ('large', 2),\n",
       "  ('last', 6),\n",
       "  ('layer', 14),\n",
       "  ('lead', 2),\n",
       "  ('learn', 36),\n",
       "  ('learning', 35),\n",
       "  ('lee', 1),\n",
       "  ('less', 2),\n",
       "  ('let', 9),\n",
       "  ('lhs', 1),\n",
       "  ('limited', 1),\n",
       "  ('line', 1),\n",
       "  ('linear', 10),\n",
       "  ('link', 2),\n",
       "  ('literature', 2),\n",
       "  ('little', 2),\n",
       "  ('lobe', 3),\n",
       "  ('local', 3),\n",
       "  ('locally', 1),\n",
       "  ('loop', 1),\n",
       "  ('low', 2),\n",
       "  ('machine', 4),\n",
       "  ('mailmcgillca', 1),\n",
       "  ('main', 1),\n",
       "  ('mainly', 1),\n",
       "  ('major', 3),\n",
       "  ('make', 2),\n",
       "  ('mammal', 1),\n",
       "  ('mammalian', 2),\n",
       "  ('mansour', 1),\n",
       "  ('many', 1),\n",
       "  ('match', 1),\n",
       "  ('mathematical', 1),\n",
       "  ('matriosome', 3),\n",
       "  ('matrix', 1),\n",
       "  ('mcallester', 1),\n",
       "  ('mean', 1),\n",
       "  ('meaning', 1),\n",
       "  ('measure', 1),\n",
       "  ('memory', 1),\n",
       "  ('method', 5),\n",
       "  ('middle', 1),\n",
       "  ('minimization', 2),\n",
       "  ('minimize', 3),\n",
       "  ('mit_press', 4),\n",
       "  ('mixed', 1),\n",
       "  ('model', 40),\n",
       "  ('modify', 2),\n",
       "  ('monkey', 1),\n",
       "  ('montral', 3),\n",
       "  ('morris', 1),\n",
       "  ('mosaic', 1),\n",
       "  ('mostly', 1),\n",
       "  ('motivating', 1),\n",
       "  ('motor', 2),\n",
       "  ('move', 4),\n",
       "  ('much', 1),\n",
       "  ('multi', 1),\n",
       "  ('multiple', 1),\n",
       "  ('muscle', 1),\n",
       "  ('namely', 1),\n",
       "  ('natural', 2),\n",
       "  ('nature', 1),\n",
       "  ('navigation', 1),\n",
       "  ('necessary', 4),\n",
       "  ('need', 1),\n",
       "  ('negating', 2),\n",
       "  ('negatively', 1),\n",
       "  ('neocortex', 1),\n",
       "  ('network', 8),\n",
       "  ('neural', 5),\n",
       "  ('neural_computation', 2),\n",
       "  ('neural_network', 1),\n",
       "  ('neurological', 3),\n",
       "  ('neurologically', 2),\n",
       "  ('neuron', 7),\n",
       "  ('neurophysiology', 3),\n",
       "  ('neuroscience', 1),\n",
       "  ('nevertheless', 1),\n",
       "  ('new', 7),\n",
       "  ('nigra', 1),\n",
       "  ('non', 9),\n",
       "  ('non_linearity', 2),\n",
       "  ('non_negative', 1),\n",
       "  ('nonnegative', 1),\n",
       "  ('norm', 1),\n",
       "  ('number', 14),\n",
       "  ('objective', 1),\n",
       "  ('observe', 1),\n",
       "  ('obtain', 1),\n",
       "  ('often', 2),\n",
       "  ('one', 1),\n",
       "  ('ons', 1),\n",
       "  ('oppose', 1),\n",
       "  ('oprationnelle', 1),\n",
       "  ('optimist', 1),\n",
       "  ('optimization', 1),\n",
       "  ('order', 5),\n",
       "  ('organization', 1),\n",
       "  ('origin', 1),\n",
       "  ('other', 1),\n",
       "  ('otherwise', 1),\n",
       "  ('output', 1),\n",
       "  ('overall', 2),\n",
       "  ('overcome', 1),\n",
       "  ('overestimate', 1),\n",
       "  ('overlap', 1),\n",
       "  ('paper', 4),\n",
       "  ('parallel', 2),\n",
       "  ('parameter', 1),\n",
       "  ('parietal', 1),\n",
       "  ('part', 3),\n",
       "  ('partially', 1),\n",
       "  ('particularly', 1),\n",
       "  ('pendulum', 1),\n",
       "  ('per_episode', 6),\n",
       "  ('perform', 3),\n",
       "  ('performance', 10),\n",
       "  ('physiologie', 1),\n",
       "  ('plan', 1),\n",
       "  ('plasticity', 1),\n",
       "  ('plausible', 1),\n",
       "  ('play', 1),\n",
       "  ('point', 1),\n",
       "  ('pole', 1),\n",
       "  ('policy', 5),\n",
       "  ('poorly', 1),\n",
       "  ('position', 2),\n",
       "  ('possible', 3),\n",
       "  ('potential', 2),\n",
       "  ('power', 1),\n",
       "  ('pp', 2),\n",
       "  ('precup', 1),\n",
       "  ('predictor', 1),\n",
       "  ('present', 6),\n",
       "  ('previous', 3),\n",
       "  ('primate', 1),\n",
       "  ('principally', 1),\n",
       "  ('prior', 1),\n",
       "  ('problem', 7),\n",
       "  ('proceeding', 1),\n",
       "  ('processing', 2),\n",
       "  ('project', 2),\n",
       "  ('prominent', 1),\n",
       "  ('promote', 1),\n",
       "  ('property', 1),\n",
       "  ('propose', 1),\n",
       "  ('protect', 1),\n",
       "  ('prove', 1),\n",
       "  ('provide', 2),\n",
       "  ('pure', 1),\n",
       "  ('purpose', 1),\n",
       "  ('push', 1),\n",
       "  ('qc', 1),\n",
       "  ('qt', 7),\n",
       "  ('quasi', 1),\n",
       "  ('radial_basis', 2),\n",
       "  ('random', 2),\n",
       "  ('randomly', 2),\n",
       "  ('rate', 7),\n",
       "  ('rather', 1),\n",
       "  ('reach', 2),\n",
       "  ('readily', 1),\n",
       "  ('realistic', 1),\n",
       "  ('receive', 6),\n",
       "  ('recent', 2),\n",
       "  ('receptive', 1),\n",
       "  ('receptor', 1),\n",
       "  ('recherche', 1),\n",
       "  ('record', 1),\n",
       "  ('reduce', 2),\n",
       "  ('reference', 1),\n",
       "  ('region', 3),\n",
       "  ('reinforce', 1),\n",
       "  ('reinforcement', 25),\n",
       "  ('remain', 2),\n",
       "  ('remark', 1),\n",
       "  ('remove', 1),\n",
       "  ('report', 2),\n",
       "  ('represent', 5),\n",
       "  ('reproduce', 2),\n",
       "  ('research', 1),\n",
       "  ('resemble', 2),\n",
       "  ('respect', 4),\n",
       "  ('respectively', 2),\n",
       "  ('response', 2),\n",
       "  ('responsible', 1),\n",
       "  ('result', 11),\n",
       "  ('reveal', 1),\n",
       "  ('reward', 10),\n",
       "  ('rgm', 1),\n",
       "  ('rh', 1),\n",
       "  ('rivest', 1),\n",
       "  ('rivestfr', 1),\n",
       "  ('role', 3),\n",
       "  ('row', 2),\n",
       "  ('rs', 2),\n",
       "  ('rule', 14),\n",
       "  ('run', 4),\n",
       "  ('sarsa', 2),\n",
       "  ('scale', 2),\n",
       "  ('scene', 1),\n",
       "  ('scheff', 2),\n",
       "  ('schultz', 2),\n",
       "  ('second', 2),\n",
       "  ('section', 2),\n",
       "  ('sejnowski', 1),\n",
       "  ('select', 2),\n",
       "  ('selection', 1),\n",
       "  ('send', 1),\n",
       "  ('sense', 1),\n",
       "  ('sensory', 1),\n",
       "  ('sequence', 1),\n",
       "  ('settle', 1),\n",
       "  ('setup', 1),\n",
       "  ('several', 1),\n",
       "  ('show', 8),\n",
       "  ('sigmoidal', 2),\n",
       "  ('signal', 14),\n",
       "  ('significantly', 7),\n",
       "  ('similar', 2),\n",
       "  ('simple', 4),\n",
       "  ('simulate', 4),\n",
       "  ('singh', 1),\n",
       "  ('single', 1),\n",
       "  ('size', 1),\n",
       "  ('slow', 4),\n",
       "  ('small', 1),\n",
       "  ('sn', 2),\n",
       "  ('solve', 3),\n",
       "  ('somewhat', 1),\n",
       "  ('sort', 1),\n",
       "  ('source', 2),\n",
       "  ('space', 3),\n",
       "  ('spatial', 1),\n",
       "  ('spatiochromatic', 1),\n",
       "  ('specific', 1),\n",
       "  ('square', 1),\n",
       "  ('stabilize', 2),\n",
       "  ('standard', 2),\n",
       "  ('standard_deviation', 1),\n",
       "  ('start', 2),\n",
       "  ('state', 7),\n",
       "  ('step', 22),\n",
       "  ('still', 1),\n",
       "  ('stone', 1),\n",
       "  ('storage', 1),\n",
       "  ('striatal', 1),\n",
       "  ('striatum', 2),\n",
       "  ('striosome', 4),\n",
       "  ('strong', 1),\n",
       "  ('structure', 3),\n",
       "  ('subset', 1),\n",
       "  ('substantia', 1),\n",
       "  ('subsystem', 1),\n",
       "  ('succ', 1),\n",
       "  ('success', 1),\n",
       "  ('successful', 2),\n",
       "  ('successfully', 1),\n",
       "  ('sufficient', 1),\n",
       "  ('sum', 2),\n",
       "  ('supervised', 1),\n",
       "  ('supervision', 1),\n",
       "  ('support', 1),\n",
       "  ('suri', 2),\n",
       "  ('sutton', 2),\n",
       "  ('synapse', 1),\n",
       "  ('synergistically', 1),\n",
       "  ('system', 11),\n",
       "  ('take', 3),\n",
       "  ('target', 1),\n",
       "  ('task', 11),\n",
       "  ('td', 2),\n",
       "  ('team', 1),\n",
       "  ('tegmental', 1),\n",
       "  ('temporal_difference', 4),\n",
       "  ('term', 2),\n",
       "  ('test', 3),\n",
       "  ('thank', 1),\n",
       "  ('theoritic', 1),\n",
       "  ('therefore', 1),\n",
       "  ('thus', 2),\n",
       "  ('tightly', 1),\n",
       "  ('tile', 2),\n",
       "  ('tiling', 1),\n",
       "  ('time', 6),\n",
       "  ('timeaverage', 1),\n",
       "  ('tip', 1),\n",
       "  ('top', 1),\n",
       "  ('torque', 2),\n",
       "  ('total', 2),\n",
       "  ('totally', 1),\n",
       "  ('train', 2),\n",
       "  ('training', 3),\n",
       "  ('transform', 1),\n",
       "  ('tri', 2),\n",
       "  ('trial', 1),\n",
       "  ('try', 3),\n",
       "  ('tsitsikli', 1),\n",
       "  ('type', 1),\n",
       "  ('ui', 2),\n",
       "  ('unable', 1),\n",
       "  ('understand', 1),\n",
       "  ('uniformly', 1),\n",
       "  ('unit', 12),\n",
       "  ('universit', 2),\n",
       "  ('unlikely', 1),\n",
       "  ('unsupervised', 6),\n",
       "  ('unxt', 1),\n",
       "  ('update', 4),\n",
       "  ('update_rule', 1),\n",
       "  ('uplink', 1),\n",
       "  ('upright', 1),\n",
       "  ('url_http', 1),\n",
       "  ('use', 18),\n",
       "  ('useful', 3),\n",
       "  ('usually', 2),\n",
       "  ('value', 6),\n",
       "  ('var', 3),\n",
       "  ('variable', 1),\n",
       "  ('variation', 1),\n",
       "  ('variety', 1),\n",
       "  ('vary', 1),\n",
       "  ('vector', 6),\n",
       "  ('velocity', 1),\n",
       "  ('ventral', 1),\n",
       "  ('version', 2),\n",
       "  ('vi', 1),\n",
       "  ('ville', 1),\n",
       "  ('visual', 1),\n",
       "  ('vta', 2),\n",
       "  ('vtzt', 1),\n",
       "  ('wachtler', 1),\n",
       "  ('way', 1),\n",
       "  ('weight', 22),\n",
       "  ('well', 4),\n",
       "  ('whiteson', 1),\n",
       "  ('wicken', 1),\n",
       "  ('win', 3),\n",
       "  ('winner', 4),\n",
       "  ('work', 3),\n",
       "  ('worst', 1),\n",
       "  ('wzt', 1),\n",
       "  ('xt', 3),\n",
       "  ('xtt', 1),\n",
       "  ('yoshua_bengio', 2),\n",
       "  ('yt', 1),\n",
       "  ('ytt', 1)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#human readable format of corpus (term-frequency)\n",
    "[[(id2word[id],freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "033c2d44-6d14-417b-bd37-b0e267bbefb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the lda model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word = id2word,\n",
    "                                            num_topics = 20,\n",
    "                                            random_state=100,\n",
    "                                            update_every = 1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha='auto',\n",
    "                                            per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35b8849b-b0fd-446e-bcc5-4b914064fb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.021*\"agent\" + 0.013*\"mechanism\" + 0.013*\"value\" + 0.009*\"learn\" + '\n",
      "  '0.009*\"model\" + 0.008*\"decision\" + 0.008*\"learning\" + 0.008*\"song\" + '\n",
      "  '0.008*\"system\" + 0.008*\"mdp\"'),\n",
      " (1,\n",
      "  '0.023*\"transformation\" + 0.019*\"model\" + 0.017*\"image\" + 0.010*\"set\" + '\n",
      "  '0.010*\"use\" + 0.010*\"cluster\" + 0.009*\"mean\" + 0.009*\"fig\" + 0.009*\"show\" + '\n",
      "  '0.008*\"mixture\"'),\n",
      " (2,\n",
      "  '0.018*\"policy\" + 0.013*\"despot\" + 0.011*\"algorithm\" + 0.010*\"belief\" + '\n",
      "  '0.009*\"state\" + 0.009*\"sample\" + 0.009*\"value\" + 0.009*\"action\" + '\n",
      "  '0.008*\"distribution\" + 0.007*\"tree\"'),\n",
      " (3,\n",
      "  '0.013*\"distribution\" + 0.013*\"factor\" + 0.011*\"variable\" + 0.008*\"gradient\" '\n",
      "  '+ 0.007*\"network\" + 0.007*\"bit\" + 0.007*\"qsgd\" + 0.006*\"algorithm\" + '\n",
      "  '0.006*\"stochastic\" + 0.006*\"communication\"'),\n",
      " (4,\n",
      "  '0.011*\"bidder\" + 0.010*\"network\" + 0.009*\"depth\" + 0.007*\"image\" + '\n",
      "  '0.007*\"model\" + 0.006*\"use\" + 0.006*\"auction\" + 0.006*\"round\" + '\n",
      "  '0.005*\"scale\" + 0.005*\"bid\"'),\n",
      " (5,\n",
      "  '0.016*\"learn\" + 0.013*\"feature\" + 0.012*\"network\" + 0.009*\"training\" + '\n",
      "  '0.009*\"use\" + 0.008*\"image\" + 0.008*\"learning\" + 0.007*\"correspondence\" + '\n",
      "  '0.007*\"model\" + 0.006*\"performance\"'),\n",
      " (6,\n",
      "  '0.020*\"algorithm\" + 0.011*\"problem\" + 0.009*\"matrix\" + 0.007*\"result\" + '\n",
      "  '0.006*\"set\" + 0.006*\"use\" + 0.006*\"function\" + 0.005*\"follow\" + '\n",
      "  '0.005*\"theorem\" + 0.005*\"give\"'),\n",
      " (7,\n",
      "  '0.009*\"use\" + 0.008*\"model\" + 0.008*\"method\" + 0.007*\"set\" + 0.007*\"error\" '\n",
      "  '+ 0.007*\"function\" + 0.005*\"linear\" + 0.005*\"result\" + 0.005*\"weight\" + '\n",
      "  '0.005*\"datum\"'),\n",
      " (8,\n",
      "  '0.010*\"sample\" + 0.010*\"model\" + 0.009*\"neuron\" + 0.008*\"distribution\" + '\n",
      "  '0.008*\"use\" + 0.007*\"algorithm\" + 0.006*\"give\" + 0.005*\"topic\" + '\n",
      "  '0.005*\"problem\" + 0.005*\"solution\"'),\n",
      " (9,\n",
      "  '0.016*\"learn\" + 0.012*\"distribution\" + 0.011*\"object\" + 0.010*\"action\" + '\n",
      "  '0.010*\"concave_distribution\" + 0.010*\"concave\" + 0.009*\"search\" + '\n",
      "  '0.008*\"log\" + 0.008*\"algorithm\" + 0.008*\"theorem\"'),\n",
      " (10,\n",
      "  '0.001*\"algorithm\" + 0.001*\"model\" + 0.001*\"set\" + 0.001*\"use\" + '\n",
      "  '0.000*\"result\" + 0.000*\"sample\" + 0.000*\"learn\" + 0.000*\"show\" + '\n",
      "  '0.000*\"give\" + 0.000*\"number\"'),\n",
      " (11,\n",
      "  '0.011*\"model\" + 0.010*\"datum\" + 0.009*\"face\" + 0.009*\"use\" + 0.007*\"set\" + '\n",
      "  '0.007*\"image\" + 0.007*\"adaptation\" + 0.006*\"machine\" + 0.006*\"network\" + '\n",
      "  '0.006*\"stimulus\"'),\n",
      " (12,\n",
      "  '0.012*\"model\" + 0.010*\"tree\" + 0.009*\"tensor\" + 0.009*\"dag\" + 0.009*\"time\" '\n",
      "  '+ 0.009*\"node\" + 0.008*\"number\" + 0.008*\"learn\" + 0.007*\"function\" + '\n",
      "  '0.006*\"use\"'),\n",
      " (13,\n",
      "  '0.024*\"network\" + 0.013*\"bayesian\" + 0.013*\"set\" + 0.012*\"pointer\" + '\n",
      "  '0.012*\"node\" + 0.011*\"number\" + 0.009*\"learn\" + 0.009*\"structure\" + '\n",
      "  '0.008*\"dag\" + 0.008*\"graph\"'),\n",
      " (14,\n",
      "  '0.024*\"algorithm\" + 0.017*\"mean\" + 0.015*\"sentence\" + 0.014*\"approximation\" '\n",
      "  '+ 0.013*\"verb\" + 0.010*\"learn\" + 0.010*\"grammatical\" + 0.010*\"language\" + '\n",
      "  '0.010*\"cluster\" + 0.009*\"model\"'),\n",
      " (15,\n",
      "  '0.001*\"model\" + 0.001*\"algorithm\" + 0.000*\"distribution\" + 0.000*\"learn\" + '\n",
      "  '0.000*\"datum\" + 0.000*\"use\" + 0.000*\"set\" + 0.000*\"sample\" + '\n",
      "  '0.000*\"function\" + 0.000*\"show\"'),\n",
      " (16,\n",
      "  '0.011*\"cluster\" + 0.011*\"problem\" + 0.008*\"policy\" + 0.006*\"model\" + '\n",
      "  '0.006*\"optimal\" + 0.006*\"show\" + 0.006*\"set\" + 0.006*\"datum\" + '\n",
      "  '0.006*\"learn\" + 0.006*\"method\"'),\n",
      " (17,\n",
      "  '0.024*\"model\" + 0.008*\"function\" + 0.008*\"network\" + 0.008*\"learn\" + '\n",
      "  '0.007*\"use\" + 0.007*\"image\" + 0.007*\"datum\" + 0.006*\"show\" + 0.006*\"human\" '\n",
      "  '+ 0.005*\"cluster\"'),\n",
      " (18,\n",
      "  '0.014*\"kernel\" + 0.011*\"label\" + 0.009*\"set\" + 0.007*\"algorithm\" + '\n",
      "  '0.007*\"learn\" + 0.007*\"datum\" + 0.007*\"large\" + 0.007*\"sample\" + '\n",
      "  '0.007*\"error\" + 0.006*\"number\"'),\n",
      " (19,\n",
      "  '0.034*\"experiment\" + 0.013*\"policy\" + 0.013*\"schedule\" + 0.013*\"cpe\" + '\n",
      "  '0.012*\"lab\" + 0.012*\"stage\" + 0.011*\"time\" + 0.011*\"number\" + '\n",
      "  '0.008*\"approach\" + 0.007*\"select\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "#print the keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03b9443c-8189-4e27-b423-cbbda5a5ffec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.32418326935807473\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model,texts=data_lemmatized,dictionary=id2word,coherence='c_v')\n",
    "coherence_lda= coherence_model_lda.get_coherence()\n",
    "\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22364f69-4a77-450b-b44f-c97673f6b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#supporting function\n",
    "def compute_coherence_values(corpus,dictionary,k,a,b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,id2word=dictionary,num_topics=k,random_state=100,chunksize=100,passes=10,alpha=a,eta=b)\n",
    "    coherence_model_lda= CoherenceModel(model=lda_model,texts=data_lemmatized,dictionary=id2word,coherence='c_v')\n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47a9ef09-f579-46e3-9ce2-502ebecc9424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 540/540 [25:29:04<00:00, 169.90s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set']  ={}\n",
    "\n",
    "#Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics,max_topics,step_size)\n",
    "\n",
    "#alpha parameter\n",
    "alpha = list(np.arange(0.01,1,0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "#beta parameter\n",
    "beta = list(np.arange(0.01,1,0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "#validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [ gensim.utils.ClippedCorpus(corpus,int(num_of_docs*0.75)),corpus]\n",
    "corpus_title = ['75% Corpus','100% Corpus']\n",
    "\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []}\n",
    "\n",
    "#can take a long time to run\n",
    "if 1==1:\n",
    "    pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)*len(corpus_title)))\n",
    "    \n",
    "    #iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        #iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            #iterate through alpha values\n",
    "            for a in alpha:\n",
    "                #iterate through beta values\n",
    "                for b in beta:\n",
    "                    #get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i],dictionary=id2word,k=k,a=a,b=b)\n",
    "                    #save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv(r'C:\\Users\\Nalin\\Desktop\\lda_tuning_results.csv',index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "768367b8-d328-4d70-ab7c-e92f27630d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 8\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                          id2word=id2word,\n",
    "                                          num_topics=num_topics,\n",
    "                                          random_state=100,\n",
    "                                          chunksize=100,\n",
    "                                          passes=10,\n",
    "                                          alpha=0.01,\n",
    "                                          eta=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e129480e-4a12-40c0-b0e2-c2232d6ed6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.005*\"object\" + 0.004*\"action\" + 0.004*\"search\" + 0.003*\"song\" + '\n",
      "  '0.003*\"window\" + 0.003*\"proposal\" + 0.002*\"iou\" + 0.002*\"syllable\" + '\n",
      "  '0.002*\"recall\" + 0.002*\"learn\"'),\n",
      " (1,\n",
      "  '0.002*\"cell\" + 0.002*\"fire\" + 0.001*\"firing\" + 0.001*\"die\" + 0.001*\"array\" '\n",
      "  '+ 0.001*\"tion\" + 0.001*\"spontaneous\" + 0.000*\"trap\" + 0.000*\"transi\" + '\n",
      "  '0.000*\"neighborhood\"'),\n",
      " (2,\n",
      "  '0.005*\"policy\" + 0.005*\"bidder\" + 0.004*\"despot\" + 0.004*\"belief\" + '\n",
      "  '0.003*\"action\" + 0.003*\"state\" + 0.003*\"auction\" + 0.002*\"rule\" + '\n",
      "  '0.002*\"agent\" + 0.002*\"search\"'),\n",
      " (3,\n",
      "  '0.002*\"wattle\" + 0.001*\"chip\" + 0.001*\"synapse\" + 0.001*\"gain\" + '\n",
      "  '0.001*\"analogue\" + 0.001*\"neuron\" + 0.001*\"jabri\" + 0.001*\"current\" + '\n",
      "  '0.000*\"transient\" + 0.000*\"energy\"'),\n",
      " (4,\n",
      "  '0.010*\"network\" + 0.004*\"learn\" + 0.004*\"model\" + 0.004*\"image\" + '\n",
      "  '0.004*\"layer\" + 0.003*\"error\" + 0.003*\"use\" + 0.003*\"theorem\" + '\n",
      "  '0.003*\"gradient\" + 0.003*\"show\"'),\n",
      " (5,\n",
      "  '0.008*\"learn\" + 0.007*\"network\" + 0.006*\"image\" + 0.006*\"use\" + '\n",
      "  '0.006*\"model\" + 0.005*\"feature\" + 0.004*\"experiment\" + 0.004*\"training\" + '\n",
      "  '0.004*\"policy\" + 0.004*\"learning\"'),\n",
      " (6,\n",
      "  '0.017*\"algorithm\" + 0.008*\"problem\" + 0.006*\"set\" + 0.006*\"matrix\" + '\n",
      "  '0.006*\"result\" + 0.005*\"use\" + 0.005*\"number\" + 0.004*\"give\" + '\n",
      "  '0.004*\"follow\" + 0.004*\"show\"'),\n",
      " (7,\n",
      "  '0.013*\"model\" + 0.008*\"use\" + 0.007*\"function\" + 0.006*\"set\" + '\n",
      "  '0.006*\"learn\" + 0.005*\"datum\" + 0.005*\"method\" + 0.005*\"distribution\" + '\n",
      "  '0.004*\"show\" + 0.004*\"result\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "\n",
    "#print th keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "522bcd3c-06c6-4317-8b8e-3af59fa752a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nalin\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el405216743802863204699360282\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el405216743802863204699360282_data = {\"mdsDat\": {\"x\": [0.1314350013055246, 0.13930859433957302, 0.048845038118157776, 0.026953963382027542, -0.05046598865585931, -0.07900450962790424, -0.10922159440521162, -0.10785050445630762], \"y\": [-0.02000347500422512, 0.053240747717803766, -0.057708449433324586, -0.00914810609082531, 0.037865162958324705, -0.009185600412065557, 0.0032364641522194602, 0.00170325611209275], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [37.96204198464533, 36.30486829311217, 12.529590280230044, 9.028367456043723, 2.5044289407920393, 1.303313168977727, 0.19037646400496222, 0.17701341219399008]}, \"tinfo\": {\"Term\": [\"network\", \"algorithm\", \"image\", \"policy\", \"learn\", \"search\", \"tree\", \"action\", \"object\", \"agent\", \"state\", \"model\", \"feature\", \"neuron\", \"theorem\", \"layer\", \"training\", \"node\", \"train\", \"cell\", \"experiment\", \"learning\", \"rule\", \"optimal\", \"system\", \"auction\", \"good\", \"gradient\", \"round\", \"take\", \"circuit\", \"spike\", \"gp\", \"pg_mean\", \"stimulus\", \"gqm\", \"ica\", \"response\", \"separability\", \"rating\", \"ds_tump\", \"likelihood\", \"resonator\", \"saliency\", \"rank_differentiable\", \"adaptation\", \"spike_triggere\", \"ctm\", \"glm\", \"marginal_likelihood\", \"dbn\", \"reflex\", \"article\", \"bci\", \"mrp\", \"spike_train\", \"competition\", \"deviant\", \"bkm\", \"hidden_unit\", \"subject\", \"neuron\", \"kernel\", \"gaussian\", \"signal\", \"covariance\", \"fit\", \"dynamic\", \"posterior\", \"model\", \"filter\", \"human\", \"optical\", \"nonlinear\", \"weight\", \"mixture\", \"function\", \"estimate\", \"average\", \"process\", \"parameter\", \"distribution\", \"neural\", \"variable\", \"linear\", \"datum\", \"use\", \"system\", \"method\", \"figure\", \"learn\", \"set\", \"show\", \"time\", \"input\", \"sample\", \"value\", \"result\", \"give\", \"different\", \"learning\", \"number\", \"error\", \"example\", \"also\", \"algorithm\", \"problem\", \"tensor\", \"dag\", \"buyer\", \"amp\", \"pv_tree\", \"seller\", \"onmf\", \"recovery\", \"revenue\", \"regret\", \"bandit\", \"price\", \"nnpca\", \"selective_sample\", \"mistake\", \"identifiability\", \"lrsdp\", \"reserve_price\", \"optspace\", \"payment\", \"jungle\", \"tree_width\", \"low_rank\", \"mms\", \"pca\", \"matrix_factorization\", \"mab\", \"query_complexity\", \"mf_lrsdp\", \"gtt\", \"pt\", \"arm\", \"lemma\", \"histogram\", \"algorithm\", \"proof\", \"bound\", \"attribute\", \"partition\", \"margin\", \"definition\", \"matrix\", \"bind\", \"tree\", \"polynomial\", \"problem\", \"entry\", \"theorem\", \"node\", \"let\", \"optimal\", \"agent\", \"decision\", \"follow\", \"guarantee\", \"rank\", \"approximation\", \"result\", \"number\", \"set\", \"log\", \"give\", \"point\", \"section\", \"define\", \"sample\", \"use\", \"first\", \"show\", \"time\", \"datum\", \"value\", \"case\", \"method\", \"function\", \"model\", \"large\", \"learn\", \"error\", \"also\", \"base\", \"cpe\", \"grammatical\", \"kitti\", \"verb\", \"stereo\", \"lab\", \"decentralize\", \"inflow\", \"turbine\", \"chair\", \"ungrammatical\", \"sentence_structure\", \"stl\", \"route\", \"schedule\", \"safe\", \"correspondence\", \"sift\", \"disentangle\", \"scheduler\", \"rat\", \"grammaticality\", \"scheduling\", \"reservoir\", \"transformer\", \"azimuth\", \"depth\", \"pck\", \"convolutional_spatial\", \"selectbatch\", \"water\", \"encoder\", \"discriminative\", \"fine\", \"language\", \"sentence\", \"scene\", \"pose\", \"policy\", \"image\", \"generative\", \"representation\", \"network\", \"experiment\", \"train\", \"feature\", \"learn\", \"control\", \"transformation\", \"training\", \"face\", \"stage\", \"use\", \"learning\", \"model\", \"approach\", \"show\", \"figure\", \"set\", \"scale\", \"task\", \"result\", \"problem\", \"time\", \"well\", \"datum\", \"system\", \"value\", \"method\", \"number\", \"state\", \"concave_distribution\", \"qsgd\", \"houdini\", \"pointer\", \"adversarial_example\", \"lraam\", \"skip_connection\", \"super_resolution\", \"deconvolution\", \"external_field\", \"ssim\", \"attack\", \"thn\", \"isotropic_concave\", \"marmann\", \"interaction_strength\", \"magnetization\", \"concave\", \"raam\", \"opinion\", \"image_restoration\", \"image_denoise\", \"deconvolutional_layer\", \"psnr\", \"gate\", \"alexnet\", \"pulvinar\", \"kontorovich\", \"feedback_alignment\", \"halfspace\", \"quantization\", \"visit\", \"deep\", \"layer\", \"transcription\", \"active\", \"network\", \"compression\", \"gradient\", \"bit\", \"access\", \"adversarial\", \"communication\", \"image\", \"label\", \"theorem\", \"error\", \"loss\", \"learn\", \"sgd\", \"let\", \"distribution\", \"model\", \"show\", \"use\", \"result\", \"system\", \"output\", \"performance\", \"set\", \"different\", \"learning\", \"log\", \"training\", \"function\", \"give\", \"base\", \"despot\", \"hmc\", \"sequential_auction\", \"bidder\", \"opponent\", \"ar_despot\", \"sampled_scenario\", \"equilibria\", \"pomcp\", \"tag\", \"language_rule\", \"music\", \"aki\", \"mdp_assessment\", \"sampler\", \"bne\", \"anytime\", \"aem\", \"pal\", \"wall\", \"hit\", \"online_pomdp\", \"default_policy\", \"slab\", \"ski_aki\", \"parser\", \"weigend\", \"planning\", \"metropolis\", \"particle\", \"belief\", \"parse\", \"pomdps\", \"auction\", \"bid\", \"policy\", \"action\", \"round\", \"equilibrium\", \"rule\", \"agent\", \"search\", \"strategy\", \"scenario\", \"state\", \"tree\", \"node\", \"good\", \"game\", \"entry\", \"value\", \"observation\", \"give\", \"space\", \"unit\", \"time\", \"set\", \"iou\", \"syllable\", \"song\", \"hvc\", \"nucleus\", \"birdsong\", \"object_proposal\", \"syrinx\", \"local_translation\", \"rpn\", \"window\", \"lman\", \"vocalization\", \"vocal\", \"tutor\", \"bird\", \"doupe\", \"songbird\", \"object_localization\", \"proposal\", \"nottebohm\", \"forebrain\", \"konishi\", \"anterior\", \"tree_rl\", \"cnn_resnet\", \"voc_teste\", \"vgg\", \"spectrographic\", \"rvc\", \"resnet\", \"pathway\", \"object\", \"auditory\", \"motor\", \"action\", \"localization\", \"whole\", \"recall\", \"search\", \"template\", \"reinforcement\", \"multiple\", \"agent\", \"evaluation\", \"area\", \"image\", \"propose\", \"level\", \"learn\", \"tree\", \"take\", \"reward\", \"scale\", \"learning\", \"state\", \"step\", \"die\", \"spontaneous\", \"transi\", \"tical\", \"ini\", \"cri\", \"extinction\", \"assist\", \"firing\", \"ime\", \"tial\", \"piriform\", \"trap\", \"inhibition\", \"criticality\", \"shunt\", \"hme\", \"tatory\", \"tative\", \"chover\", \"activi\", \"abstr\", \"quali\", \"neuromodulator\", \"ting\", \"exci\", \"inhibi\", \"ume\", \"mtg\", \"epsp\", \"fire\", \"tion\", \"array\", \"cell\", \"stretch\", \"stimulation\", \"neighborhood\", \"uni\", \"excitatory\", \"efficacy\", \"ultimate\", \"neighbor\", \"activity\", \"phase_transition\", \"bring\", \"phase\", \"time\", \"model\", \"network\", \"wattle\", \"jabri\", \"morphology\", \"dac\", \"talk\", \"coggin\", \"kakadu\", \"capacitor\", \"synapse\", \"transient\", \"analogue\", \"clock\", \"cmos\", \"lsb\", \"cardiac\", \"mume\", \"leong\", \"vlsi\", \"chip\", \"sedalsuozau\", \"defibrillator\", \"implantable\", \"abri\", \"arrythmia\", \"addrus\", \"jiggle\", \"subthreshold\", \"electrogram\", \"pacemaker\", \"marwan\", \"charge\", \"digital\", \"trainable\", \"buffer\", \"gain\", \"switch\", \"synapsis\", \"neuron\", \"energy\", \"current\", \"electrical\", \"connection\", \"network\", \"use\"], \"Freq\": [641.0, 1592.0, 454.0, 247.0, 976.0, 186.0, 268.0, 126.0, 111.0, 166.0, 450.0, 1540.0, 447.0, 208.0, 441.0, 156.0, 426.0, 233.0, 232.0, 56.0, 341.0, 535.0, 118.0, 377.0, 481.0, 69.0, 289.0, 178.0, 77.0, 244.0, 119.21613293071142, 117.2679068393018, 61.68067203107586, 48.3168895230296, 109.77276941448777, 39.46780186054933, 36.133858031187216, 158.27482319811054, 33.61281143056921, 35.910278006047854, 35.89928174023118, 89.03950534921444, 27.61334521918897, 36.51557767366423, 26.415385850466986, 83.91676062174223, 23.194839003626882, 23.177054437597285, 23.161524220843674, 22.32263999229899, 21.491069772708776, 20.654182778247705, 24.991119199029402, 19.833172646915674, 19.83639576950578, 19.803969411539075, 24.972799741572814, 18.967827362434477, 19.67285673312828, 35.70632137969784, 34.42526789041211, 180.11833821210757, 272.73477502150496, 226.43139589203415, 206.33218707383847, 109.12952229928274, 62.544115351834904, 142.65802290346716, 75.14036768856275, 1003.954238969801, 108.63064536459525, 122.1715526921303, 34.55644714329236, 76.0639070941963, 231.65854775298072, 78.25086923306714, 540.1868245697689, 245.19704003424457, 201.40297662473975, 189.7603048490686, 314.8574243922462, 375.256060386694, 154.69267597259662, 248.58282471426892, 281.9949255977918, 429.24261079077263, 595.1720471117667, 275.8951798700433, 392.416809863482, 302.9930091285241, 438.8306199680771, 468.0705309903314, 354.2037622811128, 314.46550737758594, 221.7094753841008, 297.06062702563963, 274.2192663154132, 323.4380562458325, 287.34824755671013, 221.98308267952766, 247.75588715948413, 270.3437506554015, 233.01499568108719, 219.08897570880433, 224.59937668489175, 266.56858338189886, 226.79908898249866, 107.01266242358335, 114.68988718711607, 59.81327001449891, 56.370173676117645, 44.88175340295872, 43.05616470255014, 43.063681948723094, 70.52452470989127, 82.76021721271775, 116.262756785022, 37.25452359557395, 62.530640342237554, 34.27745261076782, 32.47076021228992, 44.86440928941715, 28.82248301071179, 26.358593609197186, 26.347014766815125, 24.59463359375387, 25.87513193286924, 24.487122044370192, 24.369272086041292, 113.70443417391704, 24.17578642446924, 22.80870583146283, 30.655913884990056, 21.966210027537187, 21.965134253406127, 21.941858013941847, 21.083098261520504, 84.63056250789325, 63.46224317607611, 148.1390156715419, 64.26485849614318, 1257.909980366897, 175.63636449852896, 201.68518565350135, 47.94789409490179, 99.18345053444857, 114.17680000849319, 110.27396171564514, 423.25418998084547, 176.8117421413805, 203.0214464153816, 69.76673184831341, 611.9214021379877, 81.43467906482954, 300.9995293587536, 171.6533656647151, 304.69660938310585, 249.41555382818802, 124.26590159203246, 123.09369418968144, 310.2778133933408, 149.87070465851082, 164.59855307700988, 207.33067265671068, 416.26466151469367, 354.0045805618751, 454.3433422584448, 237.44154667592795, 328.91917880953173, 222.58125070277876, 207.2273456491511, 206.4774125251022, 293.57206861204924, 411.9176909695663, 240.12738145342468, 307.96467946582106, 281.85197928203786, 298.80635522413405, 260.95944452827626, 224.26896028690405, 265.51303396120426, 277.52246701423735, 305.55255675458454, 217.19317669001538, 246.20769196949357, 221.55279306982624, 219.38039674413807, 213.03916050576672, 34.88171947923549, 39.44135524904279, 21.38198386348956, 50.860423694903666, 21.35759351545334, 34.791471403003804, 21.245313052138783, 20.642153914184345, 19.975358623071468, 18.70074888806024, 17.342336069063233, 16.00767713049293, 15.398030569118603, 34.68960324670117, 36.14188291490971, 14.035295831973148, 59.10332176738418, 12.708529849460419, 12.645114186866708, 12.692090042646443, 19.98033064742107, 12.659146782257539, 16.35493082744851, 17.287349813797977, 12.035925276011609, 11.9773005475786, 59.38126414166311, 11.36594840455067, 11.36420645331938, 11.345567044754885, 29.271127177002974, 27.372971640344772, 59.73831640900715, 29.373989435095712, 40.138896471892664, 56.86336797042342, 38.03018835761106, 46.95679812102603, 107.8309849339627, 168.58263051647992, 48.816823186277745, 76.50868631457867, 181.7298691544871, 116.64832836281391, 89.2086761325785, 133.43778623507473, 199.720626300936, 68.13037824277386, 60.08377284266537, 110.38554770110697, 65.07874639578758, 35.525209448046475, 151.54869634300832, 96.37381632467674, 145.11267525958652, 80.83318670304442, 92.00444193894174, 77.66502066755329, 92.71357596467928, 57.457374097993345, 57.69661318001722, 78.30547680742556, 78.62746880187952, 72.18960499318825, 64.18070272194844, 65.73128935864443, 62.05385224999739, 62.65809641368615, 62.342620635234425, 61.35733240612089, 60.80481790509534, 40.48194045889996, 32.51360653112065, 26.150647185697927, 32.08660717393557, 22.128967663396377, 20.032802501219127, 18.933820158885467, 17.79123440843329, 14.907250922531162, 14.899221876655787, 12.591120696119036, 19.30849149533891, 10.825582317909287, 10.752216952170855, 15.137839485653773, 9.71777490434419, 12.599724103225263, 44.93199955244704, 8.549410052906184, 15.476223422062272, 10.301054021454405, 10.302854632993709, 8.001529495457046, 7.999389290110148, 7.9552333595908475, 7.369754526321793, 7.376246118560212, 9.206730993516263, 10.152020385346619, 16.0715455620148, 23.890243101976388, 18.75354716830351, 48.828138560089016, 73.49386541456653, 10.746283342040734, 45.75754663900151, 186.99819715340962, 20.461734594865433, 59.6439152432967, 37.608326049515256, 27.626279462489403, 28.031503322211307, 28.781274036187572, 74.29644241965298, 56.83118312438219, 60.59863027418543, 65.52519516880413, 44.94033761776791, 81.63940834506893, 25.147275241412387, 51.797909338273605, 57.45596584609966, 77.05801489524461, 58.35606196298237, 64.3847627269969, 56.19839428756092, 47.07449797650161, 39.01665978756185, 41.19144473799246, 52.95217886281344, 42.10000121764444, 43.95845508227163, 39.60608107562936, 39.21602209950833, 41.70843099448254, 38.7181666581599, 37.74868421037758, 21.089404570150673, 10.937374202233785, 8.762225320350987, 24.852511856451127, 7.660566345697186, 5.448768416049952, 5.176934704232668, 8.449090626991012, 4.349993955354369, 3.5276163906386837, 3.527124784405964, 3.2392110355730375, 2.988806569686879, 2.9873856671374717, 4.9664814987721355, 2.712840397097571, 2.7051016123534217, 2.705183698175398, 4.06721980883616, 4.33196960508683, 6.288001138144515, 2.4309143697732103, 2.429504068713726, 2.4032223693949426, 2.1637437990235284, 2.1556368396793357, 2.1434739017404216, 8.459410420181868, 5.092840051366112, 6.3382715859615715, 18.485322434976464, 8.158795783521358, 5.418197959707708, 13.24518770581653, 11.72696711371186, 25.402904865292907, 16.31716871904464, 12.079639306490748, 7.366977164958857, 12.351766831028758, 12.300491967766416, 12.14867620886996, 10.118405470877944, 8.455232221553318, 13.841751111972538, 11.250297471594724, 10.128210940357672, 9.965599835722383, 6.725033323937749, 7.615546967288895, 9.484962813176312, 7.313223976252207, 8.06925196483433, 7.680750370911916, 7.094048167782661, 7.5448986384413725, 7.396319665868295, 6.06103819836943, 5.211652934799953, 7.767707250542919, 2.6854237951123925, 2.8558795391551532, 2.1781918289247977, 2.172116610329843, 2.008818687858352, 2.0031296628120243, 2.5062158018476013, 7.52069155164019, 1.8395057614594879, 1.8391392716633417, 1.6705077798402796, 1.6701715550079443, 3.6815783701621774, 1.3316106457783934, 1.331496994534083, 1.4961142802717005, 7.496710350940622, 1.1620408612621873, 1.162198648912055, 0.993398492967756, 0.9931915247516957, 0.9891623438143655, 0.9891046512271012, 0.9889510407727595, 2.3123613000286096, 0.8241821149560487, 0.8239567828426761, 2.5106149404415143, 2.128226580493475, 13.428891052245092, 3.337359804260249, 4.083533344473928, 11.35488730701903, 1.9677015277011267, 4.205268801982123, 4.7589101986133135, 10.318114313194817, 2.1958664101602747, 3.284027893865016, 3.8302474386416914, 4.301958740896738, 3.1011509042582466, 2.90177036683345, 4.312420014793958, 3.69157179816049, 3.2705893041529093, 4.3836694142852535, 3.5886053471155743, 3.4450192162560733, 2.890730275503348, 3.162836259925295, 3.0409961360839204, 2.9529676514999035, 2.8855827095751976, 0.2791855410846698, 0.2031380040919477, 0.17941257367966176, 0.12830413688042153, 0.1281432828363234, 0.12801720835615457, 0.15307172236241084, 0.16670728007726685, 0.3398595898126497, 0.15187822265602594, 0.10209924936654872, 0.1018400316699474, 0.1856554305730764, 0.10165457520012368, 0.07657032414864084, 0.07655534625632968, 0.07651736618966208, 0.07646460394487953, 0.07645392025228555, 0.0763496794175957, 0.07631740384411809, 0.07630712309251635, 0.07629078671343137, 0.07628024692833461, 0.07626667932949624, 0.07621350838742158, 0.0761951860848749, 0.07615380980127279, 0.07612867779595743, 0.07604069275215411, 0.6032251840131866, 0.24737109327857007, 0.2598622640376941, 0.7388417673819971, 0.1251739876393824, 0.12521124241226397, 0.16932919408850663, 0.08854768182337308, 0.12153704224351615, 0.09499550904323512, 0.08550093561142562, 0.09757000841228924, 0.10786323967219766, 0.10243971147978335, 0.08821539365598083, 0.09595953961084504, 0.12323534642496657, 0.11363977871160462, 0.1042419514120295, 0.603250170772542, 0.2166077104985082, 0.16140357349110637, 0.16131652450945175, 0.1338423372968646, 0.13381059845886584, 0.13376145410633553, 0.16129476226403808, 0.3591588959207765, 0.18112486711071557, 0.31042801534883185, 0.15731028031662075, 0.10628373440924938, 0.10627687282572248, 0.10626714243660246, 0.1062244636011552, 0.10621943248686873, 0.16132915581766036, 0.5041411157662733, 0.07877856302580644, 0.07877535167626187, 0.07877332852604879, 0.07877024563048601, 0.07876869347820614, 0.078756072874496, 0.07875410324677534, 0.07875338069312782, 0.07875344492011871, 0.07875230489103038, 0.07875094006747395, 0.10602514583942263, 0.16230867095124468, 0.10632549265782718, 0.1339006554045939, 0.3267717292669523, 0.15586128728861817, 0.1166899092229367, 0.29507618026004234, 0.17230286173185994, 0.18488985331676197, 0.11231227245527692, 0.11821673465940101, 0.1199546849194234, 0.10980626372468123], \"Total\": [641.0, 1592.0, 454.0, 247.0, 976.0, 186.0, 268.0, 126.0, 111.0, 166.0, 450.0, 1540.0, 447.0, 208.0, 441.0, 156.0, 426.0, 233.0, 232.0, 56.0, 341.0, 535.0, 118.0, 377.0, 481.0, 69.0, 289.0, 178.0, 77.0, 244.0, 124.53864100875867, 122.96199183051165, 64.79147389829001, 50.90864945962495, 115.68443293410323, 42.17347629132965, 38.700363691013656, 169.93678290717375, 36.11020750375304, 38.77922059639719, 38.78609102763432, 96.59804936399948, 30.084779134312342, 39.96056082283212, 29.22654522760568, 92.8945191235318, 25.710133079154954, 25.71276702607308, 25.706919910019177, 24.828734578956347, 23.96228559831299, 23.110863228163268, 28.06993285592229, 22.282645991790478, 22.288149651386384, 22.26622829386725, 28.08787161599332, 21.411531844822147, 22.22345657741731, 40.39075981598244, 38.973263453103606, 208.90005380026724, 321.66572929283996, 266.20187344449874, 243.71236994499552, 128.68486726314137, 73.47262039276919, 176.83241202008844, 89.6586418525889, 1540.6655618432799, 137.39767477379854, 159.1547609288003, 39.74968005871416, 95.74639896775294, 338.70232158072844, 99.23694907178735, 917.556791280371, 372.5431024249612, 298.29989727769015, 280.0196027799607, 514.7691685089674, 647.4675528943598, 222.93251515911498, 397.8990667179766, 470.7605430044984, 807.4581951794561, 1231.7989442850353, 481.18735481603983, 761.5893104380009, 565.4983205464449, 976.4619144645385, 1078.3596220077204, 816.5447195030472, 703.4655984813827, 404.2929243640451, 664.1457754105498, 628.4619548927872, 880.323854837019, 707.9183912951277, 426.36983499015884, 535.768041862193, 717.3113843523663, 565.8567637347423, 462.0747586557826, 534.1480840176033, 1592.5270359389185, 946.3499411678598, 110.65968602357576, 118.84879069985668, 62.454894769939955, 58.948860366843384, 47.41930497662991, 45.630408517832386, 45.654825491209536, 74.84749623502034, 88.16616563342606, 124.52542463586778, 39.9387678699646, 67.10839498400406, 36.80338674157222, 35.02836449911453, 48.78852707799469, 31.479634710251045, 28.822600220895346, 28.82631308668148, 27.055662818987926, 28.494396547300262, 26.975723092091666, 26.982106523261887, 125.92488522123146, 26.77968922746665, 25.29226824513599, 34.00971281089246, 24.402436034324676, 24.405373722404583, 24.395105049013782, 23.524708734461967, 95.27652649483242, 71.43958669134321, 171.30345299178015, 73.6421804846904, 1592.5270359389185, 208.93727192583418, 248.13677977463, 54.96202848378387, 119.3840815660065, 140.87969541289985, 136.08902079449746, 587.9909780557624, 230.1162234556461, 268.9371279741129, 83.3725558253175, 946.3499411678598, 99.2233914807642, 441.26864236911695, 233.184767112637, 476.63649305593094, 377.38016845137906, 166.06389975414862, 165.73057843670097, 528.3827162841791, 213.02645147882825, 245.62118840958692, 333.23432835189726, 880.323854837019, 717.3113843523663, 1078.3596220077204, 429.65555940530555, 707.9183912951277, 402.2752569401312, 369.10610479596374, 375.56158999121055, 664.1457754105498, 1231.7989442850353, 495.4635269743053, 816.5447195030472, 703.4655984813827, 807.4581951794561, 628.4619548927872, 468.7226274395924, 761.5893104380009, 917.556791280371, 1540.6655618432799, 502.52958971956156, 976.4619144645385, 565.8567637347423, 534.1480840176033, 508.4537550238433, 37.61469437992882, 43.217434731638974, 24.084952708048807, 57.335884250349736, 24.08009991835386, 39.383973187812735, 24.155674947181186, 23.483320085025447, 22.8026670086835, 21.528250958246357, 20.054943931237844, 18.708427770309008, 18.033079955145475, 40.78872660519763, 42.52641567073986, 16.68758325827068, 70.65995674677129, 15.326356873374879, 15.262724585236779, 15.334470996983864, 24.182611046417247, 15.323062095944403, 19.821690609522566, 20.96353889745555, 14.64989273918942, 14.592969193899101, 72.97201217526187, 13.977152218489676, 13.975573827637005, 13.982103418549384, 36.62893641927522, 35.26934373282005, 82.50312327151839, 38.49581717342844, 57.35791633030412, 85.31410343183217, 61.786751621607465, 83.5898023140574, 247.65840009263636, 454.77459204384576, 91.75685160073101, 175.6348108091059, 641.6903085256138, 341.0621833026783, 232.5991775940196, 447.81319667881974, 976.4619144645385, 175.736345039008, 145.4001063723132, 426.5707135402634, 182.7333711494578, 64.54442271971898, 1231.7989442850353, 535.768041862193, 1540.6655618432799, 460.6317911317142, 816.5447195030472, 565.4983205464449, 1078.3596220077204, 247.29663899060085, 251.94402862521432, 880.323854837019, 946.3499411678598, 703.4655984813827, 462.71751372943265, 807.4581951794561, 481.18735481603983, 628.4619548927872, 761.5893104380009, 717.3113843523663, 450.21374986951344, 43.74868682111551, 35.42403938271755, 29.167755320249423, 35.859435912496124, 25.12120902215907, 22.835237313361265, 21.678398521401604, 20.524233418102064, 17.631869570516415, 17.635294630227005, 15.311759410509774, 23.976845494603026, 13.558253202288636, 13.628176096603939, 19.263360848645064, 12.43039548583628, 16.551323219994504, 59.1667857578269, 11.268389170988108, 20.412578055077976, 13.677220613145714, 13.74171353798872, 10.689336929899099, 10.689387640863714, 10.70233607854521, 10.084002080135711, 10.126300168970467, 12.689341379814497, 13.99532146779587, 22.282236947360715, 33.23444770584694, 28.11938085424553, 91.94083815513869, 156.75844337565718, 15.318783612494174, 93.10976342487692, 641.6903085256138, 36.00045669170661, 178.69268301977598, 97.88284130365602, 62.37817363900733, 63.878625440464624, 72.46977207715729, 454.77459204384576, 341.8588438652308, 441.26864236911695, 565.8567637347423, 237.3300864716836, 976.4619144645385, 69.49598771090758, 476.63649305593094, 647.4675528943598, 1540.6655618432799, 816.5447195030472, 1231.7989442850353, 880.323854837019, 481.18735481603983, 265.9486551962112, 358.2543740551691, 1078.3596220077204, 426.36983499015884, 535.768041862193, 429.65555940530555, 426.5707135402634, 917.556791280371, 707.9183912951277, 508.4537550238433, 24.49738845330218, 14.202683234628209, 11.883365888193136, 34.91490968483234, 10.764344332780619, 8.52504898990257, 8.242159392301428, 14.049851987356051, 7.406037316250403, 6.563612950819898, 6.584879160081907, 6.318840460551856, 5.994693025829428, 5.997438046434284, 10.456483033297808, 5.716454398798224, 5.722964111327446, 5.723764963148025, 8.755875686320778, 9.49194298718301, 13.98370924211028, 5.442629745990787, 5.445093080361399, 5.513335619692408, 5.156026070946811, 5.1746990986037895, 5.191198753553722, 21.078669005803352, 12.782035111469952, 16.22303462570443, 56.35909784717391, 25.614248410986495, 16.18762976095446, 69.3037862118437, 61.14760120907656, 247.65840009263636, 126.29086981381316, 77.11191547235923, 35.89212610951667, 118.92752713236908, 166.06389975414862, 186.35716681655416, 118.41813579764583, 84.67224184465329, 450.21374986951344, 268.9371279741129, 233.184767112637, 289.08305625378966, 46.93209619622795, 99.2233914807642, 628.4619548927872, 158.03810165098895, 707.9183912951277, 325.41883581506806, 118.431387751455, 703.4655984813827, 1078.3596220077204, 10.444221836557702, 10.691626684268702, 16.50477232156777, 5.810465152221304, 6.861812692523332, 5.286913417757921, 5.290101663576077, 5.11207408418471, 5.116662471425828, 6.513137454307873, 19.702362175170077, 4.937946798269114, 4.940474436260444, 4.764064992809911, 4.764104599986153, 11.84372271306053, 4.417418280325977, 4.4175821752304225, 5.172608993879723, 27.231333002133752, 4.243078565129881, 4.243735720089957, 4.067487454892372, 4.0687519726977985, 4.071225036655192, 4.071234219311467, 4.072430042373448, 9.787128011041691, 3.89385237240888, 3.8940804900306403, 13.143669610052626, 11.447619440439194, 111.2609174040283, 20.16750729513036, 27.694258848505797, 126.29086981381316, 10.757842327243484, 35.06454613549032, 44.819302217327945, 186.35716681655416, 15.639333603438939, 58.4151144981855, 98.42787567995295, 166.06389975414862, 73.2880251281733, 58.903212935937574, 454.77459204384576, 274.1398631527917, 138.25024851257223, 976.4619144645385, 268.9371279741129, 244.28314019544396, 73.39137520210707, 247.29663899060085, 535.768041862193, 450.21374986951344, 261.55390062503966, 5.806023657017967, 4.355558405365007, 4.145985222061409, 3.8298885048840243, 3.8345975397110394, 3.838301012331857, 4.684967957539373, 5.262309199812261, 10.961398020258065, 4.923010410311463, 3.6904267654600336, 3.698184184767841, 7.712587131304754, 4.508878978590387, 3.5322281487322167, 3.532489061681053, 3.533731915801997, 3.535105739785982, 3.5355399602859823, 3.5386030677098104, 3.5394826562006636, 3.539643203179544, 3.5399703998450116, 3.540207868072765, 3.5407550445982925, 3.5423717919688777, 3.5425851280623655, 3.543750096059033, 3.544596678237591, 3.5469473108387057, 33.49551741068668, 13.448951675551776, 14.531398294936244, 56.80048224347148, 6.699198137464609, 6.946629194056921, 13.988209957137986, 4.934019570240985, 12.692245938701664, 10.478094063545589, 6.369734533281217, 12.827059759158463, 47.23772725061177, 33.55157679742713, 10.939937810946743, 32.2774226756443, 703.4655984813827, 1540.6655618432799, 641.6903085256138, 4.04386547179768, 3.5001108473700775, 3.4216471180457075, 3.4237194786217584, 3.381408601786621, 3.3819354179577052, 3.383047042074511, 4.114052629781587, 9.509083193186038, 5.308490939986899, 9.376317765713951, 4.786894840853906, 3.340129940738163, 3.340671188865462, 3.3407717705111466, 3.3423727556725673, 3.34240184091999, 5.187854227501203, 20.92640524367745, 3.298318337718956, 3.298337501871879, 3.298626165367555, 3.298669862493791, 3.2987646514648388, 3.2987201610009853, 3.2989756777885795, 3.2990341712419444, 3.2990501535717573, 3.299154025390192, 3.2993696569042683, 4.71112222675962, 11.225926298708684, 5.674008506586227, 10.192821818541807, 77.4160737149881, 15.001254558546526, 8.453204032840903, 208.90005380026724, 63.729646257329236, 120.29843121473071, 14.885567540358913, 57.73839862930911, 641.6903085256138, 1231.7989442850353], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.4947, -6.5112, -7.1537, -7.3979, -6.5773, -7.6002, -7.6884, -6.2113, -7.7608, -7.6946, -7.6949, -6.7866, -7.9574, -7.6779, -8.0017, -6.8458, -8.1317, -8.1325, -8.1332, -8.1701, -8.208, -8.2477, -8.0571, -8.2883, -8.2881, -8.2898, -8.0579, -8.3329, -8.2964, -7.7003, -7.7369, -6.0821, -5.6672, -5.8532, -5.9462, -6.5831, -7.1398, -6.3152, -6.9563, -4.364, -6.5877, -6.4702, -7.7331, -6.9441, -5.8304, -6.9157, -4.9838, -5.7736, -5.9704, -6.0299, -5.5235, -5.3481, -6.2342, -5.7599, -5.6338, -5.2136, -4.8868, -5.6556, -5.3033, -5.562, -5.1916, -5.127, -5.4058, -5.5248, -5.8743, -5.5817, -5.6617, -5.4967, -5.615, -5.8731, -5.7632, -5.676, -5.8246, -5.8862, -5.8613, -5.69, -5.8516, -6.5581, -6.4888, -7.1398, -7.1991, -7.427, -7.4685, -7.4684, -6.9751, -6.8151, -6.4752, -7.6133, -7.0954, -7.6965, -7.7507, -7.4274, -7.8699, -7.9592, -7.9597, -8.0285, -7.9777, -8.0329, -8.0377, -6.4974, -8.0457, -8.1039, -7.8082, -8.1415, -8.1416, -8.1426, -8.1826, -6.7927, -7.0806, -6.2329, -7.068, -4.0938, -6.0626, -5.9243, -7.3609, -6.6341, -6.4933, -6.5281, -5.1831, -6.0559, -5.9177, -6.9859, -4.8144, -6.8312, -5.5239, -6.0856, -5.5117, -5.7119, -6.4086, -6.4181, -5.4936, -6.2213, -6.1275, -5.8967, -5.1997, -5.3617, -5.1122, -5.7611, -5.4352, -5.8257, -5.8972, -5.9008, -5.5489, -5.2102, -5.7499, -5.501, -5.5896, -5.5312, -5.6667, -5.8182, -5.6494, -5.6051, -5.5089, -5.8502, -5.7249, -5.8304, -5.8402, -5.8696, -6.6152, -6.4924, -7.1046, -6.2381, -7.1058, -6.6178, -7.111, -7.1398, -7.1727, -7.2386, -7.314, -7.3941, -7.4329, -6.6207, -6.5797, -7.5256, -6.0879, -7.6249, -7.6299, -7.6262, -7.1724, -7.6288, -7.3726, -7.3172, -7.6793, -7.6842, -6.0832, -7.7366, -7.7367, -7.7383, -6.7906, -6.8576, -6.0772, -6.7871, -6.4748, -6.1265, -6.5288, -6.3179, -5.4866, -5.0397, -6.2791, -5.8298, -4.9647, -5.408, -5.6762, -5.2735, -4.8703, -5.9457, -6.0714, -5.4632, -5.9916, -6.5969, -5.1463, -5.5989, -5.1897, -5.7748, -5.6453, -5.8148, -5.6377, -6.1161, -6.112, -5.8066, -5.8025, -5.8879, -6.0055, -5.9816, -6.0392, -6.0295, -6.0345, -6.0505, -6.0595, -6.1386, -6.3578, -6.5756, -6.371, -6.7426, -6.8421, -6.8985, -6.9607, -7.1376, -7.1381, -7.3065, -6.8789, -7.4575, -7.4643, -7.1223, -7.5655, -7.3058, -6.0343, -7.6936, -7.1001, -7.5072, -7.507, -7.7598, -7.7601, -7.7656, -7.8421, -7.8412, -7.6195, -7.5218, -7.0624, -6.666, -6.9081, -5.9511, -5.5422, -7.4649, -6.0161, -4.6084, -6.8209, -5.7511, -6.2122, -6.5207, -6.5061, -6.4797, -5.5314, -5.7994, -5.7352, -5.657, -6.0341, -5.4371, -6.6147, -5.8921, -5.7884, -5.4949, -5.7729, -5.6746, -5.8106, -5.9877, -6.1755, -6.1212, -5.8701, -6.0994, -6.0562, -6.1605, -6.1704, -6.1087, -6.1831, -6.2085, -5.5084, -6.165, -6.3867, -5.3442, -6.5211, -6.8618, -6.9129, -6.4231, -7.087, -7.2965, -7.2967, -7.3818, -7.4623, -7.4627, -6.9544, -7.5591, -7.562, -7.562, -7.1542, -7.0911, -6.7185, -7.6689, -7.6695, -7.6803, -7.7853, -7.7891, -7.7947, -6.4219, -6.9293, -6.7105, -5.6402, -6.458, -6.8674, -5.9735, -6.0952, -5.3223, -5.7649, -6.0656, -6.5601, -6.0433, -6.0475, -6.0599, -6.2428, -6.4224, -5.9295, -6.1367, -6.2418, -6.258, -6.6513, -6.5269, -6.3074, -6.5675, -6.4691, -6.5184, -6.5979, -6.5363, -6.5562, -6.1021, -6.2531, -5.854, -6.9162, -6.8546, -7.1255, -7.1283, -7.2064, -7.2093, -6.9852, -5.8863, -7.2945, -7.2947, -7.3909, -7.3911, -6.6006, -7.6176, -7.6177, -7.5011, -5.8895, -7.7538, -7.7537, -7.9106, -7.9108, -7.9149, -7.9149, -7.9151, -7.0657, -8.0974, -8.0976, -6.9835, -7.1487, -5.3066, -6.6988, -6.497, -5.4743, -7.2271, -6.4677, -6.344, -5.5701, -7.1174, -6.7149, -6.5611, -6.4449, -6.7722, -6.8387, -6.4425, -6.5979, -6.719, -6.4261, -6.6262, -6.6671, -6.8425, -6.7525, -6.7918, -6.8212, -6.8443, -7.2562, -7.5742, -7.6984, -8.0337, -8.0349, -8.0359, -7.8572, -7.7718, -7.0596, -7.865, -8.2621, -8.2647, -7.6642, -8.2665, -8.5499, -8.5501, -8.5506, -8.5513, -8.5514, -8.5528, -8.5532, -8.5533, -8.5535, -8.5537, -8.5538, -8.5545, -8.5548, -8.5553, -8.5557, -8.5568, -6.4858, -7.3772, -7.3279, -6.283, -8.0584, -8.0581, -7.7562, -8.4045, -8.0879, -8.3343, -8.4396, -8.3075, -8.2072, -8.2588, -8.4083, -8.3242, -8.074, -8.155, -8.2414, -6.413, -7.4372, -7.7314, -7.7319, -7.9186, -7.9189, -7.9192, -7.7321, -6.9315, -7.6161, -7.0774, -7.7571, -8.1492, -8.1493, -8.1493, -8.1498, -8.1498, -7.7319, -6.5924, -8.4487, -8.4487, -8.4487, -8.4488, -8.4488, -8.4489, -8.449, -8.449, -8.449, -8.449, -8.449, -8.1516, -7.7258, -8.1488, -7.9182, -7.026, -7.7663, -8.0558, -7.1281, -7.6661, -7.5955, -8.094, -8.0428, -8.0282, -8.1166], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9249, 0.9212, 0.9194, 0.9163, 0.9161, 0.9023, 0.9, 0.8975, 0.8969, 0.8917, 0.8912, 0.8871, 0.8829, 0.8784, 0.8675, 0.8669, 0.8656, 0.8648, 0.8643, 0.8622, 0.8597, 0.8562, 0.8524, 0.8521, 0.852, 0.8514, 0.851, 0.8474, 0.8467, 0.8453, 0.8445, 0.8203, 0.8036, 0.8068, 0.8021, 0.8038, 0.8075, 0.7538, 0.7919, 0.5403, 0.7337, 0.7041, 0.8286, 0.7385, 0.5887, 0.731, 0.4388, 0.5503, 0.5758, 0.5795, 0.477, 0.4231, 0.6032, 0.4982, 0.4561, 0.3367, 0.2412, 0.4123, 0.3055, 0.3446, 0.1688, 0.134, 0.1334, 0.1634, 0.3678, 0.164, 0.1392, -0.0327, 0.0669, 0.3159, 0.1973, -0.0072, 0.0813, 0.2223, 0.1022, -0.8189, -0.46, 0.9797, 0.9776, 0.97, 0.9685, 0.9582, 0.9551, 0.9548, 0.9537, 0.9499, 0.9446, 0.9436, 0.9426, 0.9421, 0.9374, 0.9294, 0.925, 0.9239, 0.9233, 0.9179, 0.9168, 0.9164, 0.9114, 0.9111, 0.9109, 0.9099, 0.9094, 0.908, 0.9079, 0.9072, 0.9036, 0.8947, 0.8948, 0.8679, 0.877, 0.7773, 0.8396, 0.8059, 0.8767, 0.8278, 0.8031, 0.8029, 0.6845, 0.7497, 0.7321, 0.8351, 0.5772, 0.8156, 0.6307, 0.7069, 0.5658, 0.5991, 0.7233, 0.7158, 0.4809, 0.6616, 0.6129, 0.5387, 0.2642, 0.307, 0.1489, 0.4202, 0.2467, 0.4214, 0.436, 0.415, 0.1968, -0.0822, 0.2889, 0.0381, 0.0986, 0.0191, 0.1343, 0.2761, -0.0405, -0.1826, -0.6046, 0.1744, -0.3645, 0.0755, 0.1234, 0.1433, 2.0016, 1.9856, 1.958, 1.9572, 1.9571, 1.9531, 1.9487, 1.9481, 1.9447, 1.9363, 1.9318, 1.9212, 1.9191, 1.9151, 1.9144, 1.904, 1.8985, 1.8898, 1.8889, 1.888, 1.8862, 1.8861, 1.8848, 1.8843, 1.8805, 1.8796, 1.871, 1.8703, 1.8702, 1.8681, 1.8528, 1.8236, 1.7542, 1.8066, 1.7201, 1.6714, 1.5918, 1.5004, 1.2456, 1.0847, 1.446, 1.2461, 0.8155, 1.0042, 1.1187, 0.8663, 0.4901, 1.1295, 1.1933, 0.7253, 1.0446, 1.48, -0.0182, 0.3616, -0.2854, 0.3369, -0.1062, 0.0918, -0.3766, 0.6175, 0.6031, -0.3426, -0.4108, -0.1996, 0.1017, -0.4312, 0.0288, -0.2285, -0.4257, -0.3817, 0.075, 2.3272, 2.3191, 2.2956, 2.2936, 2.278, 2.2739, 2.2694, 2.2619, 2.2369, 2.2362, 2.2092, 2.1883, 2.1797, 2.1678, 2.1638, 2.1586, 2.132, 2.1296, 2.1287, 2.128, 2.1213, 2.1168, 2.1152, 2.1149, 2.1082, 2.0912, 2.0879, 2.084, 2.0837, 2.0781, 2.0747, 1.9997, 1.772, 1.6473, 2.0503, 1.6944, 1.1718, 1.8398, 1.3075, 1.4483, 1.5904, 1.5811, 1.4814, 0.5931, 0.6105, 0.4194, 0.2489, 0.7407, -0.0768, 1.3883, 0.1854, -0.0173, -0.5906, -0.2337, -0.5466, -0.3466, 0.0803, 0.4855, 0.2418, -0.609, 0.0895, -0.0957, 0.0208, 0.0181, -0.6862, -0.5012, -0.1956, 3.5373, 3.4259, 3.3824, 3.3472, 3.347, 3.2395, 3.2221, 3.1786, 3.155, 3.0662, 3.0628, 3.0189, 2.9911, 2.9902, 2.9426, 2.9418, 2.9378, 2.9377, 2.9203, 2.9027, 2.8879, 2.8811, 2.8801, 2.8568, 2.8188, 2.8114, 2.8026, 2.7741, 2.7669, 2.7473, 2.5723, 2.5431, 2.5926, 2.0322, 2.0357, 1.4099, 1.6407, 1.8334, 2.1036, 1.4224, 1.0844, 0.9567, 1.2272, 1.3831, 0.2051, 0.513, 0.5506, 0.3195, 1.7442, 1.1199, -0.5065, 0.614, -0.7872, -0.0593, 0.872, -0.848, -1.2951, 3.7961, 3.6217, 3.5866, 3.5684, 3.4637, 3.4535, 3.4501, 3.4062, 3.4025, 3.3852, 3.3772, 3.3528, 3.3521, 3.2923, 3.2921, 3.1718, 3.1411, 3.141, 3.0998, 3.0504, 3.0451, 3.0451, 2.9306, 2.9301, 2.9254, 2.9254, 2.9249, 2.8975, 2.7875, 2.7872, 2.6848, 2.6578, 2.2258, 2.5414, 2.426, 1.9313, 2.6415, 2.2194, 2.0976, 1.4465, 2.377, 1.4618, 1.0939, 0.687, 1.1776, 1.3297, -0.318, 0.0327, 0.5962, -1.0658, 0.0235, 0.0789, 1.106, -0.0189, -0.8313, -0.6867, -0.1667, 3.2291, 3.1986, 3.1237, 2.8677, 2.8653, 2.8633, 2.8427, 2.8118, 2.7903, 2.7853, 2.6764, 2.6717, 2.5372, 2.4717, 2.4324, 2.4322, 2.4313, 2.4303, 2.43, 2.4278, 2.4271, 2.4269, 2.4266, 2.4264, 2.4261, 2.4249, 2.4246, 2.4237, 2.4232, 2.4213, 2.247, 2.2682, 2.24, 1.9217, 2.2839, 2.2479, 1.8498, 2.2436, 1.6154, 1.5607, 1.9531, 1.3852, 0.1818, 0.4724, 1.4435, 0.4457, -2.3858, -3.2508, -2.4612, 4.4341, 3.5542, 3.2827, 3.2816, 3.1073, 3.1069, 3.1062, 3.0978, 3.0605, 2.9588, 2.9287, 2.9213, 2.889, 2.8888, 2.8887, 2.8878, 2.8878, 2.8661, 2.6108, 2.6022, 2.6021, 2.602, 2.602, 2.6019, 2.6018, 2.6017, 2.6016, 2.6016, 2.6016, 2.6015, 2.5427, 2.1002, 2.3596, 2.0044, 0.869, 1.7698, 2.0539, -0.2257, 0.4235, -0.1413, 1.4498, 0.1455, -2.248, -2.9886]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 8, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6], \"Freq\": [0.3031524953042743, 0.3031524953042743, 0.3031524953042743, 0.3031524953042743, 0.28251435034517974, 0.28251435034517974, 0.28251435034517974, 0.28251435034517974, 0.17634373304449077, 0.30459372071321134, 0.06412499383436028, 0.448874956840522, 0.3088109224166128, 0.213792177057655, 0.24546509217730758, 0.007918228779913147, 0.12669166047861036, 0.08710051657904463, 0.15036017153341302, 0.2362802695525062, 0.10740012252386645, 0.49404056360978565, 0.010740012252386645, 0.2825271648804788, 0.2825271648804788, 0.2825271648804788, 0.2825271648804788, 0.6985941517661103, 0.1905256777543937, 0.02116951975048819, 0.06350855925146456, 0.9042514110902087, 0.05382448875536956, 0.021529795502147824, 0.010764897751073912, 0.3031478728697476, 0.3031478728697476, 0.3031478728697476, 0.3031478728697476, 0.5009500404767515, 0.04696406629469545, 0.015654688764898485, 0.43833128541715755, 0.0398070012919328, 0.0398070012919328, 0.0398070012919328, 0.8757540284225216, 0.1747101787789008, 0.1747101787789008, 0.1747101787789008, 0.1747101787789008, 0.5241305363367024, 0.01806533511763476, 0.7467005181955703, 0.12645734582344334, 0.006021778372544921, 0.07226134047053905, 0.024087113490179685, 0.16681421312005207, 0.16681421312005207, 0.16681421312005207, 0.16681421312005207, 0.5004426393601562, 0.09916697676707956, 0.09916697676707956, 0.09916697676707956, 0.6941688373695569, 0.16765806418010526, 0.7899394934028929, 0.021349716037916026, 0.016954186265403903, 0.003767596947867534, 0.000627932824644589, 0.4212315025220327, 0.4099986624547785, 0.10483984062770592, 0.054292060325061994, 0.005616420033627102, 0.0018721400112090341, 0.01696385636256446, 0.9499759563036096, 0.01696385636256446, 0.01696385636256446, 0.5332583776419484, 0.21330335105677936, 0.10665167552838968, 0.10665167552838968, 0.24577561048454544, 0.24577561048454544, 0.24577561048454544, 0.24577561048454544, 0.24577561048454544, 0.1747346271175636, 0.1747346271175636, 0.1747346271175636, 0.1747346271175636, 0.5242038813526908, 0.43852813437759364, 0.3582036741203116, 0.17584544002269845, 0.02170931358304919, 0.004341862716609838, 0.002170931358304919, 0.32109537012347483, 0.6211845010799935, 0.0210062391669563, 0.03300980440521704, 0.0030008913095651854, 0.11730137869992799, 0.11730137869992799, 0.11730137869992799, 0.11730137869992799, 0.5865068934996399, 0.4074480627415369, 0.288609044441922, 0.08488501307115352, 0.15279302352807633, 0.05093100784269211, 0.013997841341391416, 0.8818640045076592, 0.0839870480483485, 0.013997841341391416, 0.7569815221315054, 0.13763300402391007, 0.06881650201195504, 0.06881650201195504, 0.3031437843120888, 0.3031437843120888, 0.3031437843120888, 0.3031437843120888, 0.890632696854685, 0.035625307874187405, 0.035625307874187405, 0.035625307874187405, 0.3800612856559915, 0.19003064282799575, 0.19003064282799575, 0.19003064282799575, 0.0834138085616885, 0.0834138085616885, 0.04170690428084425, 0.7924311813360406, 0.07277751768532652, 0.8733302122239182, 0.03638875884266326, 0.01819437942133163, 0.014429226087926269, 0.7791782087480186, 0.014429226087926269, 0.014429226087926269, 0.1875799391430415, 0.694185939547444, 0.04958470996767457, 0.04958470996767457, 0.04958470996767457, 0.14875412990302372, 0.6738185357566088, 0.1810258752778949, 0.11733158582826522, 0.020113986141988324, 0.006704662047329441, 0.0033523310236647204, 0.06852615027914066, 0.06852615027914066, 0.822313803349688, 0.06852615027914066, 0.025038328755054965, 0.9264181639370337, 0.025038328755054965, 0.025038328755054965, 0.38351570437483684, 0.41891715400943713, 0.11407133771148993, 0.07473639367304513, 0.00590024160576672, 0.0039334944038444805, 0.8975594732945331, 0.04487797366472666, 0.04487797366472666, 0.04487797366472666, 0.4968141980541663, 0.10646018529732136, 0.035486728432440454, 0.017743364216220227, 0.31938055589196407, 0.016353871292199815, 0.7686319507333914, 0.016353871292199815, 0.016353871292199815, 0.1962464555063978, 0.028641059336161418, 0.22912847468929134, 0.028641059336161418, 0.028641059336161418, 0.7160264834040355, 0.160788315766583, 0.7691765375860863, 0.00869126031170719, 0.052147561870243136, 0.004345630155853595, 0.16886582440793915, 0.08443291220396958, 0.4221645610198479, 0.08443291220396958, 0.3377316488158783, 0.189146278931135, 0.189146278931135, 0.189146278931135, 0.189146278931135, 0.37829255786227, 0.5721125301857001, 0.030648885545662505, 0.010216295181887502, 0.38821921691172506, 0.8999500113912654, 0.044997500569563274, 0.044997500569563274, 0.044997500569563274, 0.17493360923341414, 0.17493360923341414, 0.17493360923341414, 0.17493360923341414, 0.5248008277002425, 0.12493109658372982, 0.8140671454810782, 0.008060070747337408, 0.04836042448402445, 0.004030035373668704, 0.27422459358024265, 0.5484491871604853, 0.09140819786008088, 0.09140819786008088, 0.09810825871407813, 0.6867578109985469, 0.09810825871407813, 0.09810825871407813, 0.01601155527815104, 0.9606933166890625, 0.01601155527815104, 0.01601155527815104, 0.24306932603657272, 0.24306932603657272, 0.24306932603657272, 0.24306932603657272, 0.2993320312470784, 0.2993320312470784, 0.2993320312470784, 0.2993320312470784, 0.39895663032418893, 0.4778945732225579, 0.05973682165281974, 0.05973682165281974, 0.004266915832344267, 0.75703582613407, 0.0176054843286993, 0.1584493589582937, 0.0176054843286993, 0.0176054843286993, 0.0176054843286993, 0.04645059191940309, 0.04645059191940309, 0.8825612464686586, 0.04645059191940309, 0.2122636501171431, 0.2122636501171431, 0.4245273002342862, 0.2122636501171431, 0.8601572888606077, 0.04778651604781154, 0.04778651604781154, 0.04778651604781154, 0.04778651604781154, 0.282597392492287, 0.282597392492287, 0.282597392492287, 0.282597392492287, 0.9555267267741492, 0.024088909078339896, 0.008029636359446632, 0.008029636359446632, 0.4178073817145379, 0.20890369085726895, 0.20890369085726895, 0.20890369085726895, 0.29938955003020085, 0.29938955003020085, 0.29938955003020085, 0.29938955003020085, 0.2456257601826508, 0.2456257601826508, 0.2456257601826508, 0.2456257601826508, 0.2456257601826508, 0.2956886742100721, 0.2956886742100721, 0.2956886742100721, 0.2956886742100721, 0.15178742370389262, 0.24837942060636975, 0.20698285050530812, 0.4001668443102624, 0.8900638803035872, 0.035602555212143484, 0.035602555212143484, 0.035602555212143484, 0.13888712698335978, 0.1944419777767037, 0.08333227619001586, 0.5555485079334391, 0.033802748862953556, 0.13521099545181423, 0.05070412329443034, 0.760561849416455, 0.022857828946704413, 0.022857828946704413, 0.022857828946704413, 0.9143131578681765, 0.4329874155413366, 0.225153456081495, 0.06927798648661385, 0.24247295270314848, 0.01731949662165346, 0.2958978120801227, 0.2503750717601039, 0.38694329272016054, 0.045522740320018885, 0.005690342540002361, 0.011380685080004721, 0.07155341257061502, 0.07155341257061502, 0.7870875382767653, 0.07155341257061502, 0.08491372307943229, 0.042456861539716145, 0.8349849436144174, 0.028304574359810764, 0.8470304420263437, 0.1321056652701637, 0.007770921486480217, 0.015541842972960435, 0.026585354912084556, 0.026585354912084556, 0.9304874219229594, 0.026585354912084556, 0.2605319376430242, 0.2605319376430242, 0.2605319376430242, 0.2605319376430242, 0.2831074205551866, 0.2831074205551866, 0.2831074205551866, 0.2831074205551866, 0.8944972735403273, 0.03889118580610119, 0.03889118580610119, 0.03889118580610119, 0.556948243825442, 0.2078165088900903, 0.1413152260452614, 0.05818862248922528, 0.016625320711207224, 0.016625320711207224, 0.2920800042889486, 0.2920800042889486, 0.2920800042889486, 0.2920800042889486, 0.016828105597227687, 0.967616071840592, 0.008414052798613843, 0.008414052798613843, 0.5312968554423496, 0.3702978083386073, 0.08173797776036149, 0.014861450501883906, 0.0012384542084903254, 0.87637716835653, 0.041732246112215717, 0.041732246112215717, 0.041732246112215717, 0.041398139451147634, 0.041398139451147634, 0.8693609284741003, 0.041398139451147634, 0.14481334842602112, 0.7421684106833583, 0.09654223228401408, 0.00603388951775088, 0.00603388951775088, 0.05671548306324678, 0.05671548306324678, 0.05671548306324678, 0.8507322459487017, 0.09355117221564083, 0.09355117221564083, 0.09355117221564083, 0.7484093777251266, 0.05438279768086434, 0.05438279768086434, 0.3371733456213589, 0.5329514172724705, 0.021753119072345735, 0.18365158964989234, 0.18365158964989234, 0.18365158964989234, 0.18365158964989234, 0.3673031792997847, 0.3031830428003435, 0.3031830428003435, 0.3031830428003435, 0.3031830428003435, 0.3275095304684343, 0.5485118965568899, 0.05059090308048985, 0.061241619518487715, 0.007988037328498397, 0.0026626791094994657, 0.12491823293865134, 0.8082944484265675, 0.029392525397329727, 0.022044394047997296, 0.007348131349332432, 0.027407768271436223, 0.12333495722146301, 0.8085291640073686, 0.013703884135718112, 0.013703884135718112, 0.04082067775943696, 0.04082067775943696, 0.04082067775943696, 0.04082067775943696, 0.8572342329481761, 0.8873722878727467, 0.046703804624881405, 0.046703804624881405, 0.046703804624881405, 0.5167047496221934, 0.17223491654073111, 0.17223491654073111, 0.17223491654073111, 0.17223491654073111, 0.5206747330169923, 0.23922893138618564, 0.13134137409437643, 0.09850603057078232, 0.0046907633605134435, 0.0046907633605134435, 0.7126360700337253, 0.17815901750843133, 0.08907950875421566, 0.08907950875421566, 0.23029431185860516, 0.024241506511432122, 0.7272451953429636, 0.012120753255716061, 0.06551910141700866, 0.06551910141700866, 0.8517483184211126, 0.06551910141700866, 0.5791796026281871, 0.26565037773879513, 0.055601241852305965, 0.08803529959948445, 0.009266873642050994, 0.2263765703270025, 0.2263765703270025, 0.2263765703270025, 0.2263765703270025, 0.2263765703270025, 0.9281677798969408, 0.025782438330470576, 0.025782438330470576, 0.025782438330470576, 0.8086752782841359, 0.09048115001780542, 0.03958550313278987, 0.05089564688501555, 0.005655071876112839, 0.4771860196784772, 0.2863116118070863, 0.19087440787139087, 0.09543720393569544, 0.47025415598169523, 0.3358958257012109, 0.13435833028048436, 0.06717916514024218, 0.30311755003704255, 0.30311755003704255, 0.30311755003704255, 0.30311755003704255, 0.028353235250857402, 0.028353235250857402, 0.7655373517731499, 0.17011941150514442, 0.4236646770480836, 0.2353692650267131, 0.28244311803205574, 0.015691284335114207, 0.031382568670228414, 0.06046961215958014, 0.816339764154332, 0.03023480607979007, 0.010078268693263358, 0.08062614954610686, 0.2819325781762294, 0.2819325781762294, 0.2819325781762294, 0.2819325781762294, 0.07117512703336196, 0.2135253811000859, 0.07117512703336196, 0.07117512703336196, 0.5694010162668957, 0.22289011176406262, 0.39005769558710957, 0.11144505588203131, 0.08358379191152349, 0.19502884779355478, 0.4117649817635189, 0.3923254332682455, 0.0777581939810937, 0.11663729097164055, 0.0017672316813884931, 0.6576420242523445, 0.2093717464966648, 0.1046858732483324, 0.013421265801068255, 0.010737012640854604, 0.002684253160213651, 0.2728958784879526, 0.4639229934295195, 0.10915835139518106, 0.10915835139518106, 0.04093438177319289, 0.47394928179390466, 0.35275677138085143, 0.09522268675311327, 0.07141701506483496, 0.006492455914984995, 0.2822967375325085, 0.2822967375325085, 0.2822967375325085, 0.2822967375325085, 0.7878826212709629, 0.07878826212709629, 0.07878826212709629, 0.07878826212709629, 0.2668135151156331, 0.30786174821034595, 0.34304594800581406, 0.0762324328901809, 0.005864033299244685, 0.05670446799828304, 0.05670446799828304, 0.05670446799828304, 0.8505670199742457, 0.2134486316796962, 0.2134486316796962, 0.2134486316796962, 0.2134486316796962, 0.4323238798860982, 0.2024808045036156, 0.3557095214252707, 0.005472454175773395, 0.4801109069463224, 0.1607813269773731, 0.2969988401109808, 0.05805992363071806, 0.0022330739857968486, 0.0022330739857968486, 0.1429048989408445, 0.07145244947042224, 0.07145244947042224, 0.7145244947042224, 0.5358106098479816, 0.25287431421868434, 0.13793144411928238, 0.06012396282122565, 0.008841759238415537, 0.0035367036953662147, 0.793317646601004, 0.10189400965517482, 0.08005957901478022, 0.021834430640394607, 0.10390739289880516, 0.10390739289880516, 0.7533285985163374, 0.02597684822470129, 0.8359327505437086, 0.029854741090846737, 0.059709482181693474, 0.029854741090846737, 0.029854741090846737, 0.029854741090846737, 0.7298339121720585, 0.09122923902150731, 0.09122923902150731, 0.09122923902150731, 0.3390764220848742, 0.48439488869267744, 0.08880572959365753, 0.07064092126768212, 0.014128184253536425, 0.002018312036219489, 0.8574622718397036, 0.06805256125711932, 0.013610512251423866, 0.0408315367542716, 0.013610512251423866, 0.2838851373770632, 0.586695950579264, 0.07570270330055019, 0.04731418956284387, 0.005677702747541265, 0.0018925675825137548, 0.2356414409280893, 0.2356414409280893, 0.2356414409280893, 0.2356414409280893, 0.2356414409280893, 0.588519430221291, 0.30297852148429427, 0.05776209222542301, 0.04577373346165597, 0.0043594031868243776, 0.0010898507967060944, 0.5037713504249883, 0.3616819951769147, 0.0645860705673062, 0.05166885645384496, 0.36222545715668103, 0.4048402168221729, 0.042614759665491886, 0.021307379832745943, 0.1491516588292216, 0.0934375441642767, 0.0934375441642767, 0.0934375441642767, 0.7475003533142136, 0.8489797501260615, 0.10518333187402533, 0.030052380535435807, 0.007513095133858952, 0.007513095133858952, 0.37054453598677234, 0.08718694964394642, 0.5340200665691719, 0.010898368705493303, 0.40541396230000065, 0.4647428348317081, 0.062154056937979194, 0.05509109592229974, 0.011300737625087126, 0.0014125922031358908, 0.8947007296286723, 0.03890003172298575, 0.03890003172298575, 0.03890003172298575, 0.3320844924087159, 0.5085043790008462, 0.0726434827144066, 0.04842898847627106, 0.034592134625907905, 0.0034592134625907904, 0.9569160302994175, 0.015434129520958347, 0.015434129520958347, 0.015434129520958347, 0.9247518447517196, 0.0237115857628646, 0.0237115857628646, 0.0237115857628646, 0.33577200244600824, 0.23504040171220578, 0.08953920065226886, 0.33577200244600824, 0.005596200040766804, 0.023138809746796742, 0.046277619493593485, 0.902413580125073, 0.023138809746796742, 0.06526110732558298, 0.06526110732558298, 0.8483943952325786, 0.06526110732558298, 0.0425084965466575, 0.8926784274798074, 0.0425084965466575, 0.0425084965466575, 0.16899309804058713, 0.7041379085024464, 0.023471263616748214, 0.0985793071903425, 0.004694252723349643, 0.0448787975086338, 0.1795151900345352, 0.0448787975086338, 0.7180607601381408, 0.8912929631433911, 0.024758137865094197, 0.024758137865094197, 0.049516275730188394, 0.09505421965955017, 0.8690671511730301, 0.013579174237078596, 0.013579174237078596, 0.2860471374758333, 0.14302356873791666, 0.07151178436895833, 0.07151178436895833, 0.42907070621375, 0.07151178436895833, 0.0704092306700085, 0.0704092306700085, 0.0704092306700085, 0.0704092306700085, 0.7745015373700935, 0.2829869451975803, 0.2829869451975803, 0.2829869451975803, 0.2829869451975803, 0.03428443461008328, 0.03428443461008328, 0.03428443461008328, 0.8913952998621653, 0.7665494848412238, 0.03141596249349278, 0.08168150248308122, 0.113097464976574, 0.0062831924986985555, 0.0062831924986985555, 0.17210326089258213, 0.17210326089258213, 0.17210326089258213, 0.17210326089258213, 0.5163097826777464, 0.930223816174609, 0.025839550449294695, 0.025839550449294695, 0.025839550449294695, 0.03176656937745086, 0.921230511946075, 0.03176656937745086, 0.03176656937745086, 0.32323705539342756, 0.13193349199731738, 0.3716126691257773, 0.1627179734633581, 0.008795566133154492, 0.07277112837751405, 0.07277112837751405, 0.07277112837751405, 0.7277112837751406, 0.07311426994449886, 0.07311426994449886, 0.07311426994449886, 0.7311426994449887, 0.40625548867638217, 0.40625548867638217, 0.20312774433819109, 0.20312774433819109, 0.3031565111860966, 0.3031565111860966, 0.3031565111860966, 0.3031565111860966, 0.04258341650070458, 0.04258341650070458, 0.8942517465147962, 0.04258341650070458, 0.2822797374941149, 0.2822797374941149, 0.2822797374941149, 0.2822797374941149, 0.22178461758417622, 0.22178461758417622, 0.22178461758417622, 0.22178461758417622, 0.2607835606328992, 0.2607835606328992, 0.2607835606328992, 0.2607835606328992, 0.5491068149392107, 0.230031233285345, 0.1261461601887376, 0.09151780248986843, 0.0024734541213477955, 0.0024734541213477955, 0.0804479633121442, 0.0804479633121442, 0.0804479633121442, 0.804479633121442, 0.0957467215508311, 0.0957467215508311, 0.0957467215508311, 0.1914934431016622, 0.5744803293049865, 0.07337739055552665, 0.07337739055552665, 0.07337739055552665, 0.8071512961107932, 0.28570523723595287, 0.28570523723595287, 0.28570523723595287, 0.28570523723595287, 0.3031243930450362, 0.3031243930450362, 0.3031243930450362, 0.3031243930450362, 0.03707036866393268, 0.8896888479343843, 0.03707036866393268, 0.03707036866393268, 0.2955915148572076, 0.2955915148572076, 0.2955915148572076, 0.2955915148572076, 0.8487071364430764, 0.12746151133394187, 0.012435269398433355, 0.009326452048825016, 0.04151969954526072, 0.04151969954526072, 0.8719136904504752, 0.04151969954526072, 0.2458520182520048, 0.2458520182520048, 0.2458520182520048, 0.2458520182520048, 0.2458520182520048, 0.07880629656561566, 0.15761259313123133, 0.07880629656561566, 0.7092566690905411, 0.050782078041300686, 0.050782078041300686, 0.8886863657227619, 0.025391039020650343, 0.2661917385875044, 0.5119071895913546, 0.049728126988874445, 0.16673548460975549, 0.005850367881044052, 0.06973754027195485, 0.08717192533994356, 0.6973754027195485, 0.05230315520396613, 0.10460631040793227, 0.15186307534116714, 0.15186307534116714, 0.15186307534116714, 0.15186307534116714, 0.6074523013646685, 0.4377851662879628, 0.4318153685658543, 0.0776073703874116, 0.03581878633265151, 0.011939595444217169, 0.003979865148072389, 0.1913772512279148, 0.01275848341519432, 0.318962085379858, 0.4656846446545927, 0.00637924170759716, 0.44958230679251227, 0.2519299486809978, 0.20482109648861607, 0.08397664956033259, 0.0061446328946584815, 0.004096421929772321, 0.4628868850370681, 0.26317359189607503, 0.17918202001434894, 0.0821250925065766, 0.007465917500597873, 0.005599438125448404, 0.05837593945336199, 0.8639639039097575, 0.005837593945336199, 0.06421353339869819, 0.299186048714224, 0.299186048714224, 0.299186048714224, 0.299186048714224, 0.22239170005717843, 0.6399006463909379, 0.023078383968197762, 0.10909781512238942, 0.004196069812399593, 0.4195290831229543, 0.2965636622076056, 0.07233260053844039, 0.17359824129225696, 0.0072332600538440395, 0.02169978016153212, 0.9213436563778984, 0.031056527743075227, 0.031056527743075227, 0.010352175914358408, 0.010352175914358408, 0.5990306625959205, 0.354745108700421, 0.03823599974016514, 0.006372666623360856, 0.002124222207786952, 0.20251331997957683, 0.20251331997957683, 0.20251331997957683, 0.20251331997957683, 0.40502663995915367, 0.19543989965813327, 0.19543989965813327, 0.19543989965813327, 0.19543989965813327, 0.39087979931626654, 0.1859108861388626, 0.1859108861388626, 0.1859108861388626, 0.2788663292082939, 0.1859108861388626, 0.2792934884075381, 0.5516046396048877, 0.072150817838614, 0.09309782946917937, 0.002327445736729484, 0.3960728342431012, 0.2865207737077753, 0.12219268290478653, 0.18960933554191015, 0.004213540789820225, 0.07941242100345355, 0.9053015994393706, 0.007941242100345356, 0.007941242100345356, 0.043791968801431456, 0.043791968801431456, 0.043791968801431456, 0.8758393760286292, 0.034694996021734224, 0.9020698965650898, 0.034694996021734224, 0.034694996021734224, 0.2993410436001676, 0.2993410436001676, 0.2993410436001676, 0.2993410436001676, 0.04097951526615586, 0.901549335855429, 0.04097951526615586, 0.04097951526615586, 0.06041813012218681, 0.06041813012218681, 0.06041813012218681, 0.7854356915884285, 0.06041813012218681, 0.09227731478194008, 0.8092010680877822, 0.0354912749161308, 0.04968778488258312, 0.8860701269345459, 0.04027591486066118, 0.04027591486066118, 0.04027591486066118, 0.051912021368292934, 0.10382404273658587, 0.051912021368292934, 0.778680320524394, 0.30308819683402183, 0.30308819683402183, 0.30308819683402183, 0.30308819683402183, 0.2517045422863008, 0.7193987931561164, 0.008503531833996648, 0.013605650934394637, 0.005102119100397989, 0.05880673003976235, 0.9115043156163164, 0.029403365019881174, 0.029403365019881174, 0.16673786244353786, 0.16673786244353786, 0.16673786244353786, 0.16673786244353786, 0.5002135873306136, 0.5147131066933637, 0.3492696081133539, 0.08140870565048099, 0.047269571022859926, 0.005252174558095547, 0.0013130436395238868, 0.3911740154361846, 0.07823480308723692, 0.07823480308723692, 0.07823480308723692, 0.3911740154361846, 0.04099183004093794, 0.9018202609006347, 0.04099183004093794, 0.04099183004093794, 0.02049662205217576, 0.9223479923479091, 0.04099324410435152, 0.02049662205217576, 0.785997561690206, 0.18138405269773983, 0.010076891816541101, 0.010076891816541101, 0.03734173281497037, 0.8962015875592889, 0.03734173281497037, 0.03734173281497037, 0.6516664127929207, 0.19861546047274278, 0.09411516917826046, 0.04997840018431763, 0.0038944207935831918, 0.0019472103967915959, 0.29225690595795734, 0.29225690595795734, 0.29225690595795734, 0.29225690595795734, 0.7582799061305453, 0.0361085669585974, 0.0361085669585974, 0.0361085669585974, 0.1444342678343896, 0.8973378370490233, 0.044866891852451164, 0.044866891852451164, 0.044866891852451164, 0.28211954441519427, 0.28211954441519427, 0.28211954441519427, 0.28211954441519427, 0.40638893934949466, 0.35559032193080786, 0.10159723483737367, 0.08127778786989893, 0.020319446967474734, 0.04063889393494947, 0.29918865222403224, 0.29918865222403224, 0.29918865222403224, 0.29918865222403224, 0.158256883718293, 0.158256883718293, 0.158256883718293, 0.158256883718293, 0.474770651154879, 0.07796018875533846, 0.6236815100427077, 0.15592037751067692, 0.07796018875533846, 0.3574438770450804, 0.28595510163606436, 0.07148877540901609, 0.21446632622704825, 0.31167682812528685, 0.10908688984385038, 0.283625913594011, 0.2914178342971432, 0.0015583841406264342, 0.0031167682812528684, 0.6952776713139889, 0.12559854707607543, 0.06279927353803771, 0.11214155988935305, 0.004485662395574122, 0.004485662395574122, 0.28246928916758346, 0.28246928916758346, 0.28246928916758346, 0.28246928916758346, 0.8616560729663619, 0.004786978183146455, 0.052656760014611004, 0.07180467274719683, 0.027171412430650684, 0.9238280226421233, 0.027171412430650684, 0.027171412430650684, 0.07290356145686121, 0.7376125041517723, 0.06432667187370107, 0.08148045104002136, 0.04288444791580071, 0.7937635338703082, 0.17755236941835842, 0.010444257024609318, 0.010444257024609318, 0.2356779363498281, 0.2356779363498281, 0.2356779363498281, 0.2356779363498281, 0.2356779363498281, 0.14573408584725803, 0.29146817169451605, 0.14573408584725803, 0.14573408584725803, 0.4372022575417741, 0.3764055693104229, 0.4935095242069989, 0.08503977677013258, 0.03485236752874286, 0.005576378804598857, 0.0027881894022994285, 0.3595152811363729, 0.1617818765113678, 0.2606485788238703, 0.08987882028409322, 0.11684246636932119, 0.19332603743743418, 0.19332603743743418, 0.19332603743743418, 0.19332603743743418, 0.19332603743743418, 0.1890322839890389, 0.1890322839890389, 0.1890322839890389, 0.1890322839890389, 0.3780645679780778, 0.34168975352066366, 0.5251898063373164, 0.056948292253443944, 0.02531035211264175, 0.04429311619712307, 0.006327588028160438, 0.1837347103643476, 0.1837347103643476, 0.1837347103643476, 0.1837347103643476, 0.3674694207286952, 0.021903489702146423, 0.9418500571922961, 0.021903489702146423, 0.021903489702146423, 0.14696820714685271, 0.04898940238228424, 0.04898940238228424, 0.7348410357342636, 0.09289929503227648, 0.09289929503227648, 0.09289929503227648, 0.09289929503227648, 0.7431943602582118, 0.8805102317377543, 0.025157435192507266, 0.0754723055775218, 0.025157435192507266, 0.16959025765087504, 0.6598120961729357, 0.09539451992861721, 0.05034710774010353, 0.015899086654769534, 0.007949543327384767, 0.036960839092738486, 0.9240209773184621, 0.036960839092738486, 0.036960839092738486, 0.36097193245505704, 0.30080994371254755, 0.18424609052393537, 0.14664484755986693, 0.0037601242964068445, 0.0037601242964068445, 0.30310800656896575, 0.30310800656896575, 0.30310800656896575, 0.30310800656896575, 0.11420902212696905, 0.2284180442539381, 0.11420902212696905, 0.11420902212696905, 0.4568360885078762, 0.6119247602034904, 0.2719665600904402, 0.08353258631349234, 0.03108189258176459, 0.001942618286360287, 0.03904077074426587, 0.585611561163988, 0.03904077074426587, 0.03904077074426587, 0.31232616595412693, 0.19324795141611514, 0.19324795141611514, 0.19324795141611514, 0.19324795141611514, 0.3864959028322303, 0.30820374334144607, 0.24656299467315684, 0.06164074866828921, 0.06164074866828921, 0.36984449200973524, 0.1507738700493997, 0.8292562852716985, 0.00837632611385554, 0.00837632611385554, 0.34941762528109843, 0.17470881264054922, 0.08735440632027461, 0.17470881264054922, 0.17470881264054922, 0.0350946193347178, 0.9124601027026629, 0.0350946193347178, 0.0350946193347178, 0.03953777456050476, 0.9093688148916094, 0.03953777456050476, 0.03953777456050476, 0.07154533229431027, 0.07154533229431027, 0.7869986552374131, 0.07154533229431027, 0.3712445949913755, 0.33774884205982286, 0.16189613916917128, 0.11444382251613833, 0.013956563721480283, 0.0027913127442960564, 0.9428653187523318, 0.019643027474006914, 0.019643027474006914, 0.019643027474006914, 0.4337397115217639, 0.24785126372672223, 0.21686985576088194, 0.06196281593168056, 0.03098140796584028, 0.03098140796584028, 0.3874631609265199, 0.536487453590566, 0.029804858532809224, 0.029804858532809224, 0.27040297346974257, 0.27040297346974257, 0.27040297346974257, 0.27040297346974257, 0.3320892793597532, 0.047441325622821884, 0.18976530249128754, 0.047441325622821884, 0.37953060498257507, 0.33061938984677297, 0.5543467965100027, 0.06711822199896894, 0.04723134140668185, 0.0024858600740358867, 0.02788666286999581, 0.05577332573999162, 0.02788666286999581, 0.892373211839866, 0.1655506132021526, 0.28668520822811794, 0.4360845420934752, 0.004037819834198844, 0.1009454958549711, 0.004037819834198844, 0.1439322554191867, 0.839604823278589, 0.011994354618265557, 0.011994354618265557, 0.13502497453068318, 0.13502497453068318, 0.13502497453068318, 0.13502497453068318, 0.5400998981227327, 0.18532669972698418, 0.12355113315132278, 0.24710226630264556, 0.06177556657566139, 0.30887783287830695, 0.2751531809297276, 0.08374227245687363, 0.5622695436390086, 0.07177909067732026, 0.8365060907715989, 0.0669204872617279, 0.07807390180534922, 0.011153414543621318, 0.011153414543621318, 0.029802530674094045, 0.9387797162339624, 0.014901265337047023, 0.014901265337047023, 0.014901265337047023, 0.23986898516617083, 0.6466952375405134, 0.08347863360408589, 0.027473980679825732, 0.002113383129217364, 0.6785239251599894, 0.19641482044104958, 0.06428121396252531, 0.04642532119515717, 0.010713535660420886, 0.0035711785534736284, 0.11965313689399645, 0.8423580837337351, 0.004786125475759858, 0.02871675285455915, 0.4406688427283278, 0.03672240356069398, 0.11016721068208195, 0.07344480712138796, 0.03672240356069398, 0.2570568249248579, 0.32465179991133175, 0.43043721785996797, 0.12402428311219416, 0.1021376449159246, 0.003647773032711593, 0.014591092130846372, 0.09355072840441951, 0.09355072840441951, 0.09355072840441951, 0.7484058272353561, 0.041983058652090455, 0.8921399963569222, 0.05247882331511307, 0.010495764663022614, 0.09875275108516453, 0.09875275108516453, 0.09875275108516453, 0.6912692575961517, 0.021088457548942126, 0.9489805897023957, 0.021088457548942126, 0.021088457548942126, 0.02822941757703311, 0.02822941757703311, 0.02822941757703311, 0.9315707800420926, 0.2824882377671244, 0.2824882377671244, 0.2824882377671244, 0.2824882377671244, 0.09026778559862181, 0.12035704746482907, 0.030089261866207268, 0.7221422847889745, 0.04097458253966345, 0.9014408158725958, 0.04097458253966345, 0.04097458253966345, 0.08874382884952416, 0.08874382884952416, 0.08874382884952416, 0.7986944596457174, 0.31349086981697294, 0.6717661496077992, 0.00814261999524605, 0.00814261999524605, 0.8896022365120981, 0.034215470635080694, 0.034215470635080694, 0.034215470635080694, 0.08270405524701635, 0.041352027623508175, 0.8270405524701636, 0.041352027623508175, 0.9283322213893233, 0.025787006149703424, 0.025787006149703424, 0.025787006149703424, 0.42392449368955726, 0.40161267823221214, 0.02231181545734512, 0.04462363091469024, 0.02231181545734512, 0.1115590772867256, 0.04008150106424444, 0.9485955251871185, 0.013360500354748148, 0.013360500354748148, 0.9086635922110025, 0.043269694867190595, 0.043269694867190595, 0.043269694867190595, 0.008030488576322142, 0.9315366748533684, 0.04818293145793285, 0.008030488576322142, 0.5649222856701762, 0.06847542856608196, 0.27390171426432786, 0.01711885714152049, 0.01711885714152049, 0.05135657142456147, 0.3643924556024396, 0.06832358542545743, 0.43840967314668516, 0.1195662744945505, 0.005693632118788119, 0.005693632118788119, 0.03469052726212241, 0.9019537088151828, 0.03469052726212241, 0.03469052726212241, 0.09540373931057748, 0.04770186965528874, 0.8109317841399085, 0.04770186965528874, 0.07608225325712491, 0.07608225325712491, 0.07608225325712491, 0.6086580260569993, 0.2282467597713747, 0.9307031929666186, 0.0332393997488078, 0.0332393997488078, 0.0332393997488078, 0.9297575092162708, 0.023538164790285334, 0.011769082395142667, 0.017653623592714003, 0.011769082395142667, 0.0058845411975713335, 0.3669104253227347, 0.47255336512154067, 0.08860375596028888, 0.06361295299713048, 0.005679727946172363, 0.0011359455892344728, 0.011342219464978914, 0.9414042155932498, 0.03402665839493674, 0.011342219464978914, 0.25888600598745165, 0.3678906400874313, 0.28613716451244653, 0.013625579262497455, 0.04087673778749236, 0.04087673778749236, 0.03890449331498386, 0.7391853729846933, 0.012968164438327953, 0.05187265775331181, 0.15561797325993543, 0.07354973419586272, 0.04903315613057515, 0.8580802322850651, 0.024516578065287575, 0.3070716707624794, 0.1535358353812397, 0.1535358353812397, 0.1535358353812397, 0.46060750614371904, 0.5129174167735414, 0.2858883962344329, 0.05885937569532442, 0.03363392896875681, 0.10090178690627043, 0.25680003342512614, 0.25680003342512614, 0.25680003342512614, 0.25680003342512614, 0.25680003342512614, 0.05992479465259783, 0.05992479465259783, 0.8389471251363696, 0.05992479465259783, 0.9259129311032953, 0.05004934762720515, 0.025024673813602575, 0.025024673813602575, 0.44719097974598393, 0.44267389914248917, 0.06775620905242181, 0.03161956422446351, 0.009034161206989575, 0.0015056935344982625, 0.12132742797161239, 0.12132742797161239, 0.12132742797161239, 0.12132742797161239, 0.6066371398580619, 0.2869033489029483, 0.0956344496343161, 0.0956344496343161, 0.0956344496343161, 0.4781722481715805, 0.3315855821361026, 0.2951920426333597, 0.23049241685070548, 0.11726807173106069, 0.008087453222831772, 0.012131179834247658, 0.16534344308121143, 0.6495635263904735, 0.03543073780311674, 0.04724098373748898, 0.09448196747497796, 0.1780316930620639, 0.16184699369278538, 0.6150185760325845, 0.03236939873855708, 0.023514796256107855, 0.09405918502443142, 0.8465326652198828, 0.023514796256107855, 0.06521255282928834, 0.06521255282928834, 0.8477631867807484, 0.06521255282928834, 0.050449783507345664, 0.050449783507345664, 0.8071965361175306, 0.050449783507345664, 0.050449783507345664, 0.42928319509573903, 0.1985434777317793, 0.13415099846741846, 0.11805287865132823, 0.06439247926436086, 0.05366039938696738, 0.3603299925735999, 0.5608143493438735, 0.03251097677355789, 0.04063872096694736, 0.005418496128926314, 0.3031848043786998, 0.3031848043786998, 0.3031848043786998, 0.3031848043786998, 0.07151999738990258, 0.07151999738990258, 0.7867199712889285, 0.07151999738990258, 0.028548292627972358, 0.9135453640951154, 0.028548292627972358, 0.028548292627972358, 0.021915210327542862, 0.942354044084343, 0.021915210327542862, 0.021915210327542862, 0.03516417426102433, 0.23442782840682885, 0.6681193109594622, 0.011721391420341443, 0.04688556568136577, 0.05345184599568748, 0.05345184599568748, 0.8552295359309997, 0.05345184599568748, 0.9415620222195146, 0.027693000653515133, 0.027693000653515133, 0.027693000653515133, 0.08415124211512853, 0.08415124211512853, 0.08415124211512853, 0.08415124211512853, 0.7573611790361567, 0.43399251089229807, 0.4210098289425284, 0.08624210152346948, 0.04914872452412777, 0.0064913409748848, 0.0027820032749506286, 0.6043514364413873, 0.014389319915271127, 0.014389319915271127, 0.35973299788177815, 0.4335341243960845, 0.37719918167794925, 0.11266988543627056, 0.07103101473156187, 0.0036740180033566485, 0.0012246726677855495, 0.28308650997608936, 0.28308650997608936, 0.28308650997608936, 0.28308650997608936, 0.06524707784517346, 0.06524707784517346, 0.8482120119872549, 0.06524707784517346, 0.8452586959229563, 0.09847674127257744, 0.02461918531814436, 0.02872238287116842, 0.00410319755302406, 0.19394781683413173, 0.19394781683413173, 0.19394781683413173, 0.19394781683413173, 0.38789563366826346, 0.04612886874520589, 0.04612886874520589, 0.04612886874520589, 0.8764485061589119, 0.18137840120384155, 0.18137840120384155, 0.18137840120384155, 0.18137840120384155, 0.3627568024076831, 0.06058853648609502, 0.24235414594438007, 0.12117707297219003, 0.06058853648609502, 0.48470829188876013, 0.22636817162271344, 0.22636817162271344, 0.22636817162271344, 0.22636817162271344, 0.22636817162271344, 0.4916740593679901, 0.36568258165494266, 0.0891159232604482, 0.03072962871049938, 0.024583702968399505, 0.25681507780978435, 0.25681507780978435, 0.25681507780978435, 0.25681507780978435, 0.25681507780978435, 0.9515135389256744, 0.024397783049376266, 0.00813259434979209, 0.00813259434979209, 0.00813259434979209, 0.8982212764569816, 0.044911063822849075, 0.044911063822849075, 0.044911063822849075, 0.8945889128301614, 0.03889517012305049, 0.03889517012305049, 0.03889517012305049, 0.45918337302892737, 0.22959168651446368, 0.22959168651446368, 0.22959168651446368, 0.06530928113418594, 0.06530928113418594, 0.06530928113418594, 0.8490206547444172, 0.10845243794955235, 0.30986410842729245, 0.5577553951691264, 0.015493205421364621, 0.015493205421364621, 0.015493205421364621, 0.4508969351976389, 0.33317507526919127, 0.1354911972761378, 0.04442334336922551, 0.031096340358457854, 0.0066635015053838256, 0.6002586832955445, 0.2791011712138519, 0.04970294829835719, 0.04587964458309894, 0.01529321486103298, 0.011469911145774735, 0.0415280668847142, 0.0415280668847142, 0.8720894045789982, 0.0415280668847142, 0.5758188451201824, 0.1439547112800456, 0.1439547112800456, 0.1439547112800456, 0.9508625941284492, 0.00864420540116772, 0.01728841080233544, 0.01728841080233544, 0.055453644218699576, 0.055453644218699576, 0.8318046632804936, 0.055453644218699576, 0.28711818313116805, 0.37156470758151156, 0.17733770134572144, 0.06755721956027483, 0.08444652445034354, 0.008444652445034354, 0.29854319262706924, 0.44781478894060384, 0.14927159631353462, 0.14927159631353462, 0.8723929429443876, 0.025658615968952577, 0.07697584790685773, 0.025658615968952577, 0.3031190185046016, 0.3031190185046016, 0.3031190185046016, 0.3031190185046016, 0.04872289159983998, 0.04872289159983998, 0.04872289159983998, 0.8770120487971196, 0.6666109131721115, 0.06666109131721115, 0.1333221826344223, 0.06666109131721115, 0.18706227397022124, 0.09353113698511062, 0.18706227397022124, 0.09353113698511062, 0.4676556849255531, 0.6309756553922511, 0.10516260923204185, 0.10516260923204185, 0.10516260923204185, 0.7097900366168679, 0.11829833943614465, 0.11829833943614465, 0.11829833943614465, 0.19561531846608268, 0.19561531846608268, 0.19561531846608268, 0.19561531846608268, 0.39123063693216537, 0.5735811576044347, 0.18495914140143005, 0.1288479412009962, 0.09767505220075519, 0.012469155600096407, 0.002078192600016068, 0.1523551140953679, 0.1523551140953679, 0.1523551140953679, 0.1523551140953679, 0.6094204563814716, 0.40936103867009754, 0.4175482594434995, 0.11052748044092635, 0.024561662320205853, 0.02046805193350488, 0.012280831160102926, 0.29573474186811793, 0.29573474186811793, 0.29573474186811793, 0.29573474186811793, 0.37706787701374594, 0.25799381058835247, 0.2302098617557607, 0.1309814730679328, 0.003969135547513115, 0.28284222812718884, 0.28284222812718884, 0.28284222812718884, 0.28284222812718884, 0.2828769699150614, 0.2828769699150614, 0.2828769699150614, 0.2828769699150614, 0.7033547770591201, 0.06394134336901092, 0.06394134336901092, 0.06394134336901092, 0.12788268673802183, 0.00903671459710226, 0.9669284618899419, 0.00903671459710226, 0.00903671459710226, 0.169964490559162, 0.6821241554441034, 0.009064772829821972, 0.13823778565478506, 0.002266193207455493, 0.07375581390021539, 0.07375581390021539, 0.07375581390021539, 0.8113139529023693, 0.27097137094260804, 0.27097137094260804, 0.27097137094260804, 0.27097137094260804, 0.2611042067477319, 0.2611042067477319, 0.2611042067477319, 0.2611042067477319, 0.4463615572358512, 0.4008724813392039, 0.10235042076745632, 0.03695987416602589, 0.011372268974161813, 0.0014215336217702267, 0.2824256373017333, 0.2824256373017333, 0.2824256373017333, 0.2824256373017333, 0.5204866646018942, 0.2974209512010824, 0.0743552378002706, 0.0743552378002706, 0.32244310051218483, 0.13757572288519887, 0.38263247927445937, 0.14187496422536133, 0.004299241340162465, 0.00859848268032493, 0.1762422454670677, 0.1762422454670677, 0.528726736401203, 0.1762422454670677, 0.43134700568850115, 0.21332922563942178, 0.25787049253116917, 0.09142681098832361, 0.004688554409657621, 0.0023442772048288107, 0.19583800358359824, 0.06527933452786608, 0.06527933452786608, 0.7180726798065269, 0.46767503612327777, 0.10316361090954657, 0.41265444363818626, 0.013755148121272875, 0.0682598854341735, 0.0682598854341735, 0.8191186252100819, 0.0682598854341735, 0.482394387070581, 0.2411971935352905, 0.2411971935352905, 0.2411971935352905, 0.5651323575598688, 0.18837745251995625, 0.18837745251995625, 0.18837745251995625, 0.38897453590161046, 0.38897453590161046, 0.12965817863387016, 0.12965817863387016, 0.1561703299071551, 0.7548232612179162, 0.007436682376531194, 0.029746729506124777, 0.04090175307092157, 0.014873364753062389, 0.24562631419204792, 0.24562631419204792, 0.24562631419204792, 0.24562631419204792, 0.24562631419204792, 0.037061598550056765, 0.8894783652013624, 0.037061598550056765, 0.037061598550056765, 0.043854519281415164, 0.043854519281415164, 0.8770903856283033, 0.043854519281415164, 0.20990303193655876, 0.20990303193655876, 0.20990303193655876, 0.20990303193655876, 0.41980606387311753, 0.4709772415671806, 0.15699241385572688, 0.15699241385572688, 0.15699241385572688, 0.28218694120448545, 0.28218694120448545, 0.28218694120448545, 0.28218694120448545, 0.049863016492526155, 0.049863016492526155, 0.8476712803729447, 0.049863016492526155, 0.40534902051519767, 0.20267451025759883, 0.20267451025759883, 0.20267451025759883, 0.5150661590491291, 0.1604304429825156, 0.06754966020316447, 0.1857615655587023, 0.05910595267776891, 0.008443707525395559, 0.4830333738801439, 0.33447016813213326, 0.12339676105845693, 0.051956530971981864, 0.005682745575060516, 0.0016236415928744332, 0.4359850232250625, 0.41529960241511427, 0.10024473161744138, 0.031823724322997266, 0.01432067594534877, 0.0015911862161498633, 0.6257868410042955, 0.2814784184436992, 0.08042240526962834, 0.007539600494027657, 0.0025132001646758855, 0.03488216892700666, 0.01744108446350333, 0.8894953076386698, 0.01744108446350333, 0.052323253390509986, 0.10217501997233662, 0.10217501997233662, 0.20435003994467324, 0.30652505991700985, 0.20435003994467324, 0.07112532137058186, 0.2133759641117456, 0.03556266068529093, 0.6756905530205276, 0.19275792189744367, 0.578273765692331, 0.19275792189744367, 0.19275792189744367, 0.24555363495383492, 0.24555363495383492, 0.24555363495383492, 0.24555363495383492, 0.24555363495383492, 0.20990477701484636, 0.20990477701484636, 0.20990477701484636, 0.20990477701484636, 0.4198095540296927, 0.2024097104238682, 0.2024097104238682, 0.2024097104238682, 0.2024097104238682, 0.4048194208477364, 0.1053525080534409, 0.1053525080534409, 0.3160575241603227, 0.1053525080534409, 0.4214100322137636, 0.13650410000353855, 0.02730082000070771, 0.7917237800205236, 0.02730082000070771, 0.24728814718840164, 0.24728814718840164, 0.24728814718840164, 0.24728814718840164, 0.24728814718840164, 0.19263373403213147, 0.19263373403213147, 0.19263373403213147, 0.19263373403213147, 0.38526746806426293, 0.6849672565492104, 0.21257604513596187, 0.038381785927326446, 0.056096456355323274, 0.005904890142665607, 0.0029524450713328035, 0.38036165647041714, 0.39116738534741763, 0.13831332962560625, 0.0821235394652037, 0.004322291550800195, 0.0021611457754000976, 0.39926368776894006, 0.2281506787251086, 0.17111300904383145, 0.08555650452191572, 0.1140753393625543, 0.2537766769053335, 0.1015106707621334, 0.1522660061432001, 0.1015106707621334, 0.4060426830485336], \"Term\": [\"abri\", \"abri\", \"abri\", \"abri\", \"abstr\", \"abstr\", \"abstr\", \"abstr\", \"access\", \"access\", \"access\", \"access\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"active\", \"active\", \"active\", \"active\", \"active\", \"activi\", \"activi\", \"activi\", \"activi\", \"activity\", \"activity\", \"activity\", \"activity\", \"adaptation\", \"adaptation\", \"adaptation\", \"adaptation\", \"addrus\", \"addrus\", \"addrus\", \"addrus\", \"adversarial\", \"adversarial\", \"adversarial\", \"adversarial\", \"adversarial_example\", \"adversarial_example\", \"adversarial_example\", \"adversarial_example\", \"aem\", \"aem\", \"aem\", \"aem\", \"aem\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"aki\", \"aki\", \"aki\", \"aki\", \"aki\", \"alexnet\", \"alexnet\", \"alexnet\", \"alexnet\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"amp\", \"amp\", \"amp\", \"amp\", \"analogue\", \"analogue\", \"analogue\", \"analogue\", \"anterior\", \"anterior\", \"anterior\", \"anterior\", \"anterior\", \"anytime\", \"anytime\", \"anytime\", \"anytime\", \"anytime\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"ar_despot\", \"ar_despot\", \"ar_despot\", \"ar_despot\", \"ar_despot\", \"area\", \"area\", \"area\", \"area\", \"area\", \"arm\", \"arm\", \"arm\", \"arm\", \"array\", \"array\", \"array\", \"array\", \"arrythmia\", \"arrythmia\", \"arrythmia\", \"arrythmia\", \"article\", \"article\", \"article\", \"article\", \"assist\", \"assist\", \"assist\", \"assist\", \"attack\", \"attack\", \"attack\", \"attack\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"auction\", \"auction\", \"auction\", \"auction\", \"auction\", \"auditory\", \"auditory\", \"auditory\", \"auditory\", \"auditory\", \"average\", \"average\", \"average\", \"average\", \"average\", \"average\", \"azimuth\", \"azimuth\", \"azimuth\", \"azimuth\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"bci\", \"bci\", \"bci\", \"bci\", \"belief\", \"belief\", \"belief\", \"belief\", \"belief\", \"bid\", \"bid\", \"bid\", \"bid\", \"bid\", \"bidder\", \"bidder\", \"bidder\", \"bidder\", \"bidder\", \"bind\", \"bind\", \"bind\", \"bind\", \"bind\", \"bird\", \"bird\", \"bird\", \"bird\", \"bird\", \"birdsong\", \"birdsong\", \"birdsong\", \"birdsong\", \"birdsong\", \"bit\", \"bit\", \"bit\", \"bit\", \"bkm\", \"bkm\", \"bkm\", \"bkm\", \"bne\", \"bne\", \"bne\", \"bne\", \"bne\", \"bound\", \"bound\", \"bound\", \"bound\", \"bound\", \"bring\", \"bring\", \"bring\", \"bring\", \"buffer\", \"buffer\", \"buffer\", \"buffer\", \"buyer\", \"buyer\", \"buyer\", \"buyer\", \"capacitor\", \"capacitor\", \"capacitor\", \"capacitor\", \"cardiac\", \"cardiac\", \"cardiac\", \"cardiac\", \"case\", \"case\", \"case\", \"case\", \"case\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"chair\", \"chair\", \"chair\", \"chair\", \"charge\", \"charge\", \"charge\", \"charge\", \"chip\", \"chip\", \"chip\", \"chip\", \"chip\", \"chover\", \"chover\", \"chover\", \"chover\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"clock\", \"clock\", \"clock\", \"clock\", \"cmos\", \"cmos\", \"cmos\", \"cmos\", \"cnn_resnet\", \"cnn_resnet\", \"cnn_resnet\", \"cnn_resnet\", \"cnn_resnet\", \"coggin\", \"coggin\", \"coggin\", \"coggin\", \"communication\", \"communication\", \"communication\", \"communication\", \"competition\", \"competition\", \"competition\", \"competition\", \"compression\", \"compression\", \"compression\", \"compression\", \"concave\", \"concave\", \"concave\", \"concave\", \"concave_distribution\", \"concave_distribution\", \"concave_distribution\", \"concave_distribution\", \"connection\", \"connection\", \"connection\", \"connection\", \"connection\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"convolutional_spatial\", \"convolutional_spatial\", \"convolutional_spatial\", \"convolutional_spatial\", \"correspondence\", \"correspondence\", \"correspondence\", \"correspondence\", \"covariance\", \"covariance\", \"covariance\", \"covariance\", \"cpe\", \"cpe\", \"cpe\", \"cpe\", \"cri\", \"cri\", \"cri\", \"cri\", \"criticality\", \"criticality\", \"criticality\", \"criticality\", \"ctm\", \"ctm\", \"ctm\", \"ctm\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"dac\", \"dac\", \"dac\", \"dac\", \"dag\", \"dag\", \"dag\", \"dag\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"dbn\", \"dbn\", \"dbn\", \"dbn\", \"decentralize\", \"decentralize\", \"decentralize\", \"decentralize\", \"decision\", \"decision\", \"decision\", \"decision\", \"decision\", \"deconvolution\", \"deconvolution\", \"deconvolution\", \"deconvolution\", \"deconvolutional_layer\", \"deconvolutional_layer\", \"deconvolutional_layer\", \"deconvolutional_layer\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"default_policy\", \"default_policy\", \"default_policy\", \"default_policy\", \"default_policy\", \"defibrillator\", \"defibrillator\", \"defibrillator\", \"defibrillator\", \"define\", \"define\", \"define\", \"define\", \"define\", \"define\", \"definition\", \"definition\", \"definition\", \"definition\", \"definition\", \"depth\", \"depth\", \"depth\", \"depth\", \"depth\", \"despot\", \"despot\", \"despot\", \"despot\", \"despot\", \"deviant\", \"deviant\", \"deviant\", \"deviant\", \"die\", \"die\", \"die\", \"die\", \"die\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"digital\", \"digital\", \"digital\", \"digital\", \"discriminative\", \"discriminative\", \"discriminative\", \"discriminative\", \"disentangle\", \"disentangle\", \"disentangle\", \"disentangle\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"doupe\", \"doupe\", \"doupe\", \"doupe\", \"doupe\", \"ds_tump\", \"ds_tump\", \"ds_tump\", \"ds_tump\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"efficacy\", \"efficacy\", \"efficacy\", \"efficacy\", \"electrical\", \"electrical\", \"electrical\", \"electrical\", \"electrogram\", \"electrogram\", \"electrogram\", \"electrogram\", \"encoder\", \"encoder\", \"encoder\", \"encoder\", \"energy\", \"energy\", \"energy\", \"energy\", \"energy\", \"entry\", \"entry\", \"entry\", \"entry\", \"entry\", \"epsp\", \"epsp\", \"epsp\", \"epsp\", \"equilibria\", \"equilibria\", \"equilibria\", \"equilibria\", \"equilibria\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"error\", \"error\", \"error\", \"error\", \"error\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"evaluation\", \"evaluation\", \"evaluation\", \"evaluation\", \"evaluation\", \"example\", \"example\", \"example\", \"example\", \"example\", \"exci\", \"exci\", \"exci\", \"exci\", \"excitatory\", \"excitatory\", \"excitatory\", \"excitatory\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"external_field\", \"external_field\", \"external_field\", \"external_field\", \"extinction\", \"extinction\", \"extinction\", \"extinction\", \"face\", \"face\", \"face\", \"face\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feedback_alignment\", \"feedback_alignment\", \"feedback_alignment\", \"feedback_alignment\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"filter\", \"filter\", \"filter\", \"filter\", \"fine\", \"fine\", \"fine\", \"fine\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"firing\", \"firing\", \"firing\", \"firing\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"forebrain\", \"forebrain\", \"forebrain\", \"forebrain\", \"forebrain\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"gain\", \"gain\", \"gain\", \"gain\", \"game\", \"game\", \"game\", \"game\", \"game\", \"gate\", \"gate\", \"gate\", \"gate\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"generative\", \"generative\", \"generative\", \"generative\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"glm\", \"glm\", \"glm\", \"glm\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gp\", \"gp\", \"gp\", \"gp\", \"gqm\", \"gqm\", \"gqm\", \"gqm\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"grammatical\", \"grammatical\", \"grammatical\", \"grammatical\", \"grammaticality\", \"grammaticality\", \"grammaticality\", \"grammaticality\", \"gtt\", \"gtt\", \"gtt\", \"gtt\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"halfspace\", \"halfspace\", \"halfspace\", \"halfspace\", \"hidden_unit\", \"hidden_unit\", \"hidden_unit\", \"hidden_unit\", \"histogram\", \"histogram\", \"histogram\", \"histogram\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hit\", \"hmc\", \"hmc\", \"hmc\", \"hmc\", \"hmc\", \"hme\", \"hme\", \"hme\", \"hme\", \"houdini\", \"houdini\", \"houdini\", \"houdini\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"hvc\", \"hvc\", \"hvc\", \"hvc\", \"hvc\", \"ica\", \"ica\", \"ica\", \"ica\", \"identifiability\", \"identifiability\", \"identifiability\", \"identifiability\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image_denoise\", \"image_denoise\", \"image_denoise\", \"image_denoise\", \"image_restoration\", \"image_restoration\", \"image_restoration\", \"image_restoration\", \"ime\", \"ime\", \"ime\", \"ime\", \"implantable\", \"implantable\", \"implantable\", \"implantable\", \"inflow\", \"inflow\", \"inflow\", \"inflow\", \"inhibi\", \"inhibi\", \"inhibi\", \"inhibi\", \"inhibition\", \"inhibition\", \"inhibition\", \"inhibition\", \"ini\", \"ini\", \"ini\", \"ini\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"interaction_strength\", \"interaction_strength\", \"interaction_strength\", \"interaction_strength\", \"iou\", \"iou\", \"iou\", \"iou\", \"iou\", \"isotropic_concave\", \"isotropic_concave\", \"isotropic_concave\", \"isotropic_concave\", \"jabri\", \"jabri\", \"jabri\", \"jabri\", \"jiggle\", \"jiggle\", \"jiggle\", \"jiggle\", \"jungle\", \"jungle\", \"jungle\", \"jungle\", \"kakadu\", \"kakadu\", \"kakadu\", \"kakadu\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kitti\", \"kitti\", \"kitti\", \"kitti\", \"konishi\", \"konishi\", \"konishi\", \"konishi\", \"konishi\", \"kontorovich\", \"kontorovich\", \"kontorovich\", \"kontorovich\", \"lab\", \"lab\", \"lab\", \"lab\", \"label\", \"label\", \"label\", \"label\", \"label\", \"language\", \"language\", \"language\", \"language\", \"language\", \"language_rule\", \"language_rule\", \"language_rule\", \"language_rule\", \"language_rule\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"lemma\", \"lemma\", \"lemma\", \"lemma\", \"leong\", \"leong\", \"leong\", \"leong\", \"let\", \"let\", \"let\", \"let\", \"let\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"lman\", \"lman\", \"lman\", \"lman\", \"lman\", \"local_translation\", \"local_translation\", \"local_translation\", \"local_translation\", \"local_translation\", \"localization\", \"localization\", \"localization\", \"localization\", \"localization\", \"log\", \"log\", \"log\", \"log\", \"log\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"low_rank\", \"low_rank\", \"low_rank\", \"low_rank\", \"lraam\", \"lraam\", \"lraam\", \"lraam\", \"lrsdp\", \"lrsdp\", \"lrsdp\", \"lrsdp\", \"lsb\", \"lsb\", \"lsb\", \"lsb\", \"mab\", \"mab\", \"mab\", \"mab\", \"magnetization\", \"magnetization\", \"magnetization\", \"magnetization\", \"magnetization\", \"margin\", \"margin\", \"margin\", \"margin\", \"marginal_likelihood\", \"marginal_likelihood\", \"marginal_likelihood\", \"marginal_likelihood\", \"marmann\", \"marmann\", \"marmann\", \"marmann\", \"marwan\", \"marwan\", \"marwan\", \"marwan\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix_factorization\", \"matrix_factorization\", \"matrix_factorization\", \"matrix_factorization\", \"mdp_assessment\", \"mdp_assessment\", \"mdp_assessment\", \"mdp_assessment\", \"mdp_assessment\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"metropolis\", \"metropolis\", \"metropolis\", \"metropolis\", \"metropolis\", \"mf_lrsdp\", \"mf_lrsdp\", \"mf_lrsdp\", \"mf_lrsdp\", \"mistake\", \"mistake\", \"mistake\", \"mistake\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mms\", \"mms\", \"mms\", \"mms\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"morphology\", \"morphology\", \"morphology\", \"morphology\", \"motor\", \"motor\", \"motor\", \"motor\", \"motor\", \"mrp\", \"mrp\", \"mrp\", \"mrp\", \"mtg\", \"mtg\", \"mtg\", \"mtg\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"mume\", \"mume\", \"mume\", \"mume\", \"music\", \"music\", \"music\", \"music\", \"music\", \"neighbor\", \"neighbor\", \"neighbor\", \"neighbor\", \"neighborhood\", \"neighborhood\", \"neighborhood\", \"neighborhood\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neuromodulator\", \"neuromodulator\", \"neuromodulator\", \"neuromodulator\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"nnpca\", \"nnpca\", \"nnpca\", \"nnpca\", \"node\", \"node\", \"node\", \"node\", \"node\", \"nonlinear\", \"nonlinear\", \"nonlinear\", \"nonlinear\", \"nottebohm\", \"nottebohm\", \"nottebohm\", \"nottebohm\", \"nottebohm\", \"nucleus\", \"nucleus\", \"nucleus\", \"nucleus\", \"nucleus\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object_localization\", \"object_localization\", \"object_localization\", \"object_localization\", \"object_localization\", \"object_proposal\", \"object_proposal\", \"object_proposal\", \"object_proposal\", \"object_proposal\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"online_pomdp\", \"online_pomdp\", \"online_pomdp\", \"online_pomdp\", \"online_pomdp\", \"onmf\", \"onmf\", \"onmf\", \"onmf\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opponent\", \"opponent\", \"opponent\", \"opponent\", \"opponent\", \"optical\", \"optical\", \"optical\", \"optical\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optspace\", \"optspace\", \"optspace\", \"optspace\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"pacemaker\", \"pacemaker\", \"pacemaker\", \"pacemaker\", \"pal\", \"pal\", \"pal\", \"pal\", \"pal\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parse\", \"parse\", \"parse\", \"parse\", \"parse\", \"parser\", \"parser\", \"parser\", \"parser\", \"parser\", \"particle\", \"particle\", \"particle\", \"particle\", \"particle\", \"partition\", \"partition\", \"partition\", \"partition\", \"pathway\", \"pathway\", \"pathway\", \"pathway\", \"pathway\", \"payment\", \"payment\", \"payment\", \"payment\", \"pca\", \"pca\", \"pca\", \"pca\", \"pck\", \"pck\", \"pck\", \"pck\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"pg_mean\", \"pg_mean\", \"pg_mean\", \"pg_mean\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase_transition\", \"phase_transition\", \"phase_transition\", \"phase_transition\", \"piriform\", \"piriform\", \"piriform\", \"piriform\", \"planning\", \"planning\", \"planning\", \"planning\", \"planning\", \"point\", \"point\", \"point\", \"point\", \"point\", \"pointer\", \"pointer\", \"pointer\", \"pointer\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"polynomial\", \"polynomial\", \"polynomial\", \"polynomial\", \"pomcp\", \"pomcp\", \"pomcp\", \"pomcp\", \"pomcp\", \"pomdps\", \"pomdps\", \"pomdps\", \"pomdps\", \"pomdps\", \"pose\", \"pose\", \"pose\", \"pose\", \"posterior\", \"posterior\", \"posterior\", \"posterior\", \"posterior\", \"price\", \"price\", \"price\", \"price\", \"price\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"proof\", \"proof\", \"proof\", \"proof\", \"proposal\", \"proposal\", \"proposal\", \"proposal\", \"proposal\", \"proposal\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"psnr\", \"psnr\", \"psnr\", \"psnr\", \"pt\", \"pt\", \"pt\", \"pt\", \"pulvinar\", \"pulvinar\", \"pulvinar\", \"pulvinar\", \"pv_tree\", \"pv_tree\", \"pv_tree\", \"pv_tree\", \"qsgd\", \"qsgd\", \"qsgd\", \"qsgd\", \"quali\", \"quali\", \"quali\", \"quali\", \"quantization\", \"quantization\", \"quantization\", \"quantization\", \"query_complexity\", \"query_complexity\", \"query_complexity\", \"query_complexity\", \"raam\", \"raam\", \"raam\", \"raam\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank_differentiable\", \"rank_differentiable\", \"rank_differentiable\", \"rank_differentiable\", \"rat\", \"rat\", \"rat\", \"rat\", \"rating\", \"rating\", \"rating\", \"rating\", \"recall\", \"recall\", \"recall\", \"recall\", \"recall\", \"recall\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"reflex\", \"reflex\", \"reflex\", \"reflex\", \"regret\", \"regret\", \"regret\", \"regret\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"reserve_price\", \"reserve_price\", \"reserve_price\", \"reserve_price\", \"reservoir\", \"reservoir\", \"reservoir\", \"reservoir\", \"resnet\", \"resnet\", \"resnet\", \"resnet\", \"resnet\", \"resonator\", \"resonator\", \"resonator\", \"resonator\", \"response\", \"response\", \"response\", \"response\", \"response\", \"response\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"revenue\", \"revenue\", \"revenue\", \"revenue\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"round\", \"round\", \"round\", \"round\", \"round\", \"route\", \"route\", \"route\", \"route\", \"rpn\", \"rpn\", \"rpn\", \"rpn\", \"rpn\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rvc\", \"rvc\", \"rvc\", \"rvc\", \"rvc\", \"safe\", \"safe\", \"safe\", \"safe\", \"saliency\", \"saliency\", \"saliency\", \"saliency\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sampled_scenario\", \"sampled_scenario\", \"sampled_scenario\", \"sampled_scenario\", \"sampled_scenario\", \"sampler\", \"sampler\", \"sampler\", \"sampler\", \"sampler\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scenario\", \"scenario\", \"scenario\", \"scenario\", \"scenario\", \"scene\", \"scene\", \"scene\", \"scene\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"scheduler\", \"scheduler\", \"scheduler\", \"scheduler\", \"scheduling\", \"scheduling\", \"scheduling\", \"scheduling\", \"scheduling\", \"search\", \"search\", \"search\", \"search\", \"search\", \"search\", \"section\", \"section\", \"section\", \"section\", \"section\", \"sedalsuozau\", \"sedalsuozau\", \"sedalsuozau\", \"sedalsuozau\", \"selectbatch\", \"selectbatch\", \"selectbatch\", \"selectbatch\", \"selective_sample\", \"selective_sample\", \"selective_sample\", \"selective_sample\", \"seller\", \"seller\", \"seller\", \"seller\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sentence_structure\", \"sentence_structure\", \"sentence_structure\", \"sentence_structure\", \"separability\", \"separability\", \"separability\", \"separability\", \"sequential_auction\", \"sequential_auction\", \"sequential_auction\", \"sequential_auction\", \"sequential_auction\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"sgd\", \"sgd\", \"sgd\", \"sgd\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"shunt\", \"shunt\", \"shunt\", \"shunt\", \"sift\", \"sift\", \"sift\", \"sift\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"ski_aki\", \"ski_aki\", \"ski_aki\", \"ski_aki\", \"ski_aki\", \"skip_connection\", \"skip_connection\", \"skip_connection\", \"skip_connection\", \"slab\", \"slab\", \"slab\", \"slab\", \"slab\", \"song\", \"song\", \"song\", \"song\", \"song\", \"songbird\", \"songbird\", \"songbird\", \"songbird\", \"songbird\", \"space\", \"space\", \"space\", \"space\", \"space\", \"spectrographic\", \"spectrographic\", \"spectrographic\", \"spectrographic\", \"spectrographic\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike_train\", \"spike_train\", \"spike_train\", \"spike_train\", \"spike_triggere\", \"spike_triggere\", \"spike_triggere\", \"spike_triggere\", \"spontaneous\", \"spontaneous\", \"spontaneous\", \"spontaneous\", \"ssim\", \"ssim\", \"ssim\", \"ssim\", \"stage\", \"stage\", \"stage\", \"stage\", \"stage\", \"stage\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"stereo\", \"stereo\", \"stereo\", \"stereo\", \"stimulation\", \"stimulation\", \"stimulation\", \"stimulation\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stl\", \"stl\", \"stl\", \"stl\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"stretch\", \"stretch\", \"stretch\", \"stretch\", \"subject\", \"subject\", \"subject\", \"subject\", \"subthreshold\", \"subthreshold\", \"subthreshold\", \"subthreshold\", \"super_resolution\", \"super_resolution\", \"super_resolution\", \"super_resolution\", \"switch\", \"switch\", \"switch\", \"switch\", \"syllable\", \"syllable\", \"syllable\", \"syllable\", \"syllable\", \"synapse\", \"synapse\", \"synapse\", \"synapse\", \"synapsis\", \"synapsis\", \"synapsis\", \"synapsis\", \"syrinx\", \"syrinx\", \"syrinx\", \"syrinx\", \"syrinx\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"tag\", \"tag\", \"tag\", \"tag\", \"tag\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"talk\", \"talk\", \"talk\", \"talk\", \"task\", \"task\", \"task\", \"task\", \"task\", \"tative\", \"tative\", \"tative\", \"tative\", \"tatory\", \"tatory\", \"tatory\", \"tatory\", \"template\", \"template\", \"template\", \"template\", \"template\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"thn\", \"thn\", \"thn\", \"thn\", \"tial\", \"tial\", \"tial\", \"tial\", \"tical\", \"tical\", \"tical\", \"tical\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"ting\", \"ting\", \"ting\", \"ting\", \"tion\", \"tion\", \"tion\", \"tion\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"trainable\", \"trainable\", \"trainable\", \"trainable\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"transcription\", \"transcription\", \"transcription\", \"transcription\", \"transformation\", \"transformation\", \"transformation\", \"transformation\", \"transformer\", \"transformer\", \"transformer\", \"transformer\", \"transi\", \"transi\", \"transi\", \"transi\", \"transient\", \"transient\", \"transient\", \"transient\", \"trap\", \"trap\", \"trap\", \"trap\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree_rl\", \"tree_rl\", \"tree_rl\", \"tree_rl\", \"tree_rl\", \"tree_width\", \"tree_width\", \"tree_width\", \"tree_width\", \"turbine\", \"turbine\", \"turbine\", \"turbine\", \"tutor\", \"tutor\", \"tutor\", \"tutor\", \"tutor\", \"ultimate\", \"ultimate\", \"ultimate\", \"ultimate\", \"ume\", \"ume\", \"ume\", \"ume\", \"ungrammatical\", \"ungrammatical\", \"ungrammatical\", \"ungrammatical\", \"uni\", \"uni\", \"uni\", \"uni\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"verb\", \"verb\", \"verb\", \"verb\", \"verb\", \"vgg\", \"vgg\", \"vgg\", \"vgg\", \"vgg\", \"visit\", \"visit\", \"visit\", \"visit\", \"vlsi\", \"vlsi\", \"vlsi\", \"vlsi\", \"voc_teste\", \"voc_teste\", \"voc_teste\", \"voc_teste\", \"voc_teste\", \"vocal\", \"vocal\", \"vocal\", \"vocal\", \"vocal\", \"vocalization\", \"vocalization\", \"vocalization\", \"vocalization\", \"vocalization\", \"wall\", \"wall\", \"wall\", \"wall\", \"wall\", \"water\", \"water\", \"water\", \"water\", \"wattle\", \"wattle\", \"wattle\", \"wattle\", \"wattle\", \"weigend\", \"weigend\", \"weigend\", \"weigend\", \"weigend\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"whole\", \"whole\", \"whole\", \"whole\", \"whole\", \"window\", \"window\", \"window\", \"window\", \"window\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [8, 7, 6, 5, 3, 1, 2, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el405216743802863204699360282\", ldavis_el405216743802863204699360282_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el405216743802863204699360282\", ldavis_el405216743802863204699360282_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el405216743802863204699360282\", ldavis_el405216743802863204699360282_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "7      0.131435 -0.020003       1        1  37.962042\n",
       "6      0.139309  0.053241       2        1  36.304868\n",
       "5      0.048845 -0.057708       3        1  12.529590\n",
       "4      0.026954 -0.009148       4        1   9.028367\n",
       "2     -0.050466  0.037865       5        1   2.504429\n",
       "0     -0.079005 -0.009186       6        1   1.303313\n",
       "1     -0.109222  0.003236       7        1   0.190376\n",
       "3     -0.107851  0.001703       8        1   0.177013, topic_info=            Term         Freq        Total Category  logprob  loglift\n",
       "371      network   641.000000   641.000000  Default  30.0000  30.0000\n",
       "18     algorithm  1592.000000  1592.000000  Default  29.0000  29.0000\n",
       "1239       image   454.000000   454.000000  Default  28.0000  28.0000\n",
       "427       policy   247.000000   247.000000  Default  27.0000  27.0000\n",
       "306        learn   976.000000   976.000000  Default  26.0000  26.0000\n",
       "...          ...          ...          ...      ...      ...      ...\n",
       "132      current     0.184890   120.298431   Topic8  -7.5955  -0.1413\n",
       "2950  electrical     0.112312    14.885568   Topic8  -8.0940   1.4498\n",
       "104   connection     0.118217    57.738399   Topic8  -8.0428   0.1455\n",
       "371      network     0.119955   641.690309   Topic8  -8.0282  -2.2480\n",
       "616          use     0.109806  1231.798944   Topic8  -8.1166  -2.9886\n",
       "\n",
       "[533 rows x 6 columns], token_table=       Topic      Freq    Term\n",
       "term                          \n",
       "9900       1  0.303152    abri\n",
       "9900       2  0.303152    abri\n",
       "9900       3  0.303152    abri\n",
       "9900       4  0.303152    abri\n",
       "11929      1  0.282514   abstr\n",
       "...      ...       ...     ...\n",
       "1506       1  0.253777  window\n",
       "1506       2  0.101511  window\n",
       "1506       3  0.152266  window\n",
       "1506       4  0.101511  window\n",
       "1506       6  0.406043  window\n",
       "\n",
       "[1968 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[8, 7, 6, 5, 3, 1, 2, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "\n",
    "#visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "LDAvis_prepared = gensimvis.prepare(lda_model,corpus,id2word)\n",
    "\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d6a372dc-2898-4a55-83ea-d12d5f3087bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.060*\"team\" + 0.058*\"game\" + 0.038*\"play\" + 0.036*\"year\" + 0.033*\"win\" + '\n",
      "  '0.019*\"season\" + 0.018*\"fan\" + 0.016*\"goal\" + 0.015*\"nhl\" + 0.014*\"score\"'),\n",
      " (1,\n",
      "  '0.107*\"space\" + 0.034*\"earth\" + 0.028*\"launch\" + 0.025*\"moon\" + '\n",
      "  '0.025*\"nasa\" + 0.024*\"mission\" + 0.024*\"orbit\" + 0.020*\"satellite\" + '\n",
      "  '0.016*\"brown\" + 0.015*\"flight\"'),\n",
      " (2,\n",
      "  '0.043*\"md\" + 0.042*\"richard\" + 0.039*\"hole\" + 0.032*\"motto\" + 0.031*\"mu\" + '\n",
      "  '0.030*\"quick\" + 0.026*\"insert\" + 0.024*\"strip\" + 0.018*\"caltech\" + '\n",
      "  '0.017*\"rs\"'),\n",
      " (3,\n",
      "  '0.034*\"government\" + 0.030*\"israel\" + 0.026*\"public\" + 0.025*\"state\" + '\n",
      "  '0.018*\"american\" + 0.015*\"israeli\" + 0.013*\"country\" + 0.013*\"security\" + '\n",
      "  '0.013*\"encryption\" + 0.012*\"right\"'),\n",
      " (4,\n",
      "  '0.044*\"line\" + 0.040*\"organization\" + 0.028*\"write\" + 0.024*\"article\" + '\n",
      "  '0.019*\"get\" + 0.017*\"nntp_poste\" + 0.016*\"university\" + 0.015*\"host\" + '\n",
      "  '0.010*\"reply\" + 0.009*\"problem\"'),\n",
      " (5,\n",
      "  '0.097*\"gun\" + 0.078*\"law\" + 0.031*\"crime\" + 0.031*\"weapon\" + '\n",
      "  '0.030*\"firearm\" + 0.029*\"ride\" + 0.025*\"legal\" + 0.023*\"safety\" + '\n",
      "  '0.019*\"police\" + 0.018*\"tax\"'),\n",
      " (6,\n",
      "  '0.031*\"kill\" + 0.031*\"armenian\" + 0.026*\"greek\" + 0.026*\"soldier\" + '\n",
      "  '0.022*\"murder\" + 0.022*\"village\" + 0.020*\"woman\" + 0.019*\"turk\" + '\n",
      "  '0.017*\"muslim\" + 0.017*\"death\"'),\n",
      " (7,\n",
      "  '0.102*\"bike\" + 0.043*\"cop\" + 0.033*\"modem\" + 0.029*\"ticket\" + 0.024*\"duo\" + '\n",
      "  '0.021*\"craig\" + 0.020*\"specification\" + 0.016*\"purdue_university\" + '\n",
      "  '0.015*\"era\" + 0.014*\"tire\"'),\n",
      " (8,\n",
      "  '0.111*\"sale\" + 0.049*\"price\" + 0.041*\"sell\" + 0.037*\"material\" + '\n",
      "  '0.035*\"signal\" + 0.032*\"purchase\" + 0.028*\"circuit\" + 0.023*\"offer\" + '\n",
      "  '0.019*\"band\" + 0.018*\"super\"'),\n",
      " (9,\n",
      "  '0.061*\"cool\" + 0.049*\"telnet\" + 0.046*\"illinois\" + 0.034*\"dod\" + '\n",
      "  '0.031*\"joseph\" + 0.025*\"oil\" + 0.024*\"expansion\" + 0.022*\"unlikely\" + '\n",
      "  '0.020*\"cylinder\" + 0.019*\"brave\"'),\n",
      " (10,\n",
      "  '0.032*\"system\" + 0.023*\"key\" + 0.023*\"use\" + 0.018*\"information\" + '\n",
      "  '0.017*\"program\" + 0.016*\"include\" + 0.015*\"bit\" + 0.013*\"chip\" + '\n",
      "  '0.013*\"source\" + 0.012*\"available\"'),\n",
      " (11,\n",
      "  '0.080*\"video\" + 0.063*\"package\" + 0.055*\"mouse\" + 0.051*\"family\" + '\n",
      "  '0.041*\"mhz\" + 0.027*\"intel\" + 0.023*\"mine\" + 0.018*\"ftp_site\" + '\n",
      "  '0.013*\"columbia\" + 0.011*\"import\"'),\n",
      " (12,\n",
      "  '0.187*\"car\" + 0.049*\"replace\" + 0.029*\"warranty\" + 0.024*\"blind\" + '\n",
      "  '0.023*\"rm\" + 0.021*\"dealer\" + 0.016*\"mph\" + 0.015*\"panel\" + '\n",
      "  '0.015*\"terminal\" + 0.014*\"minnesota\"'),\n",
      " (13,\n",
      "  '0.070*\"image\" + 0.054*\"graphic\" + 0.044*\"monitor\" + 0.044*\"scan\" + '\n",
      "  '0.041*\"input\" + 0.036*\"format\" + 0.033*\"notice\" + 0.027*\"gov\" + '\n",
      "  '0.026*\"corp\" + 0.023*\"convert\"'),\n",
      " (14,\n",
      "  '0.669*\"ax\" + 0.115*\"_\" + 0.054*\"max\" + 0.014*\"m\" + 0.008*\"mr\" + 0.006*\"el\" '\n",
      "  '+ 0.002*\"gt\" + 0.001*\"sc\" + 0.001*\"austria\" + 0.001*\"lx\"'),\n",
      " (15,\n",
      "  '0.067*\"god\" + 0.047*\"evidence\" + 0.037*\"christian\" + 0.025*\"reason\" + '\n",
      "  '0.024*\"believe\" + 0.023*\"faith\" + 0.020*\"sense\" + 0.019*\"bible\" + '\n",
      "  '0.017*\"religion\" + 0.016*\"claim\"'),\n",
      " (16,\n",
      "  '0.056*\"window\" + 0.052*\"file\" + 0.040*\"card\" + 0.034*\"software\" + '\n",
      "  '0.033*\"driver\" + 0.032*\"mac\" + 0.023*\"entry\" + 0.023*\"machine\" + 0.022*\"do\" '\n",
      "  '+ 0.021*\"memory\"'),\n",
      " (17,\n",
      "  '0.034*\"ice\" + 0.028*\"detroit\" + 0.028*\"wing\" + 0.025*\"alan\" + '\n",
      "  '0.025*\"conference\" + 0.024*\"roger\" + 0.023*\"definitely\" + 0.021*\"trace\" + '\n",
      "  '0.021*\"years_ago\" + 0.019*\"journal\"'),\n",
      " (18,\n",
      "  '0.020*\"say\" + 0.017*\"people\" + 0.017*\"think\" + 0.015*\"make\" + 0.014*\"go\" + '\n",
      "  '0.013*\"see\" + 0.013*\"know\" + 0.011*\"time\" + 0.011*\"well\" + 0.010*\"come\"'),\n",
      " (19,\n",
      "  '0.041*\"child\" + 0.035*\"physical\" + 0.030*\"die\" + 0.029*\"patient\" + '\n",
      "  '0.022*\"drug\" + 0.021*\"fire\" + 0.015*\"disease\" + 0.015*\"health\" + '\n",
      "  '0.014*\"direct\" + 0.013*\"visit\"')]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0e82846b-7f98-4911-961e-52f4ecc6e50a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-57acddd79405>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent_topics_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mdf_topic_sents_keywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_topics_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimal_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-115-57acddd79405>\u001b[0m in \u001b[0;36mformat_topics_sentences\u001b[1;34m(ldamodel, corpus, texts)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#get the main topic in each document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;31m#get the dominant topic, perc contribution and keywords for each document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtopic_num\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprop_topic\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'tuple'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e8f42-fe2d-460e-8f3c-5bd165279458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
